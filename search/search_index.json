{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Read Latest Documentation - Browse GitHub Code Repository isort your python imports for you so you don't have to. isort is a Python utility / library to sort imports alphabetically, and automatically separated into sections. It provides a command line utility, Python library and plugins for various editors to quickly sort all your imports. It requires Python 3.5+ to run but supports formatting Python 2 code too. Get professionally supported isort with the Tidelift Subscription Professional support for isort is available as part of the Tidelift Subscription . Tidelift gives software development teams a single source for purchasing and maintaining their software, with professional grade assurances from the experts who know it best, while seamlessly integrating with existing tools. Before isort: from my_lib import Object print ( \"Hey\" ) import os from my_lib import Object3 from my_lib import Object2 import sys from third_party import lib15 , lib1 , lib2 , lib3 , lib4 , lib5 , lib6 , lib7 , lib8 , lib9 , lib10 , lib11 , lib12 , lib13 , lib14 import sys from __future__ import absolute_import from third_party import lib3 print ( \"yo\" ) After isort: from __future__ import absolute_import import os import sys from third_party import ( lib1 , lib2 , lib3 , lib4 , lib5 , lib6 , lib7 , lib8 , lib9 , lib10 , lib11 , lib12 , lib13 , lib14 , lib15 ) from my_lib import Object , Object2 , Object3 print ( \"Hey\" ) print ( \"yo\" ) Installing isort Installing isort is as simple as: pip install isort Install isort with requirements.txt support: pip install isort [ requirements ] Install isort with Pipfile support: pip install isort [ pipfile ] Install isort with both formats support: pip install isort [ requirements,pipfile ] Using isort From the command line : isort mypythonfile.py mypythonfile2.py or recursively: isort -rc . which is equivalent to: isort **/*.py or to see the proposed changes without applying them: isort mypythonfile.py --diff Finally, to atomically run isort against a project, only applying changes if they don't introduce syntax errors do: isort -rc --atomic . (Note: this is disabled by default as it keeps isort from being able to run against code written using a different version of Python) From within Python : from isort import SortImports SortImports ( \"pythonfile.py\" ) or: from isort import SortImports new_contents = SortImports ( file_contents = old_contents ) .output From within Kate: ctrl+ [ or: menu > Python > Sort Imports Installing isort's Kate plugin For KDE 4.13+ / Pate 2.0+: wget https://raw.github.com/timothycrosley/isort/master/kate_plugin/isort_plugin.py --output-document ~/.kde/share/apps/kate/pate/isort_plugin.py wget https://raw.github.com/timothycrosley/isort/master/kate_plugin/isort_plugin_ui.rc --output-document ~/.kde/share/apps/kate/pate/isort_plugin_ui.rc wget https://raw.github.com/timothycrosley/isort/master/kate_plugin/katepart_isort.desktop --output-document ~/.kde/share/kde4/services/katepart_isort.desktop For all older versions: wget https://raw.github.com/timothycrosley/isort/master/kate_plugin/isort_plugin_old.py --output-document ~/.kde/share/apps/kate/pate/isort_plugin.py You will then need to restart kate and enable Python Plugins as well as the isort plugin itself. Installing isort's for your preferred text editor Several plugins have been written that enable to use isort from within a variety of text-editors. You can find a full list of them on the isort wiki . Additionally, I will enthusiastically accept pull requests that include plugins for other text editors and add documentation for them as I am notified. How does isort work? isort parses specified files for global level import lines (imports outside of try / except blocks, functions, etc..) and puts them all at the top of the file grouped together by the type of import: Future Python Standard Library Third Party Current Python Project Explicitly Local (. before import, as in: from . import x ) Custom Separate Sections (Defined by forced_separate list in configuration file) Custom Sections (Defined by sections list in configuration file) Inside of each section the imports are sorted alphabetically. isort automatically removes duplicate python imports, and wraps long from imports to the specified line length (defaults to 79). When will isort not work? If you ever have the situation where you need to have a try / except block in the middle of top-level imports or if your import order is directly linked to precedence. For example: a common practice in Django settings files is importing * from various settings files to form a new settings file. In this case if any of the imports change order you are changing the settings definition itself. However, you can configure isort to skip over just these files - or even to force certain imports to the top. Configuring isort If you find the default isort settings do not work well for your project, isort provides several ways to adjust the behavior. To configure isort for a single user create a ~/.isort.cfg or $XDG_CONFIG_HOME/isort.cfg file: [settings] line_length = 120 force_to_top = file1.py,file2.py skip = file3.py,file4.py known_future_library = future,pies known_standard_library = std,std2 known_third_party = randomthirdparty known_first_party = mylib1,mylib2 indent = ' ' multi_line_output = 3 length_sort = 1 forced_separate = django.contrib,django.utils default_section = FIRSTPARTY no_lines_before = LOCALFOLDER Additionally, you can specify project level configuration simply by placing a .isort.cfg file at the root of your project. isort will look up to 25 directories up, from the file it is ran against, to find a project specific configuration. Or, if you prefer, you can add an isort or tool:isort section to your project's setup.cfg or tox.ini file with any desired settings. You can also add your desired settings under a [tool.isort] section in your pyproject.toml file. You can then override any of these settings by using command line arguments, or by passing in override values to the SortImports class. Finally, as of version 3.0 isort supports editorconfig files using the standard syntax defined here: https://editorconfig.org/ Meaning you place any standard isort configuration parameters within a .editorconfig file under the *.py section and they will be honored. For a full list of isort settings and their meanings take a look at the isort wiki . Multi line output modes You will notice above the \\\"multi_line_output\\\" setting. This setting defines how from imports wrap when they extend past the line_length limit and has 6 possible settings: 0 - Grid from third_party import ( lib1 , lib2 , lib3 , lib4 , lib5 , ... ) 1 - Vertical from third_party import ( lib1 , lib2 , lib3 lib4 , lib5 , ... ) 2 - Hanging Indent from third_party import \\ lib1 , lib2 , lib3 , \\ lib4 , lib5 , lib6 3 - Vertical Hanging Indent from third_party import ( lib1 , lib2 , lib3 , lib4 , ) 4 - Hanging Grid from third_party import ( lib1 , lib2 , lib3 , lib4 , lib5 , ... ) 5 - Hanging Grid Grouped from third_party import ( lib1 , lib2 , lib3 , lib4 , lib5 , ... ) 6 - Hanging Grid Grouped, No Trailing Comma In Mode 5 isort leaves a single extra space to maintain consistency of output when a comma is added at the end. Mode 6 is the same - except that no extra space is maintained leading to the possibility of lines one character longer. You can enforce a trailing comma by using this in conjunction with -tc or include_trailing_comma: True . from third_party import ( lib1 , lib2 , lib3 , lib4 , lib5 ) 7 - NOQA from third_party import lib1 , lib2 , lib3 , ... # NOQA Alternatively, you can set force_single_line to True ( -sl on the command line) and every import will appear on its own line: from third_party import lib1 from third_party import lib2 from third_party import lib3 ... Note: to change the how constant indents appear - simply change the indent property with the following accepted formats: Number of spaces you would like. For example: 4 would cause standard 4 space indentation. Tab A verbatim string with quotes around it. For example: \" \" is equivalent to 4. For the import styles that use parentheses, you can control whether or not to include a trailing comma after the last import with the include_trailing_comma option (defaults to False ). Intelligently Balanced Multi-line Imports As of isort 3.1.0 support for balanced multi-line imports has been added. With this enabled isort will dynamically change the import length to the one that produces the most balanced grid, while staying below the maximum import length defined. Example: from __future__ import ( absolute_import , division , print_function , unicode_literals ) Will be produced instead of: from __future__ import ( absolute_import , division , print_function , unicode_literals ) To enable this set balanced_wrapping to True in your config or pass the -e option into the command line utility. Custom Sections and Ordering You can change the section order with sections option from the default of: FUTURE,STDLIB,THIRDPARTY,FIRSTPARTY,LOCALFOLDER to your preference: sections = FUTURE,STDLIB,FIRSTPARTY,THIRDPARTY,LOCALFOLDER You also can define your own sections and their order. Example: known_django = django known_pandas = pandas,numpy sections = FUTURE,STDLIB,DJANGO,THIRDPARTY,PANDAS,FIRSTPARTY,LOCALFOLDER would create two new sections with the specified known modules. The no_lines_before option will prevent the listed sections from being split from the previous section by an empty line. Example: sections = FUTURE,STDLIB,THIRDPARTY,FIRSTPARTY,LOCALFOLDER no_lines_before = LOCALFOLDER would produce a section with both FIRSTPARTY and LOCALFOLDER modules combined. Auto-comment import sections Some projects prefer to have import sections uniquely titled to aid in identifying the sections quickly when visually scanning. isort can automate this as well. To do this simply set the import_heading_{section_name} setting for each section you wish to have auto commented - to the desired comment. For Example: import_heading_stdlib = Standard Library import_heading_firstparty = My Stuff Would lead to output looking like the following: # Standard Library import os import sys import django.settings # My Stuff import myproject.test Ordering by import length isort also makes it easy to sort your imports by length, simply by setting the length_sort option to True . This will result in the following output style: from evn.util import ( Pool , Dict , Options , Constant , DecayDict , UnexpectedCodePath , ) It is also possible to opt-in to sorting imports by length for only specific sections by using length_sort_ followed by the section name as a configuration item, e.g.: length_sort_stdlib = 1 Skip processing of imports (outside of configuration) To make isort ignore a single import simply add a comment at the end of the import line containing the text isort:skip : import module # isort:skip or: from xyz import ( abc , # isort:skip yo , hey ) To make isort skip an entire file simply add isort:skip_file to the module's doc string: \"\"\" my_module.py Best module ever isort:skip_file \"\"\" import b import a Adding an import to multiple files isort makes it easy to add an import statement across multiple files, while being assured it's correctly placed. From the command line: isort -a \"from __future__ import print_function\" *.py from within Kate: ctrl + ] or: menu > Python > Add Import Removing an import from multiple files isort also makes it easy to remove an import from multiple files, without having to be concerned with how it was originally formatted. From the command line: isort -rm \"os.system\" *.py from within Kate: ctrl + shift + ] or: menu > Python > Remove Import Using isort to verify code The --check-only option isort can also be used to used to verify that code is correctly formatted by running it with -c . Any files that contain incorrectly sorted and/or formatted imports will be outputted to stderr . isort **/*.py -c -vb SUCCESS: /home/timothy/Projects/Open_Source/isort/isort_kate_plugin.py Everything Looks Good! ERROR: /home/timothy/Projects/Open_Source/isort/isort/isort.py Imports are incorrectly sorted. One great place this can be used is with a pre-commit git hook, such as this one by \\@acdha: https://gist.github.com/acdha/8717683 This can help to ensure a certain level of code quality throughout a project. Git hook isort provides a hook function that can be integrated into your Git pre-commit script to check Python code before committing. To cause the commit to fail if there are isort errors (strict mode), include the following in .git/hooks/pre-commit : #!/usr/bin/env python import sys from isort.hooks import git_hook sys . exit ( git_hook ( strict = True , modify = True )) If you just want to display warnings, but allow the commit to happen anyway, call git_hook without the strict parameter. If you want to display warnings, but not also fix the code, call git_hook without the modify parameter. Setuptools integration Upon installation, isort enables a setuptools command that checks Python files declared by your project. Running python setup.py isort on the command line will check the files listed in your py_modules and packages . If any warning is found, the command will exit with an error code: $ python setup.py isort Also, to allow users to be able to use the command without having to install isort themselves, add isort to the setup_requires of your setup() like so: setup ( name = \"project\" , packages = [ \"project\" ], setup_requires = [ \"isort\" ] ) Security contact information ========== To report a security vulnerability, please use the Tidelift security contact . Tidelift will coordinate the fix and disclosure. Why isort? isort simply stands for import sort. It was originally called \"sortImports\" however I got tired of typing the extra characters and came to the realization camelCase is not pythonic. I wrote isort because in an organization I used to work in the manager came in one day and decided all code must have alphabetically sorted imports. The code base was huge - and he meant for us to do it by hand. However, being a programmer - I\\'m too lazy to spend 8 hours mindlessly performing a function, but not too lazy to spend 16 hours automating it. I was given permission to open source sortImports and here we are :) Thanks and I hope you find isort useful! ~Timothy Crosley","title":"Home"},{"location":"#installing-isort","text":"Installing isort is as simple as: pip install isort Install isort with requirements.txt support: pip install isort [ requirements ] Install isort with Pipfile support: pip install isort [ pipfile ] Install isort with both formats support: pip install isort [ requirements,pipfile ]","title":"Installing isort"},{"location":"#using-isort","text":"From the command line : isort mypythonfile.py mypythonfile2.py or recursively: isort -rc . which is equivalent to: isort **/*.py or to see the proposed changes without applying them: isort mypythonfile.py --diff Finally, to atomically run isort against a project, only applying changes if they don't introduce syntax errors do: isort -rc --atomic . (Note: this is disabled by default as it keeps isort from being able to run against code written using a different version of Python) From within Python : from isort import SortImports SortImports ( \"pythonfile.py\" ) or: from isort import SortImports new_contents = SortImports ( file_contents = old_contents ) .output From within Kate: ctrl+ [ or: menu > Python > Sort Imports","title":"Using isort"},{"location":"#installing-isorts-kate-plugin","text":"For KDE 4.13+ / Pate 2.0+: wget https://raw.github.com/timothycrosley/isort/master/kate_plugin/isort_plugin.py --output-document ~/.kde/share/apps/kate/pate/isort_plugin.py wget https://raw.github.com/timothycrosley/isort/master/kate_plugin/isort_plugin_ui.rc --output-document ~/.kde/share/apps/kate/pate/isort_plugin_ui.rc wget https://raw.github.com/timothycrosley/isort/master/kate_plugin/katepart_isort.desktop --output-document ~/.kde/share/kde4/services/katepart_isort.desktop For all older versions: wget https://raw.github.com/timothycrosley/isort/master/kate_plugin/isort_plugin_old.py --output-document ~/.kde/share/apps/kate/pate/isort_plugin.py You will then need to restart kate and enable Python Plugins as well as the isort plugin itself.","title":"Installing isort's Kate plugin"},{"location":"#installing-isorts-for-your-preferred-text-editor","text":"Several plugins have been written that enable to use isort from within a variety of text-editors. You can find a full list of them on the isort wiki . Additionally, I will enthusiastically accept pull requests that include plugins for other text editors and add documentation for them as I am notified.","title":"Installing isort's for your preferred text editor"},{"location":"#how-does-isort-work","text":"isort parses specified files for global level import lines (imports outside of try / except blocks, functions, etc..) and puts them all at the top of the file grouped together by the type of import: Future Python Standard Library Third Party Current Python Project Explicitly Local (. before import, as in: from . import x ) Custom Separate Sections (Defined by forced_separate list in configuration file) Custom Sections (Defined by sections list in configuration file) Inside of each section the imports are sorted alphabetically. isort automatically removes duplicate python imports, and wraps long from imports to the specified line length (defaults to 79).","title":"How does isort work?"},{"location":"#when-will-isort-not-work","text":"If you ever have the situation where you need to have a try / except block in the middle of top-level imports or if your import order is directly linked to precedence. For example: a common practice in Django settings files is importing * from various settings files to form a new settings file. In this case if any of the imports change order you are changing the settings definition itself. However, you can configure isort to skip over just these files - or even to force certain imports to the top.","title":"When will isort not work?"},{"location":"#configuring-isort","text":"If you find the default isort settings do not work well for your project, isort provides several ways to adjust the behavior. To configure isort for a single user create a ~/.isort.cfg or $XDG_CONFIG_HOME/isort.cfg file: [settings] line_length = 120 force_to_top = file1.py,file2.py skip = file3.py,file4.py known_future_library = future,pies known_standard_library = std,std2 known_third_party = randomthirdparty known_first_party = mylib1,mylib2 indent = ' ' multi_line_output = 3 length_sort = 1 forced_separate = django.contrib,django.utils default_section = FIRSTPARTY no_lines_before = LOCALFOLDER Additionally, you can specify project level configuration simply by placing a .isort.cfg file at the root of your project. isort will look up to 25 directories up, from the file it is ran against, to find a project specific configuration. Or, if you prefer, you can add an isort or tool:isort section to your project's setup.cfg or tox.ini file with any desired settings. You can also add your desired settings under a [tool.isort] section in your pyproject.toml file. You can then override any of these settings by using command line arguments, or by passing in override values to the SortImports class. Finally, as of version 3.0 isort supports editorconfig files using the standard syntax defined here: https://editorconfig.org/ Meaning you place any standard isort configuration parameters within a .editorconfig file under the *.py section and they will be honored. For a full list of isort settings and their meanings take a look at the isort wiki .","title":"Configuring isort"},{"location":"#multi-line-output-modes","text":"You will notice above the \\\"multi_line_output\\\" setting. This setting defines how from imports wrap when they extend past the line_length limit and has 6 possible settings: 0 - Grid from third_party import ( lib1 , lib2 , lib3 , lib4 , lib5 , ... ) 1 - Vertical from third_party import ( lib1 , lib2 , lib3 lib4 , lib5 , ... ) 2 - Hanging Indent from third_party import \\ lib1 , lib2 , lib3 , \\ lib4 , lib5 , lib6 3 - Vertical Hanging Indent from third_party import ( lib1 , lib2 , lib3 , lib4 , ) 4 - Hanging Grid from third_party import ( lib1 , lib2 , lib3 , lib4 , lib5 , ... ) 5 - Hanging Grid Grouped from third_party import ( lib1 , lib2 , lib3 , lib4 , lib5 , ... ) 6 - Hanging Grid Grouped, No Trailing Comma In Mode 5 isort leaves a single extra space to maintain consistency of output when a comma is added at the end. Mode 6 is the same - except that no extra space is maintained leading to the possibility of lines one character longer. You can enforce a trailing comma by using this in conjunction with -tc or include_trailing_comma: True . from third_party import ( lib1 , lib2 , lib3 , lib4 , lib5 ) 7 - NOQA from third_party import lib1 , lib2 , lib3 , ... # NOQA Alternatively, you can set force_single_line to True ( -sl on the command line) and every import will appear on its own line: from third_party import lib1 from third_party import lib2 from third_party import lib3 ... Note: to change the how constant indents appear - simply change the indent property with the following accepted formats: Number of spaces you would like. For example: 4 would cause standard 4 space indentation. Tab A verbatim string with quotes around it. For example: \" \" is equivalent to 4. For the import styles that use parentheses, you can control whether or not to include a trailing comma after the last import with the include_trailing_comma option (defaults to False ).","title":"Multi line output modes"},{"location":"#intelligently-balanced-multi-line-imports","text":"As of isort 3.1.0 support for balanced multi-line imports has been added. With this enabled isort will dynamically change the import length to the one that produces the most balanced grid, while staying below the maximum import length defined. Example: from __future__ import ( absolute_import , division , print_function , unicode_literals ) Will be produced instead of: from __future__ import ( absolute_import , division , print_function , unicode_literals ) To enable this set balanced_wrapping to True in your config or pass the -e option into the command line utility.","title":"Intelligently Balanced Multi-line Imports"},{"location":"#custom-sections-and-ordering","text":"You can change the section order with sections option from the default of: FUTURE,STDLIB,THIRDPARTY,FIRSTPARTY,LOCALFOLDER to your preference: sections = FUTURE,STDLIB,FIRSTPARTY,THIRDPARTY,LOCALFOLDER You also can define your own sections and their order. Example: known_django = django known_pandas = pandas,numpy sections = FUTURE,STDLIB,DJANGO,THIRDPARTY,PANDAS,FIRSTPARTY,LOCALFOLDER would create two new sections with the specified known modules. The no_lines_before option will prevent the listed sections from being split from the previous section by an empty line. Example: sections = FUTURE,STDLIB,THIRDPARTY,FIRSTPARTY,LOCALFOLDER no_lines_before = LOCALFOLDER would produce a section with both FIRSTPARTY and LOCALFOLDER modules combined.","title":"Custom Sections and Ordering"},{"location":"#auto-comment-import-sections","text":"Some projects prefer to have import sections uniquely titled to aid in identifying the sections quickly when visually scanning. isort can automate this as well. To do this simply set the import_heading_{section_name} setting for each section you wish to have auto commented - to the desired comment. For Example: import_heading_stdlib = Standard Library import_heading_firstparty = My Stuff Would lead to output looking like the following: # Standard Library import os import sys import django.settings # My Stuff import myproject.test","title":"Auto-comment import sections"},{"location":"#ordering-by-import-length","text":"isort also makes it easy to sort your imports by length, simply by setting the length_sort option to True . This will result in the following output style: from evn.util import ( Pool , Dict , Options , Constant , DecayDict , UnexpectedCodePath , ) It is also possible to opt-in to sorting imports by length for only specific sections by using length_sort_ followed by the section name as a configuration item, e.g.: length_sort_stdlib = 1","title":"Ordering by import length"},{"location":"#skip-processing-of-imports-outside-of-configuration","text":"To make isort ignore a single import simply add a comment at the end of the import line containing the text isort:skip : import module # isort:skip or: from xyz import ( abc , # isort:skip yo , hey ) To make isort skip an entire file simply add isort:skip_file to the module's doc string: \"\"\" my_module.py Best module ever isort:skip_file \"\"\" import b import a","title":"Skip processing of imports (outside of configuration)"},{"location":"#adding-an-import-to-multiple-files","text":"isort makes it easy to add an import statement across multiple files, while being assured it's correctly placed. From the command line: isort -a \"from __future__ import print_function\" *.py from within Kate: ctrl + ] or: menu > Python > Add Import","title":"Adding an import to multiple files"},{"location":"#removing-an-import-from-multiple-files","text":"isort also makes it easy to remove an import from multiple files, without having to be concerned with how it was originally formatted. From the command line: isort -rm \"os.system\" *.py from within Kate: ctrl + shift + ] or: menu > Python > Remove Import","title":"Removing an import from multiple files"},{"location":"#using-isort-to-verify-code","text":"","title":"Using isort to verify code"},{"location":"#the-check-only-option","text":"isort can also be used to used to verify that code is correctly formatted by running it with -c . Any files that contain incorrectly sorted and/or formatted imports will be outputted to stderr . isort **/*.py -c -vb SUCCESS: /home/timothy/Projects/Open_Source/isort/isort_kate_plugin.py Everything Looks Good! ERROR: /home/timothy/Projects/Open_Source/isort/isort/isort.py Imports are incorrectly sorted. One great place this can be used is with a pre-commit git hook, such as this one by \\@acdha: https://gist.github.com/acdha/8717683 This can help to ensure a certain level of code quality throughout a project.","title":"The --check-only option"},{"location":"#git-hook","text":"isort provides a hook function that can be integrated into your Git pre-commit script to check Python code before committing. To cause the commit to fail if there are isort errors (strict mode), include the following in .git/hooks/pre-commit : #!/usr/bin/env python import sys from isort.hooks import git_hook sys . exit ( git_hook ( strict = True , modify = True )) If you just want to display warnings, but allow the commit to happen anyway, call git_hook without the strict parameter. If you want to display warnings, but not also fix the code, call git_hook without the modify parameter.","title":"Git hook"},{"location":"#setuptools-integration","text":"Upon installation, isort enables a setuptools command that checks Python files declared by your project. Running python setup.py isort on the command line will check the files listed in your py_modules and packages . If any warning is found, the command will exit with an error code: $ python setup.py isort Also, to allow users to be able to use the command without having to install isort themselves, add isort to the setup_requires of your setup() like so: setup ( name = \"project\" , packages = [ \"project\" ], setup_requires = [ \"isort\" ] ) Security contact information ========== To report a security vulnerability, please use the Tidelift security contact . Tidelift will coordinate the fix and disclosure.","title":"Setuptools integration"},{"location":"#why-isort","text":"isort simply stands for import sort. It was originally called \"sortImports\" however I got tired of typing the extra characters and came to the realization camelCase is not pythonic. I wrote isort because in an organization I used to work in the manager came in one day and decided all code must have alphabetically sorted imports. The code base was huge - and he meant for us to do it by hand. However, being a programmer - I\\'m too lazy to spend 8 hours mindlessly performing a function, but not too lazy to spend 16 hours automating it. I was given permission to open source sortImports and here we are :) Thanks and I hope you find isort useful! ~Timothy Crosley","title":"Why isort?"},{"location":"CHANGELOG/","text":"Changelog 5.0.0 UNRELEASED Breaking changes: - isort now requires Python 3.5+ to run but continues to support formatting Python 2 code. - isort deprecates official support for Python 3.4, removing modules only in this release from known_standard_library: - user Internal: - isort now utilizes mypy and typing to filter out typing related issues before deployment Planned: - profile support for common project types (black, django, google, etc) 4.3.21 - June 25, 2019 - hot fix release Fixed issue #957 - Long aliases and use_parentheses generates invalid syntax 4.3.20 - May 14, 2019 - hot fix release Fixed issue #948 - Pipe redirection broken on Python2.7 4.3.19 - May 12, 2019 - hot fix release Fixed issue #942 - correctly handle pyi (Python Template Files) to match black output 4.3.18 - May 1, 2019 - hot fix release Fixed an issue with parsing files that contain unicode characters in Python 2 Fixed issue #924 - Pulling in pip internals causes depreciation warning Fixed issue #938 - Providing a way to filter explicitly passed in files via configuration settings ( --filter-files ) Improved interoperability with toml configuration files 4.3.17 - April 7, 2019 - hot fix release Fixed issue #905 & #919: Import section headers behaving strangely 4.3.16 - March 23, 2019 - hot fix release Fixed issue #909 - skip and skip-glob are not enforced when using settings-path. Fixed issue #907 - appdirs optional requirement does not correctly specify version Fixed issue #902 - Too broad warning about missing toml package Fixed issue #778 - remove user from known standard library as it's no longer in any supported Python version. 4.3.15 - March 10, 2019 - hot fix release Fixed a regression with handling streaming input from pipes (Issue #895) Fixed handling of \\x0c whitespace character (Issue #811) Improved CLI documentation 4.3.14 - March 9, 2019 - hot fix release Fixed a regression with /directory/ .py style patterns 4.3.13 - March 8, 2019 - hot fix release Fixed the inability to accurately determine import section when a mix of conda and virtual environments are used. Fixed some output being printed even when --quiet mode is enabled. Fixed issue #890 interoperability with PyCharm by allowing case sensitive non type grouped sorting. Fixed issue #889 under some circumstances isort will incorrectly add a new line at the beginning of a file. Fixed issue #885 many files not being skipped according to set skip settings. Fixed issue #842 streaming encoding improvements. 4.3.12 - March 6, 2019 - hot fix release Fix error caused when virtual environment not detected 4.3.11 - March 6, 2019 - hot fix release Fixed issue #876: confused by symlinks pointing to virtualenv gives FIRSTPARTY not THIRDPARTY Fixed issue #873: current version skips every file on travis Additional caching to reduce performance regression introduced in 4.3.5 4.3.10 - March 2, 2019 - hot fix release Fixed Windows incompatibilities (Issue #835) Fixed relative import sorting bug (Issue #417) Fixed \"no_lines_before\" to also be respected from previous empty sections. Fixed slow-down introduced by finders mechanism by adding a LRU cache (issue #848) Fixed issue #842 default encoding not-set in Python2 Restored Windows automated testing Added Mac automated testing 4.3.9 - February 25, 2019 - hot fix release Fixed a bug that led to an incompatibility with black: #831 4.3.8 - February 25, 2019 - hot fix release Fixed a bug that led to the recursive option not always been available from the command line. 4.3.7 - February 25, 2019 - hot fix release Expands the finder failsafe to occur on the creation of the finder objects. 4.3.6 - February 24, 2019 - hot fix release Fixes a fatal error that occurs if a single finder throws an exception. Important as we add more finders that utilize third party libraries. 4.3.5 - February 24, 2019 - last Python 2.7 Maintenance Release This is the final Python 2.x release of isort, and includes the following major changes: Potentially Interface Breaking: - The -r option for removing imports has been renamed -rm to avoid accidental deletions and confusion with the -rc recursive option. - __init__.py has been removed from the default ignore list. The default ignore list is now empty - with all items needing to be explicitly ignored. - Isort will now by default ignore .tox / venv folders in an effort to be \"safe\". You can disable this behaviour by setting the \"--unsafe\" flag, this is separate from any skip or not skip rules you may have in place. - Isort now allows for files missing closing newlines in whitespace check - distutils support has been removed to simplify setup.py New: - Official Python 3.7 Compatibility. - Support for using requirements files to auto determine third-paty section if pipreqs & requirementslib are installed. - Added support for using pyproject.toml if toml is installed. - Added support for XDG_HOME if appdirs is installed. - An option has been added to enable ignoring trailing comments ('ignore_comments') defaulting to False. - Added support to enable line length sorting for only specific sections - Added a correctly_sorted property on the SortsImport to enable more intuitive programmatic checking. Fixes: - Improved black compatibility. - Isort will now detect files in the CWD as first-party. - Fixed several cases where '-ns' or 'not_skip' was being incorrectly ignored. - Fixed sorting of relative path imports ('.', '..', '...', etc). - Fixed bugs caused by a failure to maintain order when loading iterables from config files. - Correctly handle CPython compiled imports and others that need EXT_SUFFIX to correctly identify. - Fixed handling of Symbolic Links to follow them when walking the path. - Fixed handling of relative known_paths. - Fixed lack of access to all wrap modes from the CLI. - Fixed handling of FIFO files. - Fixed a bug that could result in multiple imports being inserted on the same line. 4.3.4 - February 12, 2018 - hotfix release Fixed issue #671: isort is corrupting CRLF files 4.3.3 - Feburary 5, 2018 - hotfix release Fixed issue #665: Tabs turned into single spaces 4.3.2 - Feburary 4, 2018 - hotfix release Fixed issue #651: Add imports option is broken Fixed issue #662: An error generated by rewriting .imports to . imoprts 4.3.1 - Feburary 2, 2018 - hotfix release Fixed setup.py errors Fixed issue #654: Trailing comma count error Fixed issue #650: Wrong error message displayed 4.3.0 - January 31, 2018 Fixed #557: force_alphabetical_sort and force_sort_within_sections can now be utilized together without extra new lines Fix case-sensitive path existence check in Mac OS X Added --no-lines-before for more granular control over section output Fixed #493: Unwanted conversion to Windows line endings Fixed #590: Import as mucks with alphabetical sorting Implemented --version-number to retrieve just the version number without the isort logo Breaking changes Python 2.7+ only (dropped 2.6) allowing various code simplifications and improvements. 4.2.15 - June 6, 2017 - hotfix release IMPORTANT NOTE: This will be the last release with Python 2.6 support, subsequent releases will be 2.7+ only - Fixed certain one line imports not being successfully wrapped 4.2.14 - June 5, 2017 - hotfix release Fixed #559 & #565: Added missing standard library imports 4.2.13 - June 2, 2017 - hotfix release Fixed #553: Check only and --diff now work together again 4.2.12 - June 1, 2017 - hotfix release Fixed wheel distribution bug 4.2.11 - June 1, 2017 - hotfix release Fixed #546: Can't select y/n/c after latest update Fixed #545: Incorrectly moves future imports above encoding comments 4.2.9 - June 1, 2017 - hotfix release Fixed #428: Check only modifies sorting Fixed #540: Not correctly identifying stdlib modules 4.2.8 - May 31, 2017 Added --virtual-env switch command line option Added --enforce-whitespace option to go along with --check-only for more exact checks (issue #423) Fixed imports with a tailing '\\' and no space in-between getting removed (issue #425) Fixed issue #299: long lines occasionally not wrapped Fixed issue #432: No longer add import inside class when class starts at top of file after encoding comment Fixed issue #440: Added missing --use-parentheses option to command line tool and documentation Fixed issue #496: import* imports now get successfully identified and reformatted instead of deleted Fixed issue #491: Non ending parentheses withing single line comments no longer cause formatting issues Fixed issue #471: Imports that wrap the maximum line length and contain comments on the last line are no longer rendered incorrectly Fixed issue #436: Force sort within section no longer rearranges comments Fixed issue #473: Force_to_top and force_sort_within_sections now work together Fixed issue #484 & #472: Consistent output with imports of same spelling but different case Fixed issue #433: No longer incorrectly add an extra new-line when comment between imports and function definition Fixed issue #419: Path specification for skipped paths is not Unix/Windows inter-operable. Breaking Changes: Fixed issue #511: All command line options with an underscore, have had the underscore replaced with a dash for consistency. This effects: multi-line, add-import, remove-import, force-adds, --force-single-line-imports, and length-sort. Replaced the --enforce-whitespace option with --ignore-whitespace to restore original behavior of strict whitespace by default 4.2.5 Fixed an issue that caused modules to inccorectly be matched as thirdparty when they simply had src in the leading path, even if they weren't withing $VIRTUALENV/src #414 4.2.4 Fixed an issue that caused module that contained functions before doc strings, to incorrectly place imports Fixed regression in how force_alphabetical_sort was being interpretted (issue #409) Fixed stray print statement printing skipped files (issue #411) Added option for forcing imports into a single bucket: no_sections Added option for new lines between import types (from, straight): lines_between_sections 4.2.3 Fixed a large number of priority bugs - bug fix only release 4.2.2 Give an error message when isort is unable to determine where to place a module Allow imports to be sorted by module, independent of import_type, when force_sort_within_sections option is set Fixed an issue that caused Python files with 2 top comments not to be sorted 4.2.1 Hot fix release to fix code error when skipping globs 4.2.0 Added option \"NOQA\" Do not wrap lines, but add a noqa statement at the end Added support for running isort recursively, simply with a standalone isort command Added support to run isort library as a module Added compatibility for Python 3.5 Fixed performance issue (#338) when running on project with lots of skipped directories Fixed issue #328: extra new can occasionally occur when using alphabetical-only sort Fixed custom sections parsing from config file (unicode string -> list) Updated pylama extension to the correct entry point Skip files even when file_contents is provided if they are explicitly in skip list Removed always showing isort banner, keeping it for when the version is requested, verbose is used, or show_logo setting is set. 4.1.2 Fixed issue #323: Accidental default configuration change introduced 4.1.1 Added support for partial file match skips (thanks to @Amwam) Added support for --quiet option to only show errors when running isort Fixed issue #316: isort added new lines incorrectly when a top-of line comment is present 4.1.0 Started keeping a log of all changes between releases Added the isort logo to the command line interface Added example usage gif to README Implemented issue #292: skip setting now supports glob patterns Implemented issue #271: Add option to sort imports purely alphabetically Implemented issue #301: Readme is now natively in RST format, making it easier for Python tooling to pick up Implemented pylama isort extension Fixed issue #260: # encoding lines at the top of the file are now correctly supported Fixed issue #284: Sticky comments above first import are now supported Fixed issue #310: Ensure comments don't get duplicated when reformatting imports Fixed issue #289: Sections order not being respected Fixed issue #296: Made it more clear how to set arguments more then once 4.0.0 Removed all external dependencies","title":"Changelog"},{"location":"CHANGELOG/#changelog","text":"","title":"Changelog"},{"location":"CHANGELOG/#500-unreleased","text":"Breaking changes: - isort now requires Python 3.5+ to run but continues to support formatting Python 2 code. - isort deprecates official support for Python 3.4, removing modules only in this release from known_standard_library: - user Internal: - isort now utilizes mypy and typing to filter out typing related issues before deployment Planned: - profile support for common project types (black, django, google, etc)","title":"5.0.0 UNRELEASED"},{"location":"CHANGELOG/#4321-june-25-2019-hot-fix-release","text":"Fixed issue #957 - Long aliases and use_parentheses generates invalid syntax","title":"4.3.21 - June 25, 2019 - hot fix release"},{"location":"CHANGELOG/#4320-may-14-2019-hot-fix-release","text":"Fixed issue #948 - Pipe redirection broken on Python2.7","title":"4.3.20 - May 14, 2019 - hot fix release"},{"location":"CHANGELOG/#4319-may-12-2019-hot-fix-release","text":"Fixed issue #942 - correctly handle pyi (Python Template Files) to match black output","title":"4.3.19 - May 12, 2019 - hot fix release"},{"location":"CHANGELOG/#4318-may-1-2019-hot-fix-release","text":"Fixed an issue with parsing files that contain unicode characters in Python 2 Fixed issue #924 - Pulling in pip internals causes depreciation warning Fixed issue #938 - Providing a way to filter explicitly passed in files via configuration settings ( --filter-files ) Improved interoperability with toml configuration files","title":"4.3.18 - May 1, 2019 - hot fix release"},{"location":"CHANGELOG/#4317-april-7-2019-hot-fix-release","text":"Fixed issue #905 & #919: Import section headers behaving strangely","title":"4.3.17 - April 7, 2019 - hot fix release"},{"location":"CHANGELOG/#4316-march-23-2019-hot-fix-release","text":"Fixed issue #909 - skip and skip-glob are not enforced when using settings-path. Fixed issue #907 - appdirs optional requirement does not correctly specify version Fixed issue #902 - Too broad warning about missing toml package Fixed issue #778 - remove user from known standard library as it's no longer in any supported Python version.","title":"4.3.16 - March 23, 2019 - hot fix release"},{"location":"CHANGELOG/#4315-march-10-2019-hot-fix-release","text":"Fixed a regression with handling streaming input from pipes (Issue #895) Fixed handling of \\x0c whitespace character (Issue #811) Improved CLI documentation","title":"4.3.15 - March 10, 2019 - hot fix release"},{"location":"CHANGELOG/#4314-march-9-2019-hot-fix-release","text":"Fixed a regression with /directory/ .py style patterns","title":"4.3.14 - March 9, 2019 - hot fix release"},{"location":"CHANGELOG/#4313-march-8-2019-hot-fix-release","text":"Fixed the inability to accurately determine import section when a mix of conda and virtual environments are used. Fixed some output being printed even when --quiet mode is enabled. Fixed issue #890 interoperability with PyCharm by allowing case sensitive non type grouped sorting. Fixed issue #889 under some circumstances isort will incorrectly add a new line at the beginning of a file. Fixed issue #885 many files not being skipped according to set skip settings. Fixed issue #842 streaming encoding improvements.","title":"4.3.13 - March 8, 2019 - hot fix release"},{"location":"CHANGELOG/#4312-march-6-2019-hot-fix-release","text":"Fix error caused when virtual environment not detected","title":"4.3.12 - March 6, 2019 - hot fix release"},{"location":"CHANGELOG/#4311-march-6-2019-hot-fix-release","text":"Fixed issue #876: confused by symlinks pointing to virtualenv gives FIRSTPARTY not THIRDPARTY Fixed issue #873: current version skips every file on travis Additional caching to reduce performance regression introduced in 4.3.5","title":"4.3.11 - March 6, 2019 - hot fix release"},{"location":"CHANGELOG/#4310-march-2-2019-hot-fix-release","text":"Fixed Windows incompatibilities (Issue #835) Fixed relative import sorting bug (Issue #417) Fixed \"no_lines_before\" to also be respected from previous empty sections. Fixed slow-down introduced by finders mechanism by adding a LRU cache (issue #848) Fixed issue #842 default encoding not-set in Python2 Restored Windows automated testing Added Mac automated testing","title":"4.3.10 - March 2, 2019 - hot fix release"},{"location":"CHANGELOG/#439-february-25-2019-hot-fix-release","text":"Fixed a bug that led to an incompatibility with black: #831","title":"4.3.9 - February 25, 2019 - hot fix release"},{"location":"CHANGELOG/#438-february-25-2019-hot-fix-release","text":"Fixed a bug that led to the recursive option not always been available from the command line.","title":"4.3.8 - February 25, 2019 - hot fix release"},{"location":"CHANGELOG/#437-february-25-2019-hot-fix-release","text":"Expands the finder failsafe to occur on the creation of the finder objects.","title":"4.3.7 - February 25, 2019 - hot fix release"},{"location":"CHANGELOG/#436-february-24-2019-hot-fix-release","text":"Fixes a fatal error that occurs if a single finder throws an exception. Important as we add more finders that utilize third party libraries.","title":"4.3.6 - February 24, 2019 - hot fix release"},{"location":"CHANGELOG/#435-february-24-2019-last-python-27-maintenance-release","text":"This is the final Python 2.x release of isort, and includes the following major changes: Potentially Interface Breaking: - The -r option for removing imports has been renamed -rm to avoid accidental deletions and confusion with the -rc recursive option. - __init__.py has been removed from the default ignore list. The default ignore list is now empty - with all items needing to be explicitly ignored. - Isort will now by default ignore .tox / venv folders in an effort to be \"safe\". You can disable this behaviour by setting the \"--unsafe\" flag, this is separate from any skip or not skip rules you may have in place. - Isort now allows for files missing closing newlines in whitespace check - distutils support has been removed to simplify setup.py New: - Official Python 3.7 Compatibility. - Support for using requirements files to auto determine third-paty section if pipreqs & requirementslib are installed. - Added support for using pyproject.toml if toml is installed. - Added support for XDG_HOME if appdirs is installed. - An option has been added to enable ignoring trailing comments ('ignore_comments') defaulting to False. - Added support to enable line length sorting for only specific sections - Added a correctly_sorted property on the SortsImport to enable more intuitive programmatic checking. Fixes: - Improved black compatibility. - Isort will now detect files in the CWD as first-party. - Fixed several cases where '-ns' or 'not_skip' was being incorrectly ignored. - Fixed sorting of relative path imports ('.', '..', '...', etc). - Fixed bugs caused by a failure to maintain order when loading iterables from config files. - Correctly handle CPython compiled imports and others that need EXT_SUFFIX to correctly identify. - Fixed handling of Symbolic Links to follow them when walking the path. - Fixed handling of relative known_paths. - Fixed lack of access to all wrap modes from the CLI. - Fixed handling of FIFO files. - Fixed a bug that could result in multiple imports being inserted on the same line.","title":"4.3.5 - February 24, 2019 - last Python 2.7 Maintenance Release"},{"location":"CHANGELOG/#434-february-12-2018-hotfix-release","text":"Fixed issue #671: isort is corrupting CRLF files","title":"4.3.4 - February 12, 2018 - hotfix release"},{"location":"CHANGELOG/#433-feburary-5-2018-hotfix-release","text":"Fixed issue #665: Tabs turned into single spaces","title":"4.3.3 - Feburary 5, 2018 - hotfix release"},{"location":"CHANGELOG/#432-feburary-4-2018-hotfix-release","text":"Fixed issue #651: Add imports option is broken Fixed issue #662: An error generated by rewriting .imports to . imoprts","title":"4.3.2 - Feburary 4, 2018 - hotfix release"},{"location":"CHANGELOG/#431-feburary-2-2018-hotfix-release","text":"Fixed setup.py errors Fixed issue #654: Trailing comma count error Fixed issue #650: Wrong error message displayed","title":"4.3.1 - Feburary 2, 2018 - hotfix release"},{"location":"CHANGELOG/#430-january-31-2018","text":"Fixed #557: force_alphabetical_sort and force_sort_within_sections can now be utilized together without extra new lines Fix case-sensitive path existence check in Mac OS X Added --no-lines-before for more granular control over section output Fixed #493: Unwanted conversion to Windows line endings Fixed #590: Import as mucks with alphabetical sorting Implemented --version-number to retrieve just the version number without the isort logo Breaking changes Python 2.7+ only (dropped 2.6) allowing various code simplifications and improvements.","title":"4.3.0 - January 31, 2018"},{"location":"CHANGELOG/#4215-june-6-2017-hotfix-release","text":"IMPORTANT NOTE: This will be the last release with Python 2.6 support, subsequent releases will be 2.7+ only - Fixed certain one line imports not being successfully wrapped","title":"4.2.15 - June 6, 2017 - hotfix release"},{"location":"CHANGELOG/#4214-june-5-2017-hotfix-release","text":"Fixed #559 & #565: Added missing standard library imports","title":"4.2.14 - June 5, 2017 - hotfix release"},{"location":"CHANGELOG/#4213-june-2-2017-hotfix-release","text":"Fixed #553: Check only and --diff now work together again","title":"4.2.13 - June 2, 2017 - hotfix release"},{"location":"CHANGELOG/#4212-june-1-2017-hotfix-release","text":"Fixed wheel distribution bug","title":"4.2.12 - June 1, 2017 - hotfix release"},{"location":"CHANGELOG/#4211-june-1-2017-hotfix-release","text":"Fixed #546: Can't select y/n/c after latest update Fixed #545: Incorrectly moves future imports above encoding comments","title":"4.2.11 - June 1, 2017 - hotfix release"},{"location":"CHANGELOG/#429-june-1-2017-hotfix-release","text":"Fixed #428: Check only modifies sorting Fixed #540: Not correctly identifying stdlib modules","title":"4.2.9 - June 1, 2017 - hotfix release"},{"location":"CHANGELOG/#428-may-31-2017","text":"Added --virtual-env switch command line option Added --enforce-whitespace option to go along with --check-only for more exact checks (issue #423) Fixed imports with a tailing '\\' and no space in-between getting removed (issue #425) Fixed issue #299: long lines occasionally not wrapped Fixed issue #432: No longer add import inside class when class starts at top of file after encoding comment Fixed issue #440: Added missing --use-parentheses option to command line tool and documentation Fixed issue #496: import* imports now get successfully identified and reformatted instead of deleted Fixed issue #491: Non ending parentheses withing single line comments no longer cause formatting issues Fixed issue #471: Imports that wrap the maximum line length and contain comments on the last line are no longer rendered incorrectly Fixed issue #436: Force sort within section no longer rearranges comments Fixed issue #473: Force_to_top and force_sort_within_sections now work together Fixed issue #484 & #472: Consistent output with imports of same spelling but different case Fixed issue #433: No longer incorrectly add an extra new-line when comment between imports and function definition Fixed issue #419: Path specification for skipped paths is not Unix/Windows inter-operable. Breaking Changes: Fixed issue #511: All command line options with an underscore, have had the underscore replaced with a dash for consistency. This effects: multi-line, add-import, remove-import, force-adds, --force-single-line-imports, and length-sort. Replaced the --enforce-whitespace option with --ignore-whitespace to restore original behavior of strict whitespace by default","title":"4.2.8 - May 31, 2017"},{"location":"CHANGELOG/#425","text":"Fixed an issue that caused modules to inccorectly be matched as thirdparty when they simply had src in the leading path, even if they weren't withing $VIRTUALENV/src #414","title":"4.2.5"},{"location":"CHANGELOG/#424","text":"Fixed an issue that caused module that contained functions before doc strings, to incorrectly place imports Fixed regression in how force_alphabetical_sort was being interpretted (issue #409) Fixed stray print statement printing skipped files (issue #411) Added option for forcing imports into a single bucket: no_sections Added option for new lines between import types (from, straight): lines_between_sections","title":"4.2.4"},{"location":"CHANGELOG/#423","text":"Fixed a large number of priority bugs - bug fix only release","title":"4.2.3"},{"location":"CHANGELOG/#422","text":"Give an error message when isort is unable to determine where to place a module Allow imports to be sorted by module, independent of import_type, when force_sort_within_sections option is set Fixed an issue that caused Python files with 2 top comments not to be sorted","title":"4.2.2"},{"location":"CHANGELOG/#421","text":"Hot fix release to fix code error when skipping globs","title":"4.2.1"},{"location":"CHANGELOG/#420","text":"Added option \"NOQA\" Do not wrap lines, but add a noqa statement at the end Added support for running isort recursively, simply with a standalone isort command Added support to run isort library as a module Added compatibility for Python 3.5 Fixed performance issue (#338) when running on project with lots of skipped directories Fixed issue #328: extra new can occasionally occur when using alphabetical-only sort Fixed custom sections parsing from config file (unicode string -> list) Updated pylama extension to the correct entry point Skip files even when file_contents is provided if they are explicitly in skip list Removed always showing isort banner, keeping it for when the version is requested, verbose is used, or show_logo setting is set.","title":"4.2.0"},{"location":"CHANGELOG/#412","text":"Fixed issue #323: Accidental default configuration change introduced","title":"4.1.2"},{"location":"CHANGELOG/#411","text":"Added support for partial file match skips (thanks to @Amwam) Added support for --quiet option to only show errors when running isort Fixed issue #316: isort added new lines incorrectly when a top-of line comment is present","title":"4.1.1"},{"location":"CHANGELOG/#410","text":"Started keeping a log of all changes between releases Added the isort logo to the command line interface Added example usage gif to README Implemented issue #292: skip setting now supports glob patterns Implemented issue #271: Add option to sort imports purely alphabetically Implemented issue #301: Readme is now natively in RST format, making it easier for Python tooling to pick up Implemented pylama isort extension Fixed issue #260: # encoding lines at the top of the file are now correctly supported Fixed issue #284: Sticky comments above first import are now supported Fixed issue #310: Ensure comments don't get duplicated when reformatting imports Fixed issue #289: Sections order not being respected Fixed issue #296: Made it more clear how to set arguments more then once","title":"4.1.0"},{"location":"CHANGELOG/#400","text":"Removed all external dependencies","title":"4.0.0"},{"location":"docs/contributing/1.-contributing-guide/","text":"Contributing to isort Looking for a useful open source project to contribute to? Want your contributions to be warmly welcomed and acknowledged? Welcome! You have found the right place. Getting isort set up for local development The first step when contributing to any project is getting it set up on your local machine. isort aims to make this as simple as possible. Account Requirements: A valid GitHub account Base System Requirements: Python3.6+ poetry bash or a bash compatible shell (should be auto-installed on Linux / Mac) Once you have verified that you system matches the base requirements you can start to get the project working by following these steps: Fork the project on GitHub . Clone your fork to your local file system: git clone https://github.com/$GITHUB_ACCOUNT/isort.git `cd isort poetry install Making a contribution Congrats! You're now ready to make a contribution! Use the following as a guide to help you reach a successful pull-request: Check the issues page on GitHub to see if the task you want to complete is listed there. If it's listed there, write a comment letting others know you are working on it. If it's not listed in GitHub issues, go ahead and log a new issue. Then add a comment letting everyone know you have it under control. If you're not sure if it's something that is good for the main isort project and want immediate feedback, you can discuss it here . Create an issue branch for your local work git checkout -b issue/$ISSUE-NUMBER . Do your magic here. Ensure your code matches the HOPE-8 Coding Standard used by the project. Submit a pull request to the main project repository via GitHub. Thanks for the contribution! It will quickly get reviewed, and, once accepted, will result in your name being added to the acknowledgments list :). Thank you! I can not tell you how thankful I am for the hard work done by isort contributors like you . Thank you! ~Timothy Crosley","title":"1. Contributing Guide"},{"location":"docs/contributing/1.-contributing-guide/#contributing-to-isort","text":"Looking for a useful open source project to contribute to? Want your contributions to be warmly welcomed and acknowledged? Welcome! You have found the right place.","title":"Contributing to isort"},{"location":"docs/contributing/1.-contributing-guide/#getting-isort-set-up-for-local-development","text":"The first step when contributing to any project is getting it set up on your local machine. isort aims to make this as simple as possible. Account Requirements: A valid GitHub account Base System Requirements: Python3.6+ poetry bash or a bash compatible shell (should be auto-installed on Linux / Mac) Once you have verified that you system matches the base requirements you can start to get the project working by following these steps: Fork the project on GitHub . Clone your fork to your local file system: git clone https://github.com/$GITHUB_ACCOUNT/isort.git `cd isort poetry install","title":"Getting isort set up for local development"},{"location":"docs/contributing/1.-contributing-guide/#making-a-contribution","text":"Congrats! You're now ready to make a contribution! Use the following as a guide to help you reach a successful pull-request: Check the issues page on GitHub to see if the task you want to complete is listed there. If it's listed there, write a comment letting others know you are working on it. If it's not listed in GitHub issues, go ahead and log a new issue. Then add a comment letting everyone know you have it under control. If you're not sure if it's something that is good for the main isort project and want immediate feedback, you can discuss it here . Create an issue branch for your local work git checkout -b issue/$ISSUE-NUMBER . Do your magic here. Ensure your code matches the HOPE-8 Coding Standard used by the project. Submit a pull request to the main project repository via GitHub. Thanks for the contribution! It will quickly get reviewed, and, once accepted, will result in your name being added to the acknowledgments list :).","title":"Making a contribution"},{"location":"docs/contributing/1.-contributing-guide/#thank-you","text":"I can not tell you how thankful I am for the hard work done by isort contributors like you . Thank you! ~Timothy Crosley","title":"Thank you!"},{"location":"docs/contributing/2.-coding-standard/","text":"HOPE 8 -- Style Guide for Hug Code HOPE: 8 Title: Style Guide for Hug Code Author(s): Timothy Crosley timothy.crosley@gmail.com Status: Active Type: Process Created: 19-May-2019 Updated: 17-August-2019 Introduction This document gives coding conventions for the Hug code comprising the Hug core as well as all official interfaces, extensions, and plugins for the framework. Optionally, projects that use Hug are encouraged to follow this HOPE and link to it as a reference. PEP 8 Foundation All guidelines in this document are in addition to those defined in Python's PEP 8 and PEP 257 guidelines. Line Length Too short of lines discourage descriptive variable names where they otherwise make sense. Too long of lines reduce overall readability and make it hard to compare 2 files side by side. There is no perfect number: but for Hug, we've decided to cap the lines at 100 characters. Descriptive Variable names Naming things is hard. Hug has a few strict guidelines on the usage of variable names, which hopefully will reduce some of the guesswork: - No one character variable names. - Except for x, y, and z as coordinates. - It's not okay to override built-in functions. - Except for id . Guido himself thought that shouldn't have been moved to the system module. It's too commonly used, and alternatives feel very artificial. - Avoid Acronyms, Abbreviations, or any other short forms - unless they are almost universally understand. Adding new modules New modules added to the a project that follows the HOPE-8 standard should all live directly within the base PROJECT_NAME/ directory without nesting. If the modules are meant only for internal use within the project, they should be prefixed with a leading underscore. For example, def _internal_function. Modules should contain a docstring at the top that gives a general explanation of the purpose and then restates the project's use of the MIT license. There should be a tests/test_$MODULE_NAME.py file created to correspond to every new module that contains test coverage for the module. Ideally, tests should be 1:1 (one test object per code object, one test method per code method) to the extent cleanly possible. Automated Code Cleaners All code submitted to Hug should be formatted using Black and isort. Black should be run with the line length set to 100, and isort with Black compatible settings in place. Automated Code Linting All code submitted to hug should run through the following tools: Black and isort verification. Flake8 flake8-bugbear Bandit pep8-naming vulture safety","title":"2. Coding Standard"},{"location":"docs/contributing/2.-coding-standard/#hope-8-style-guide-for-hug-code","text":"HOPE: 8 Title: Style Guide for Hug Code Author(s): Timothy Crosley timothy.crosley@gmail.com Status: Active Type: Process Created: 19-May-2019 Updated: 17-August-2019","title":"HOPE 8 -- Style Guide for Hug Code"},{"location":"docs/contributing/2.-coding-standard/#introduction","text":"This document gives coding conventions for the Hug code comprising the Hug core as well as all official interfaces, extensions, and plugins for the framework. Optionally, projects that use Hug are encouraged to follow this HOPE and link to it as a reference.","title":"Introduction"},{"location":"docs/contributing/2.-coding-standard/#pep-8-foundation","text":"All guidelines in this document are in addition to those defined in Python's PEP 8 and PEP 257 guidelines.","title":"PEP 8 Foundation"},{"location":"docs/contributing/2.-coding-standard/#line-length","text":"Too short of lines discourage descriptive variable names where they otherwise make sense. Too long of lines reduce overall readability and make it hard to compare 2 files side by side. There is no perfect number: but for Hug, we've decided to cap the lines at 100 characters.","title":"Line Length"},{"location":"docs/contributing/2.-coding-standard/#descriptive-variable-names","text":"Naming things is hard. Hug has a few strict guidelines on the usage of variable names, which hopefully will reduce some of the guesswork: - No one character variable names. - Except for x, y, and z as coordinates. - It's not okay to override built-in functions. - Except for id . Guido himself thought that shouldn't have been moved to the system module. It's too commonly used, and alternatives feel very artificial. - Avoid Acronyms, Abbreviations, or any other short forms - unless they are almost universally understand.","title":"Descriptive Variable names"},{"location":"docs/contributing/2.-coding-standard/#adding-new-modules","text":"New modules added to the a project that follows the HOPE-8 standard should all live directly within the base PROJECT_NAME/ directory without nesting. If the modules are meant only for internal use within the project, they should be prefixed with a leading underscore. For example, def _internal_function. Modules should contain a docstring at the top that gives a general explanation of the purpose and then restates the project's use of the MIT license. There should be a tests/test_$MODULE_NAME.py file created to correspond to every new module that contains test coverage for the module. Ideally, tests should be 1:1 (one test object per code object, one test method per code method) to the extent cleanly possible.","title":"Adding new modules"},{"location":"docs/contributing/2.-coding-standard/#automated-code-cleaners","text":"All code submitted to Hug should be formatted using Black and isort. Black should be run with the line length set to 100, and isort with Black compatible settings in place.","title":"Automated Code Cleaners"},{"location":"docs/contributing/2.-coding-standard/#automated-code-linting","text":"All code submitted to hug should run through the following tools: Black and isort verification. Flake8 flake8-bugbear Bandit pep8-naming vulture safety","title":"Automated Code Linting"},{"location":"docs/contributing/3.-code-of-conduct/","text":"HOPE 11 -- Code of Conduct HOPE: 11 Title: Code of Conduct Author(s): Timothy Crosley timothy.crosley@gmail.com Status: Active Type: Process Created: 17-August-2019 Updated: 17-August-2019 Abstract Defines the Code of Conduct for Hug and all related projects. Our Pledge In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation. Our Standards Examples of behavior that contributes to creating a positive environment include: Using welcoming and inclusive language Being respectful of differing viewpoints and experiences Gracefully accepting constructive criticism Focusing on what is best for the community Showing empathy towards other community members Examples of unacceptable behavior by participants include: The use of sexualized language or imagery and unwelcome sexual attention or advances Trolling, insulting/derogatory comments, and personal or political attacks Public or private harassment Publishing others' private information, such as a physical or electronic address, without explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting Our Responsibilities Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior. Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful. Scope This Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers. Enforcement Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting timothy.crosley@gmail.com . All complaints will be reviewed and investigated and will result in a response that is deemed necessary and appropriate to the circumstances. Confidentiality will be maintained with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately. Project maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership. Attribution This Code of Conduct is adapted from the [Contributor Covenant][https://www.contributor-covenant.org], version 1.4, available at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html For answers to common questions about this code of conduct, see https://www.contributor-covenant.org/faq","title":"3. Code Of Conduct"},{"location":"docs/contributing/3.-code-of-conduct/#hope-11-code-of-conduct","text":"HOPE: 11 Title: Code of Conduct Author(s): Timothy Crosley timothy.crosley@gmail.com Status: Active Type: Process Created: 17-August-2019 Updated: 17-August-2019","title":"HOPE 11 -- Code of Conduct"},{"location":"docs/contributing/3.-code-of-conduct/#abstract","text":"Defines the Code of Conduct for Hug and all related projects.","title":"Abstract"},{"location":"docs/contributing/3.-code-of-conduct/#our-pledge","text":"In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.","title":"Our Pledge"},{"location":"docs/contributing/3.-code-of-conduct/#our-standards","text":"Examples of behavior that contributes to creating a positive environment include: Using welcoming and inclusive language Being respectful of differing viewpoints and experiences Gracefully accepting constructive criticism Focusing on what is best for the community Showing empathy towards other community members Examples of unacceptable behavior by participants include: The use of sexualized language or imagery and unwelcome sexual attention or advances Trolling, insulting/derogatory comments, and personal or political attacks Public or private harassment Publishing others' private information, such as a physical or electronic address, without explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting","title":"Our Standards"},{"location":"docs/contributing/3.-code-of-conduct/#our-responsibilities","text":"Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior. Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful.","title":"Our Responsibilities"},{"location":"docs/contributing/3.-code-of-conduct/#scope","text":"This Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers.","title":"Scope"},{"location":"docs/contributing/3.-code-of-conduct/#enforcement","text":"Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting timothy.crosley@gmail.com . All complaints will be reviewed and investigated and will result in a response that is deemed necessary and appropriate to the circumstances. Confidentiality will be maintained with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately. Project maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership.","title":"Enforcement"},{"location":"docs/contributing/3.-code-of-conduct/#attribution","text":"This Code of Conduct is adapted from the [Contributor Covenant][https://www.contributor-covenant.org], version 1.4, available at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html For answers to common questions about this code of conduct, see https://www.contributor-covenant.org/faq","title":"Attribution"},{"location":"docs/contributing/4.-acknowledgements/","text":"Original Creator & Maintainer Timothy Edmund Crosley (@timothycrosley) Plugin Writers VIM - Juan Pedro Fisanotti (@fisadev) Emacs - Friedrich Paetzke (@paetzke) Sublime - Thijs de Zoute (@thijsdezoete) Notable Bug Reporters Bengt L\u00fcers (@Bengt) Chris Adams (@acdha) @OddBloke Martin Geisler (@mgeisler) Tim Heap (@timheap) Code Contributors Aaron Gallagher (@habnabit) Thomas Grainger (@graingert) Thijs de Zoute (@thijsdezoete) Marc Abramowitz (@msabramo) Daniel Cowgill (@dcowgill) Francois Lebel (@flebel) Antoni Segura Puimedon (@celebdor) Pablo (@oubiga) Oskar Hahn (@ostcar) Wim Glenn (@wimglenn) Matt Caldwell (@mattcaldwell) Dwayne Bailey (@dwaynebailey) Ionel Cristian M\u0103rie\u0219 (@ionelmc) Chris Adams (@acdha) GuoJing (@GuoJing) George Hickman (@ghickman) Dan Davison (@dandavison) Maciej Wolff (@maciejwo) Elliott Sales de Andrade (@qulogic) Kasper Jacobsen (@dinoshauer) Sebastian Pipping (@hartwork) Helen Sherwood-Taylor (@helenst) Mocker (@Zuckonit) Tim Graham (@timgraham) Adam (@NorthIsUp) Norman J\u00e4ckel (@normanjaeckel) Derrick Petzold (@dpetzold) Michael van Tellingen (@mvantellingen) Patrick Yevsukov (@patrickyevsukov) Christer van der Meeren (@cmeeren) Timon Wong/NHNCN (@timonwong) Jeremy Dunck (@jdunck) Benjamin ABEL (@benjaminabel) Dan Baragan (@danbaragan) Rob Cowie (@robcowie) Amit Shah (@Amwam) Patrick Gerken (@do3cc) @dein0s David Stensland (@terite) Ankur Dedania (@AbsoluteMSTR) Lee Packham (@leepa) Jesse Mullan (@jmullan) Kwok-kuen Cheung (@cheungpat) Johan Bloemberg (@aequitas) Dan Watson (@dcwatson) \u00c9ric Araujo (@merwok) Dan Palmer (@danpalmer) Andy Boot (@bootandy) @m7v8 John Vandenberg (@jayvdb) Adam Chainz (@adamchainz) @Brightcells Jonas Trappenberg (@teeberg) Andrew Konstantaras (@akonsta) Jason Brackman (@jasonbrackman) Kathryn Lingel (@katlings) Andrew Gaul (@gaul) John Chadwick (@jchv) Jon Dufresne (@jdufresne) Brian F. Baron (@briabar) Madison Caldwell (@madirey) Matt Yule-Bennett (@mattbennett) Jaswanth Kumar (@jaswanth098) Dario Navin (@Zarathustra2) Danny Weinberg (@FuegoFro) Gram (@orsinium) Hugo van Kemenade (@hugovk) G\u00e9ry Ogam (@maggyero) Cody Scott (@Siecje) Pedro Algarvio (@s0undt3ch) Chris St. Pierre (@stpierre) Sebastian Rittau (@srittau) Documenters Reinout van Rees (@reinout) Helen Sherwood-Taylor (@helenst) Elliott Sales de Andrade (@QuLogic) Brian Peiris (@brianpeiris) Tim Graham (@timgraham) Josh Soref (@jsoref) A sincere thanks to everyone who has helped isort be the great utility it is today! It would not be one-hundredth as useful and consistent as it is now without the help of your bug reports, commits, and suggestions. You guys rock! ~Timothy Crosley","title":"4. Acknowledgements"},{"location":"docs/contributing/4.-acknowledgements/#original-creator-maintainer","text":"Timothy Edmund Crosley (@timothycrosley)","title":"Original Creator &amp; Maintainer"},{"location":"docs/contributing/4.-acknowledgements/#plugin-writers","text":"VIM - Juan Pedro Fisanotti (@fisadev) Emacs - Friedrich Paetzke (@paetzke) Sublime - Thijs de Zoute (@thijsdezoete)","title":"Plugin Writers"},{"location":"docs/contributing/4.-acknowledgements/#notable-bug-reporters","text":"Bengt L\u00fcers (@Bengt) Chris Adams (@acdha) @OddBloke Martin Geisler (@mgeisler) Tim Heap (@timheap)","title":"Notable Bug Reporters"},{"location":"docs/contributing/4.-acknowledgements/#code-contributors","text":"Aaron Gallagher (@habnabit) Thomas Grainger (@graingert) Thijs de Zoute (@thijsdezoete) Marc Abramowitz (@msabramo) Daniel Cowgill (@dcowgill) Francois Lebel (@flebel) Antoni Segura Puimedon (@celebdor) Pablo (@oubiga) Oskar Hahn (@ostcar) Wim Glenn (@wimglenn) Matt Caldwell (@mattcaldwell) Dwayne Bailey (@dwaynebailey) Ionel Cristian M\u0103rie\u0219 (@ionelmc) Chris Adams (@acdha) GuoJing (@GuoJing) George Hickman (@ghickman) Dan Davison (@dandavison) Maciej Wolff (@maciejwo) Elliott Sales de Andrade (@qulogic) Kasper Jacobsen (@dinoshauer) Sebastian Pipping (@hartwork) Helen Sherwood-Taylor (@helenst) Mocker (@Zuckonit) Tim Graham (@timgraham) Adam (@NorthIsUp) Norman J\u00e4ckel (@normanjaeckel) Derrick Petzold (@dpetzold) Michael van Tellingen (@mvantellingen) Patrick Yevsukov (@patrickyevsukov) Christer van der Meeren (@cmeeren) Timon Wong/NHNCN (@timonwong) Jeremy Dunck (@jdunck) Benjamin ABEL (@benjaminabel) Dan Baragan (@danbaragan) Rob Cowie (@robcowie) Amit Shah (@Amwam) Patrick Gerken (@do3cc) @dein0s David Stensland (@terite) Ankur Dedania (@AbsoluteMSTR) Lee Packham (@leepa) Jesse Mullan (@jmullan) Kwok-kuen Cheung (@cheungpat) Johan Bloemberg (@aequitas) Dan Watson (@dcwatson) \u00c9ric Araujo (@merwok) Dan Palmer (@danpalmer) Andy Boot (@bootandy) @m7v8 John Vandenberg (@jayvdb) Adam Chainz (@adamchainz) @Brightcells Jonas Trappenberg (@teeberg) Andrew Konstantaras (@akonsta) Jason Brackman (@jasonbrackman) Kathryn Lingel (@katlings) Andrew Gaul (@gaul) John Chadwick (@jchv) Jon Dufresne (@jdufresne) Brian F. Baron (@briabar) Madison Caldwell (@madirey) Matt Yule-Bennett (@mattbennett) Jaswanth Kumar (@jaswanth098) Dario Navin (@Zarathustra2) Danny Weinberg (@FuegoFro) Gram (@orsinium) Hugo van Kemenade (@hugovk) G\u00e9ry Ogam (@maggyero) Cody Scott (@Siecje) Pedro Algarvio (@s0undt3ch) Chris St. Pierre (@stpierre) Sebastian Rittau (@srittau)","title":"Code Contributors"},{"location":"docs/contributing/4.-acknowledgements/#documenters","text":"Reinout van Rees (@reinout) Helen Sherwood-Taylor (@helenst) Elliott Sales de Andrade (@QuLogic) Brian Peiris (@brianpeiris) Tim Graham (@timgraham) Josh Soref (@jsoref) A sincere thanks to everyone who has helped isort be the great utility it is today! It would not be one-hundredth as useful and consistent as it is now without the help of your bug reports, commits, and suggestions. You guys rock! ~Timothy Crosley","title":"Documenters"},{"location":"reference/isort/","text":"Module isort init .py. Defines the isort module to include the SortImports utility class as well as any defined settings. Copyright (C) 2013 Timothy Edmund Crosley Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. View Source \"\"\" __init__.py. Defines the isort module to include the SortImports utility class as well as any defined settings . Copyright ( C ) 2013 Timothy Edmund Crosley Permission is hereby granted , free of charge , to any person obtaining a copy of this software and associated documentation files ( the \" Software \" ) , to deal in the Software without restriction , including without limitation the rights to use , copy , modify , merge , publish , distribute , sublicense , and / or sell copies of the Software , and to permit persons to whom the Software is furnished to do so , subject to the following conditions : The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software . THE SOFTWARE IS PROVIDED \" AS IS \" , WITHOUT WARRANTY OF ANY KIND , EXPRESS OR IMPLIED , INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY , FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT . IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM , DAMAGES OR OTHER LIABILITY , WHETHER IN AN ACTION OF CONTRACT , TORT OR OTHERWISE , ARISING FROM , OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE . \"\"\" from . import settings # noqa : F401 from . compat import SortImports # noqa : F401 __version__ = \" 4.3.21 \" Sub-modules isort.compat isort.finders isort.format isort.hooks isort.isort isort.main isort.natural isort.pylama_isort isort.settings isort.stdlibs isort.utils","title":"Index"},{"location":"reference/isort/#module-isort","text":"init .py. Defines the isort module to include the SortImports utility class as well as any defined settings. Copyright (C) 2013 Timothy Edmund Crosley Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. View Source \"\"\" __init__.py. Defines the isort module to include the SortImports utility class as well as any defined settings . Copyright ( C ) 2013 Timothy Edmund Crosley Permission is hereby granted , free of charge , to any person obtaining a copy of this software and associated documentation files ( the \" Software \" ) , to deal in the Software without restriction , including without limitation the rights to use , copy , modify , merge , publish , distribute , sublicense , and / or sell copies of the Software , and to permit persons to whom the Software is furnished to do so , subject to the following conditions : The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software . THE SOFTWARE IS PROVIDED \" AS IS \" , WITHOUT WARRANTY OF ANY KIND , EXPRESS OR IMPLIED , INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY , FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT . IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM , DAMAGES OR OTHER LIABILITY , WHETHER IN AN ACTION OF CONTRACT , TORT OR OTHERWISE , ARISING FROM , OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE . \"\"\" from . import settings # noqa : F401 from . compat import SortImports # noqa : F401 __version__ = \" 4.3.21 \"","title":"Module isort"},{"location":"reference/isort/#sub-modules","text":"isort.compat isort.finders isort.format isort.hooks isort.isort isort.main isort.natural isort.pylama_isort isort.settings isort.stdlibs isort.utils","title":"Sub-modules"},{"location":"reference/isort/compat/","text":"Module isort.compat View Source import locale import os import re import sys from pathlib import Path from typing import Any , Optional , Tuple from isort import settings from isort.format import ask_whether_to_apply_changes_to_file , show_unified_diff from isort.isort import _SortImports def determine_file_encoding ( file_path : Path , default : str = \"utf-8\" ) -> str : # see https://www.python.org/dev/peps/pep-0263/ pattern = re . compile ( br \"^[ \\t\\f]*#.*?coding[:=][ \\t]*([-_.a-zA-Z0-9]+)\" ) coding = default with file_path . open ( \"rb\" ) as f : for line_number , line in enumerate ( f , 1 ): if line_number > 2 : break groups = re . findall ( pattern , line ) if groups : coding = groups [ 0 ] . decode ( \"ascii\" ) break return coding def read_file_contents ( file_path : Path , encoding : str , fallback_encoding : str ) -> Tuple [ Optional [ str ], Optional [ str ]]: with file_path . open ( encoding = encoding , newline = \"\" ) as file_to_import_sort : try : file_contents = file_to_import_sort . read () return file_contents , encoding except UnicodeDecodeError : pass with file_path . open ( encoding = fallback_encoding , newline = \"\" ) as file_to_import_sort : try : file_contents = file_to_import_sort . read () return file_contents , fallback_encoding except UnicodeDecodeError : return None , None def resolve ( path : Path ) -> Path : if sys . version_info [: 2 ] >= ( 3 , 6 ): return path . resolve () else : return Path ( os . path . abspath ( str ( path ))) def get_settings_path ( settings_path : Optional [ Path ], current_file_path : Optional [ Path ] ) -> Path : if settings_path : return settings_path if current_file_path : return resolve ( current_file_path ) . parent else : return Path . cwd () class SortImports : incorrectly_sorted = False skipped = False def __init__ ( self , file_path : Optional [ str ] = None , file_contents : Optional [ str ] = None , write_to_stdout : bool = False , check : bool = False , show_diff : bool = False , settings_path : Optional [ str ] = None , ask_to_apply : bool = False , run_path : str = \"\" , check_skip : bool = True , extension : Optional [ str ] = None , ** setting_overrides : Any ): file_path = None if file_path is None else Path ( file_path ) file_name = None settings_path = None if settings_path is None else Path ( settings_path ) self . config = settings . prepare_config ( get_settings_path ( settings_path , file_path ), ** setting_overrides ) self . output = None file_encoding = \"utf-8\" self . file_path = None if file_path : self . file_path = file_path # raw file path (unresolved) ? absolute_file_path = resolve ( file_path ) if check_skip : if run_path and run_path in absolute_file_path . parents : # TODO: Drop str() when isort is Python 3.6+. file_name = os . path . relpath ( str ( absolute_file_path ), run_path ) else : file_name = str ( absolute_file_path ) run_path = \"\" if settings . file_should_be_skipped ( file_name , self . config , run_path ): self . skipped = True if self . config [ \"verbose\" ]: print ( \"WARNING: {} was skipped as it's listed in 'skip' setting\" \" or matches a glob in 'skip_glob' setting\" . format ( absolute_file_path ) ) file_contents = None if not self . skipped and not file_contents : preferred_encoding = determine_file_encoding ( absolute_file_path ) # default encoding for open(mode='r') on the system fallback_encoding = locale . getpreferredencoding ( False ) file_contents , used_encoding = read_file_contents ( absolute_file_path , encoding = preferred_encoding , fallback_encoding = fallback_encoding , ) if used_encoding is None : self . skipped = True if self . config [ \"verbose\" ]: print ( \"WARNING: {} was skipped as it couldn't be opened with the given \" \"{} encoding or {} fallback encoding\" . format ( str ( absolute_file_path ), file_encoding , fallback_encoding , ) ) else : file_encoding = used_encoding if file_contents is None or ( \"isort:\" + \"skip_file\" ) in file_contents : self . skipped = True if write_to_stdout and file_contents : sys . stdout . write ( file_contents ) return if not extension : extension = file_name . split ( \".\" )[ - 1 ] if file_name else \"py\" self . sorted_imports = _SortImports ( file_contents = file_contents , config = self . config , extension = extension ) self . output = self . sorted_imports . output if self . config [ \"atomic\" ]: logging_file_path = str ( self . file_path or \"\" ) try : out_lines_without_top_comment = ( self . sorted_imports . get_out_lines_without_top_comment () ) compile ( out_lines_without_top_comment , logging_file_path , \"exec\" , 0 , 1 ) except SyntaxError : self . output = file_contents self . incorrectly_sorted = True try : in_lines_without_top_comment = ( self . sorted_imports . get_in_lines_without_top_comment () ) compile ( in_lines_without_top_comment , logging_file_path , \"exec\" , 0 , 1 ) print ( \"ERROR: {} isort would have introduced syntax errors, please report to the project!\" . format ( logging_file_path ) ) except SyntaxError : print ( \"ERROR: {} File contains syntax errors.\" . format ( logging_file_path ) ) return if check : check_output = self . output check_against = file_contents if self . config [ \"ignore_whitespace\" ]: check_output = self . sorted_imports . remove_whitespaces ( check_output ) check_against = self . sorted_imports . remove_whitespaces ( check_against ) current_input_sorted_correctly = self . sorted_imports . check_if_input_already_sorted ( check_output , check_against , logging_file_path = str ( self . file_path or \"\" ) ) if current_input_sorted_correctly : return else : self . incorrectly_sorted = True if show_diff or self . config [ \"show_diff\" ]: show_unified_diff ( file_input = file_contents , file_output = self . output , file_path = self . file_path , ) elif write_to_stdout : sys . stdout . write ( self . output ) elif self . file_path and not check : # if file_name resolves to True, file_path never None or '' if self . output == file_contents : return if ask_to_apply : show_unified_diff ( file_input = file_contents , file_output = self . output , file_path = self . file_path , ) apply_changes = ask_whether_to_apply_changes_to_file ( str ( self . file_path ) ) if not apply_changes : return with self . file_path . open ( \"w\" , encoding = file_encoding , newline = \"\" ) as output_file : if not self . config [ \"quiet\" ]: print ( \"Fixing {}\" . format ( self . file_path )) output_file . write ( self . output ) @property def sections ( self ): return self . sorted_imports . sections @property def length_change ( self ) -> int : return self . sorted_imports . length_change Functions determine_file_encoding def determine_file_encoding ( file_path : pathlib . Path , default : str = 'utf-8' ) -> str View Source def determine_file_encoding ( file_path : Path , default : str = \" utf-8 \" ) -> str : # see https : // www . python . org / dev / peps / pep - 0263 / pattern = re . compile ( br \" ^[ \\t \\f]*#.*?coding[:=][ \\t ]*([-_.a-zA-Z0-9]+) \" ) coding = default with file_path . open ( \" rb \" ) as f : for line_number , line in enumerate ( f , 1 ) : if line_number > 2 : break groups = re . findall ( pattern , line ) if groups : coding = groups [ 0 ]. decode ( \" ascii \" ) break return coding get_settings_path def get_settings_path ( settings_path : Union [ pathlib . Path , NoneType ], current_file_path : Union [ pathlib . Path , NoneType ] ) -> pathlib . Path View Source def get_settings_path ( settings_path : Optional [ Path ], current_file_path : Optional [ Path ] ) -> Path : if settings_path : return settings_path if current_file_path : return resolve ( current_file_path ) . parent else : return Path . cwd () read_file_contents def read_file_contents ( file_path : pathlib . Path , encoding : str , fallback_encoding : str ) -> Tuple [ Union [ str , NoneType ], Union [ str , NoneType ]] View Source def read_file_contents ( file_path : Path , encoding : str , fallback_encoding : str ) -> Tuple [ Optional [ str ], Optional [ str ]]: with file_path . open ( encoding = encoding , newline = \"\" ) as file_to_import_sort : try : file_contents = file_to_import_sort . read () return file_contents , encoding except UnicodeDecodeError : pass with file_path . open ( encoding = fallback_encoding , newline = \"\" ) as file_to_import_sort : try : file_contents = file_to_import_sort . read () return file_contents , fallback_encoding except UnicodeDecodeError : return None , None resolve def resolve ( path : pathlib . Path ) -> pathlib . Path View Source def resolve ( path : Path ) -> Path : if sys . version_info [: 2 ] >= ( 3 , 6 ) : return path . resolve () else : return Path ( os . path . abspath ( str ( path ))) Classes SortImports class SortImports ( file_path : Union [ str , NoneType ] = None , file_contents : Union [ str , NoneType ] = None , write_to_stdout : bool = False , check : bool = False , show_diff : bool = False , settings_path : Union [ str , NoneType ] = None , ask_to_apply : bool = False , run_path : str = '' , check_skip : bool = True , extension : Union [ str , NoneType ] = None , ** setting_overrides : Any ) View Source class SortImports : incorrectly_sorted = False skipped = False def __init__ ( self , file_path : Optional [ str ] = None , file_contents : Optional [ str ] = None , write_to_stdout : bool = False , check : bool = False , show_diff : bool = False , settings_path : Optional [ str ] = None , ask_to_apply : bool = False , run_path : str = \"\" , check_skip : bool = True , extension : Optional [ str ] = None , ** setting_overrides : Any ) : file_path = None if file_path is None else Path ( file_path ) file_name = None settings_path = None if settings_path is None else Path ( settings_path ) self . config = settings . prepare_config ( get_settings_path ( settings_path , file_path ) , ** setting_overrides ) self . output = None file_encoding = \" utf-8 \" self . file_path = None if file_path : self . file_path = file_path # raw file path ( unresolved ) ? absolute_file_path = resolve ( file_path ) if check_skip : if run_path and run_path in absolute_file_path . parents : # TODO : Drop str () when isort is Python 3 . 6 + . file_name = os . path . relpath ( str ( absolute_file_path ) , run_path ) else : file_name = str ( absolute_file_path ) run_path = \"\" if settings . file_should_be_skipped ( file_name , self . config , run_path ) : self . skipped = True if self . config [ \" verbose \" ]: print ( \" WARNING: {} was skipped as it's listed in 'skip' setting \" \" or matches a glob in 'skip_glob' setting \" . format ( absolute_file_path ) ) file_contents = None if not self . skipped and not file_contents : preferred_encoding = determine_file_encoding ( absolute_file_path ) # default encoding for open ( mode = ' r ' ) on the system fallback_encoding = locale . getpreferredencoding ( False ) file_contents , used_encoding = read_file_contents ( absolute_file_path , encoding = preferred_encoding , fallback_encoding = fallback_encoding , ) if used_encoding is None : self . skipped = True if self . config [ \" verbose \" ]: print ( \" WARNING: {} was skipped as it couldn't be opened with the given \" \" {} encoding or {} fallback encoding \" . format ( str ( absolute_file_path ) , file_encoding , fallback_encoding , ) ) else : file_encoding = used_encoding if file_contents is None or ( \" isort: \" + \" skip_file \" ) in file_contents : self . skipped = True if write_to_stdout and file_contents : sys . stdout . write ( file_contents ) return if not extension : extension = file_name . split ( \" . \" ) [ - 1 ] if file_name else \" py \" self . sorted_imports = _SortImports ( file_contents = file_contents , config = self . config , extension = extension ) self . output = self . sorted_imports . output if self . config [ \" atomic \" ]: logging_file_path = str ( self . file_path or \"\" ) try : out_lines_without_top_comment = ( self . sorted_imports . get_out_lines_without_top_comment () ) compile ( out_lines_without_top_comment , logging_file_path , \" exec \" , 0 , 1 ) except SyntaxError : self . output = file_contents self . incorrectly_sorted = True try : in_lines_without_top_comment = ( self . sorted_imports . get_in_lines_without_top_comment () ) compile ( in_lines_without_top_comment , logging_file_path , \" exec \" , 0 , 1 ) print ( \" ERROR: {} isort would have introduced syntax errors, please report to the project! \" . format ( logging_file_path ) ) except SyntaxError : print ( \" ERROR: {} File contains syntax errors. \" . format ( logging_file_path ) ) return if check : check_output = self . output check_against = file_contents if self . config [ \" ignore_whitespace \" ]: check_output = self . sorted_imports . remove_whitespaces ( check_output ) check_against = self . sorted_imports . remove_whitespaces ( check_against ) current_input_sorted_correctly = self . sorted_imports . check_if_input_already_sorted ( check_output , check_against , logging_file_path = str ( self . file_path or \"\" ) ) if current_input_sorted_correctly : return else : self . incorrectly_sorted = True if show_diff or self . config [ \" show_diff \" ]: show_unified_diff ( file_input = file_contents , file_output = self . output , file_path = self . file_path , ) elif write_to_stdout : sys . stdout . write ( self . output ) elif self . file_path and not check : # if file_name resolves to True , file_path never None or '' if self . output == file_contents : return if ask_to_apply : show_unified_diff ( file_input = file_contents , file_output = self . output , file_path = self . file_path , ) apply_changes = ask_whether_to_apply_changes_to_file ( str ( self . file_path ) ) if not apply_changes : return with self . file_path . open ( \" w \" , encoding = file_encoding , newline = \"\" ) as output_file : if not self . config [ \" quiet \" ]: print ( \" Fixing {} \" . format ( self . file_path )) output_file . write ( self . output ) @ property def sections ( self ) : return self . sorted_imports . sections @ property def length_change ( self ) -> int : return self . sorted_imports . length_change Class variables incorrectly_sorted skipped Instance variables length_change sections","title":"Compat"},{"location":"reference/isort/compat/#module-isortcompat","text":"View Source import locale import os import re import sys from pathlib import Path from typing import Any , Optional , Tuple from isort import settings from isort.format import ask_whether_to_apply_changes_to_file , show_unified_diff from isort.isort import _SortImports def determine_file_encoding ( file_path : Path , default : str = \"utf-8\" ) -> str : # see https://www.python.org/dev/peps/pep-0263/ pattern = re . compile ( br \"^[ \\t\\f]*#.*?coding[:=][ \\t]*([-_.a-zA-Z0-9]+)\" ) coding = default with file_path . open ( \"rb\" ) as f : for line_number , line in enumerate ( f , 1 ): if line_number > 2 : break groups = re . findall ( pattern , line ) if groups : coding = groups [ 0 ] . decode ( \"ascii\" ) break return coding def read_file_contents ( file_path : Path , encoding : str , fallback_encoding : str ) -> Tuple [ Optional [ str ], Optional [ str ]]: with file_path . open ( encoding = encoding , newline = \"\" ) as file_to_import_sort : try : file_contents = file_to_import_sort . read () return file_contents , encoding except UnicodeDecodeError : pass with file_path . open ( encoding = fallback_encoding , newline = \"\" ) as file_to_import_sort : try : file_contents = file_to_import_sort . read () return file_contents , fallback_encoding except UnicodeDecodeError : return None , None def resolve ( path : Path ) -> Path : if sys . version_info [: 2 ] >= ( 3 , 6 ): return path . resolve () else : return Path ( os . path . abspath ( str ( path ))) def get_settings_path ( settings_path : Optional [ Path ], current_file_path : Optional [ Path ] ) -> Path : if settings_path : return settings_path if current_file_path : return resolve ( current_file_path ) . parent else : return Path . cwd () class SortImports : incorrectly_sorted = False skipped = False def __init__ ( self , file_path : Optional [ str ] = None , file_contents : Optional [ str ] = None , write_to_stdout : bool = False , check : bool = False , show_diff : bool = False , settings_path : Optional [ str ] = None , ask_to_apply : bool = False , run_path : str = \"\" , check_skip : bool = True , extension : Optional [ str ] = None , ** setting_overrides : Any ): file_path = None if file_path is None else Path ( file_path ) file_name = None settings_path = None if settings_path is None else Path ( settings_path ) self . config = settings . prepare_config ( get_settings_path ( settings_path , file_path ), ** setting_overrides ) self . output = None file_encoding = \"utf-8\" self . file_path = None if file_path : self . file_path = file_path # raw file path (unresolved) ? absolute_file_path = resolve ( file_path ) if check_skip : if run_path and run_path in absolute_file_path . parents : # TODO: Drop str() when isort is Python 3.6+. file_name = os . path . relpath ( str ( absolute_file_path ), run_path ) else : file_name = str ( absolute_file_path ) run_path = \"\" if settings . file_should_be_skipped ( file_name , self . config , run_path ): self . skipped = True if self . config [ \"verbose\" ]: print ( \"WARNING: {} was skipped as it's listed in 'skip' setting\" \" or matches a glob in 'skip_glob' setting\" . format ( absolute_file_path ) ) file_contents = None if not self . skipped and not file_contents : preferred_encoding = determine_file_encoding ( absolute_file_path ) # default encoding for open(mode='r') on the system fallback_encoding = locale . getpreferredencoding ( False ) file_contents , used_encoding = read_file_contents ( absolute_file_path , encoding = preferred_encoding , fallback_encoding = fallback_encoding , ) if used_encoding is None : self . skipped = True if self . config [ \"verbose\" ]: print ( \"WARNING: {} was skipped as it couldn't be opened with the given \" \"{} encoding or {} fallback encoding\" . format ( str ( absolute_file_path ), file_encoding , fallback_encoding , ) ) else : file_encoding = used_encoding if file_contents is None or ( \"isort:\" + \"skip_file\" ) in file_contents : self . skipped = True if write_to_stdout and file_contents : sys . stdout . write ( file_contents ) return if not extension : extension = file_name . split ( \".\" )[ - 1 ] if file_name else \"py\" self . sorted_imports = _SortImports ( file_contents = file_contents , config = self . config , extension = extension ) self . output = self . sorted_imports . output if self . config [ \"atomic\" ]: logging_file_path = str ( self . file_path or \"\" ) try : out_lines_without_top_comment = ( self . sorted_imports . get_out_lines_without_top_comment () ) compile ( out_lines_without_top_comment , logging_file_path , \"exec\" , 0 , 1 ) except SyntaxError : self . output = file_contents self . incorrectly_sorted = True try : in_lines_without_top_comment = ( self . sorted_imports . get_in_lines_without_top_comment () ) compile ( in_lines_without_top_comment , logging_file_path , \"exec\" , 0 , 1 ) print ( \"ERROR: {} isort would have introduced syntax errors, please report to the project!\" . format ( logging_file_path ) ) except SyntaxError : print ( \"ERROR: {} File contains syntax errors.\" . format ( logging_file_path ) ) return if check : check_output = self . output check_against = file_contents if self . config [ \"ignore_whitespace\" ]: check_output = self . sorted_imports . remove_whitespaces ( check_output ) check_against = self . sorted_imports . remove_whitespaces ( check_against ) current_input_sorted_correctly = self . sorted_imports . check_if_input_already_sorted ( check_output , check_against , logging_file_path = str ( self . file_path or \"\" ) ) if current_input_sorted_correctly : return else : self . incorrectly_sorted = True if show_diff or self . config [ \"show_diff\" ]: show_unified_diff ( file_input = file_contents , file_output = self . output , file_path = self . file_path , ) elif write_to_stdout : sys . stdout . write ( self . output ) elif self . file_path and not check : # if file_name resolves to True, file_path never None or '' if self . output == file_contents : return if ask_to_apply : show_unified_diff ( file_input = file_contents , file_output = self . output , file_path = self . file_path , ) apply_changes = ask_whether_to_apply_changes_to_file ( str ( self . file_path ) ) if not apply_changes : return with self . file_path . open ( \"w\" , encoding = file_encoding , newline = \"\" ) as output_file : if not self . config [ \"quiet\" ]: print ( \"Fixing {}\" . format ( self . file_path )) output_file . write ( self . output ) @property def sections ( self ): return self . sorted_imports . sections @property def length_change ( self ) -> int : return self . sorted_imports . length_change","title":"Module isort.compat"},{"location":"reference/isort/compat/#functions","text":"","title":"Functions"},{"location":"reference/isort/compat/#determine_file_encoding","text":"def determine_file_encoding ( file_path : pathlib . Path , default : str = 'utf-8' ) -> str View Source def determine_file_encoding ( file_path : Path , default : str = \" utf-8 \" ) -> str : # see https : // www . python . org / dev / peps / pep - 0263 / pattern = re . compile ( br \" ^[ \\t \\f]*#.*?coding[:=][ \\t ]*([-_.a-zA-Z0-9]+) \" ) coding = default with file_path . open ( \" rb \" ) as f : for line_number , line in enumerate ( f , 1 ) : if line_number > 2 : break groups = re . findall ( pattern , line ) if groups : coding = groups [ 0 ]. decode ( \" ascii \" ) break return coding","title":"determine_file_encoding"},{"location":"reference/isort/compat/#get_settings_path","text":"def get_settings_path ( settings_path : Union [ pathlib . Path , NoneType ], current_file_path : Union [ pathlib . Path , NoneType ] ) -> pathlib . Path View Source def get_settings_path ( settings_path : Optional [ Path ], current_file_path : Optional [ Path ] ) -> Path : if settings_path : return settings_path if current_file_path : return resolve ( current_file_path ) . parent else : return Path . cwd ()","title":"get_settings_path"},{"location":"reference/isort/compat/#read_file_contents","text":"def read_file_contents ( file_path : pathlib . Path , encoding : str , fallback_encoding : str ) -> Tuple [ Union [ str , NoneType ], Union [ str , NoneType ]] View Source def read_file_contents ( file_path : Path , encoding : str , fallback_encoding : str ) -> Tuple [ Optional [ str ], Optional [ str ]]: with file_path . open ( encoding = encoding , newline = \"\" ) as file_to_import_sort : try : file_contents = file_to_import_sort . read () return file_contents , encoding except UnicodeDecodeError : pass with file_path . open ( encoding = fallback_encoding , newline = \"\" ) as file_to_import_sort : try : file_contents = file_to_import_sort . read () return file_contents , fallback_encoding except UnicodeDecodeError : return None , None","title":"read_file_contents"},{"location":"reference/isort/compat/#resolve","text":"def resolve ( path : pathlib . Path ) -> pathlib . Path View Source def resolve ( path : Path ) -> Path : if sys . version_info [: 2 ] >= ( 3 , 6 ) : return path . resolve () else : return Path ( os . path . abspath ( str ( path )))","title":"resolve"},{"location":"reference/isort/compat/#classes","text":"","title":"Classes"},{"location":"reference/isort/compat/#sortimports","text":"class SortImports ( file_path : Union [ str , NoneType ] = None , file_contents : Union [ str , NoneType ] = None , write_to_stdout : bool = False , check : bool = False , show_diff : bool = False , settings_path : Union [ str , NoneType ] = None , ask_to_apply : bool = False , run_path : str = '' , check_skip : bool = True , extension : Union [ str , NoneType ] = None , ** setting_overrides : Any ) View Source class SortImports : incorrectly_sorted = False skipped = False def __init__ ( self , file_path : Optional [ str ] = None , file_contents : Optional [ str ] = None , write_to_stdout : bool = False , check : bool = False , show_diff : bool = False , settings_path : Optional [ str ] = None , ask_to_apply : bool = False , run_path : str = \"\" , check_skip : bool = True , extension : Optional [ str ] = None , ** setting_overrides : Any ) : file_path = None if file_path is None else Path ( file_path ) file_name = None settings_path = None if settings_path is None else Path ( settings_path ) self . config = settings . prepare_config ( get_settings_path ( settings_path , file_path ) , ** setting_overrides ) self . output = None file_encoding = \" utf-8 \" self . file_path = None if file_path : self . file_path = file_path # raw file path ( unresolved ) ? absolute_file_path = resolve ( file_path ) if check_skip : if run_path and run_path in absolute_file_path . parents : # TODO : Drop str () when isort is Python 3 . 6 + . file_name = os . path . relpath ( str ( absolute_file_path ) , run_path ) else : file_name = str ( absolute_file_path ) run_path = \"\" if settings . file_should_be_skipped ( file_name , self . config , run_path ) : self . skipped = True if self . config [ \" verbose \" ]: print ( \" WARNING: {} was skipped as it's listed in 'skip' setting \" \" or matches a glob in 'skip_glob' setting \" . format ( absolute_file_path ) ) file_contents = None if not self . skipped and not file_contents : preferred_encoding = determine_file_encoding ( absolute_file_path ) # default encoding for open ( mode = ' r ' ) on the system fallback_encoding = locale . getpreferredencoding ( False ) file_contents , used_encoding = read_file_contents ( absolute_file_path , encoding = preferred_encoding , fallback_encoding = fallback_encoding , ) if used_encoding is None : self . skipped = True if self . config [ \" verbose \" ]: print ( \" WARNING: {} was skipped as it couldn't be opened with the given \" \" {} encoding or {} fallback encoding \" . format ( str ( absolute_file_path ) , file_encoding , fallback_encoding , ) ) else : file_encoding = used_encoding if file_contents is None or ( \" isort: \" + \" skip_file \" ) in file_contents : self . skipped = True if write_to_stdout and file_contents : sys . stdout . write ( file_contents ) return if not extension : extension = file_name . split ( \" . \" ) [ - 1 ] if file_name else \" py \" self . sorted_imports = _SortImports ( file_contents = file_contents , config = self . config , extension = extension ) self . output = self . sorted_imports . output if self . config [ \" atomic \" ]: logging_file_path = str ( self . file_path or \"\" ) try : out_lines_without_top_comment = ( self . sorted_imports . get_out_lines_without_top_comment () ) compile ( out_lines_without_top_comment , logging_file_path , \" exec \" , 0 , 1 ) except SyntaxError : self . output = file_contents self . incorrectly_sorted = True try : in_lines_without_top_comment = ( self . sorted_imports . get_in_lines_without_top_comment () ) compile ( in_lines_without_top_comment , logging_file_path , \" exec \" , 0 , 1 ) print ( \" ERROR: {} isort would have introduced syntax errors, please report to the project! \" . format ( logging_file_path ) ) except SyntaxError : print ( \" ERROR: {} File contains syntax errors. \" . format ( logging_file_path ) ) return if check : check_output = self . output check_against = file_contents if self . config [ \" ignore_whitespace \" ]: check_output = self . sorted_imports . remove_whitespaces ( check_output ) check_against = self . sorted_imports . remove_whitespaces ( check_against ) current_input_sorted_correctly = self . sorted_imports . check_if_input_already_sorted ( check_output , check_against , logging_file_path = str ( self . file_path or \"\" ) ) if current_input_sorted_correctly : return else : self . incorrectly_sorted = True if show_diff or self . config [ \" show_diff \" ]: show_unified_diff ( file_input = file_contents , file_output = self . output , file_path = self . file_path , ) elif write_to_stdout : sys . stdout . write ( self . output ) elif self . file_path and not check : # if file_name resolves to True , file_path never None or '' if self . output == file_contents : return if ask_to_apply : show_unified_diff ( file_input = file_contents , file_output = self . output , file_path = self . file_path , ) apply_changes = ask_whether_to_apply_changes_to_file ( str ( self . file_path ) ) if not apply_changes : return with self . file_path . open ( \" w \" , encoding = file_encoding , newline = \"\" ) as output_file : if not self . config [ \" quiet \" ]: print ( \" Fixing {} \" . format ( self . file_path )) output_file . write ( self . output ) @ property def sections ( self ) : return self . sorted_imports . sections @ property def length_change ( self ) -> int : return self . sorted_imports . length_change","title":"SortImports"},{"location":"reference/isort/compat/#class-variables","text":"incorrectly_sorted skipped","title":"Class variables"},{"location":"reference/isort/compat/#instance-variables","text":"length_change sections","title":"Instance variables"},{"location":"reference/isort/finders/","text":"Module isort.finders Finders try to find right section for passed module name View Source \"\"\"Finders try to find right section for passed module name \"\"\" import inspect import os import os . path import re import sys import sysconfig from abc import ABCMeta , abstractmethod from fnmatch import fnmatch from functools import lru_cache from glob import glob from typing import ( Any , Dict , Iterable , Iterator , List , Mapping , Optional , Pattern , Sequence , Tuple , Type , ) from . utils import chdir , exists_case_sensitive try : from pipreqs import pipreqs except ImportError : pipreqs = None try : from pip_api import parse_requirements except ImportError : parse_requirements = None try : from requirementslib import Pipfile except ImportError : Pipfile = None KNOWN_SECTION_MAPPING = { \"STDLIB\" : \"STANDARD_LIBRARY\" , \"FUTURE\" : \"FUTURE_LIBRARY\" , \"FIRSTPARTY\" : \"FIRST_PARTY\" , \"THIRDPARTY\" : \"THIRD_PARTY\" , } class BaseFinder ( metaclass = ABCMeta ) : def __ init__ ( self , config : Mapping [ str , Any ], sections : Any ) -> None : self . config = config self . sections = sections @abstractmethod def find ( self , module_name: str ) -> Optional [ str ] : raise NotImplementedError class ForcedSeparateFinder ( BaseFinder ) : def find ( self , module_name: str ) -> Optional [ str ] : for forced_separate in self . config [ \"forced_separate\" ] : # Ensure all forced_separate patterns will match to end of string path_glob = forced_separate if not forced_separate . endswith ( \"*\" ) : path_glob = \"%s*\" % forced_separate if fnmatch ( module_name , path_glob ) or fnmatch ( module_name , \".\" + path_glob ) : return forced_separate return None class LocalFinder ( BaseFinder ) : def find ( self , module_name: str ) -> Optional [ str ] : if module_name . startswith ( \".\" ) : return self . sections . LOCALFOLDER return None class KnownPatternFinder ( BaseFinder ) : def __ init__ ( self , config : Mapping [ str , Any ], sections : Any ) -> None : super (). __ init__ ( config , sections ) self . known_patterns = [] # type : List [ Tuple [ Pattern [ str ], str ]] for placement in reversed ( self . sections ) : known_placement = KNOWN_SECTION_MAPPING . get ( placement , placement ) config_key = \"known_{}\" . format ( known_placement . lower ()) known_patterns = self . config . get ( config_key , []) known_patterns = [ pattern for known_pattern in known_patterns for pattern in self . _ parse_known_pattern ( known_pattern ) ] for known_pattern in known_patterns: regexp = \"^\" + known_pattern . replace ( \"*\" , \".*\" ). replace ( \"?\" , \".?\" ) + \"$\" self . known_patterns . append (( re . compile ( regexp ), placement )) def _ parse_known_pattern ( self , pattern : str ) -> List [ str ] : \"\"\" Expand pattern if identified as a directory and return found sub packages \"\"\" if pattern . endswith ( os . path . sep ) : patterns = [ filename for filename in os . listdir ( pattern ) if os . path . isdir ( os . path . join ( pattern , filename )) ] else : patterns = [ pattern ] return patterns def find ( self , module_name: str ) -> Optional [ str ] : # Try to find most specific placement instruction match ( if any ) parts = module_name . split ( \".\" ) module_names_to_check = ( \".\" . join ( parts [ :first_k ]) for first_k in range ( len ( parts ), 0 , - 1 ) ) for module_name_to_check in module_names_to_check: for pattern , placement in self . known_patterns: if pattern . match ( module_name_to_check ) : return placement return None class PathFinder ( BaseFinder ) : def __ init__ ( self , config : Mapping [ str , Any ], sections : Any ) -> None : super (). __ init__ ( config , sections ) # restore the original import path ( i . e . not the path to bin / isort ) root_dir = os . getcwd () src_dir = \"{0}/src\" . format ( root_dir ) self . paths = [ root_dir , src_dir ] # virtual env self . virtual_env = self . config . get ( \"virtual_env\" ) or os . environ . get ( \"VIRTUAL_ENV\" ) if self . virtual_env: self . virtual_env = os . path . realpath ( self . virtual_env ) self . virtual_env_src = \"\" if self . virtual_env: self . virtual_env_src = \"{}/src/\" . format ( self . virtual_env ) for path in glob ( \"{}/lib/python*/site-packages\" . format ( self . virtual_env )) : if path not in self . paths : self . paths . append ( path ) for path in glob ( \"{}/lib/python*/*/site-packages\" . format ( self . virtual_env )) : if path not in self . paths : self . paths . append ( path ) for path in glob ( \"{}/src/*\" . format ( self . virtual_env )) : if os . path . isdir ( path ) : self . paths . append ( path ) # conda self . conda_env = ( self . config . get ( \"conda_env\" ) or os . environ . get ( \"CONDA_PREFIX\" ) or \"\" ) if self . conda_env: self . conda_env = os . path . realpath ( self . conda_env ) for path in glob ( \"{}/lib/python*/site-packages\" . format ( self . conda_env )) : if path not in self . paths : self . paths . append ( path ) for path in glob ( \"{}/lib/python*/*/site-packages\" . format ( self . conda_env )) : if path not in self . paths : self . paths . append ( path ) # handle case - insensitive paths on windows self . stdlib_lib_prefix = os . path . normcase ( sysconfig . get_paths ()[ \"stdlib\" ]) if self . stdlib_lib_prefix not in self . paths : self . paths . append ( self . stdlib_lib_prefix ) # handle compiled libraries self . ext_suffix = sysconfig . get_config_var ( \"EXT_SUFFIX\" ) or \".so\" # add system paths for path in sys . path [ 1 : ] : if path not in self . paths : self . paths . append ( path ) def find ( self , module_name: str ) -> Optional [ str ] : for prefix in self . paths : package_path = \"/\" . join (( prefix , module_name . split ( \".\" )[ 0 ])) is_module = ( exists_case_sensitive ( package_path + \".py\" ) or exists_case_sensitive ( package_path + \".so\" ) or exists_case_sensitive ( package_path + self . ext_suffix ) or exists_case_sensitive ( package_path + \"/__init__.py\" ) ) is_package = exists_case_sensitive ( package_path ) and os . path . isdir ( package_path ) if is_module or is_package: if \"site-packages\" in prefix : return self . sections . THIRDPARTY if \"dist-packages\" in prefix : return self . sections . THIRDPARTY if self . virtual_env and self . virtual_env_src in prefix : return self . sections . THIRDPARTY if self . conda_env and self . conda_env in prefix : return self . sections . THIRDPARTY if os . path . normcase ( prefix ). startswith ( self . stdlib_lib_prefix ) : return self . sections . STDLIB return self . config [ \"default_section\" ] return None class ReqsBaseFinder ( BaseFinder ) : enabled = False def __ init__ ( self , config : Mapping [ str , Any ], sections : Any , path : str = \".\" ) -> None : super (). __ init__ ( config , sections ) self . path = path if self . enabled : self . mapping = self . _ load_mapping () self . names = self . _ load_names () @abstractmethod def _ get_names ( self , path : str ) -> Iterator [ str ] : raise NotImplementedError @abstractmethod def _ get_files_from_dir ( self , path : str ) -> Iterator [ str ] : raise NotImplementedError @staticmethod def _ load_mapping () -> Optional [ Dict [ str , str ]] : \"\"\"Return list of mappings `package_name -> module_name` Example: django-haystack -> haystack \"\"\" if not pipreqs : return None path = os . path . dirname ( inspect . getfile ( pipreqs )) path = os . path . join ( path , \"mapping\" ) with open ( path ) as f : # pypi_name: import_name mappings = {} # type : Dict [ str , str ] for line in f : import_name , _ , pypi_name = line . strip (). partition ( \":\" ) mappings [ pypi_name ] = import_name return mappings # return dict ( tuple ( line . strip (). split ( \":\" )[ ::- 1 ]) for line in f ) def _ load_names ( self ) -> List [ str ] : \"\"\"Return list of thirdparty modules from requirements \"\"\" names = [] for path in self . _ get_files () : for name in self . _ get_names ( path ) : names . append ( self . _ normalize_name ( name )) return names @staticmethod def _ get_parents ( path : str ) -> Iterator [ str ] : prev = \"\" while path ! = prev : prev = path yield path path = os . path . dirname ( path ) def _ get_files ( self ) -> Iterator [ str ] : \"\"\"Return paths to all requirements files \"\"\" path = os . path . abspath ( self . path ) if os . path . isfile ( path ) : path = os . path . dirname ( path ) for path in self . _ get_parents ( path ) : yield from self . _ get_files_from_dir ( path ) def _ normalize_name ( self , name : str ) -> str : \"\"\"Convert package name to module name Examples: Django -> django django-haystack -> django_haystack Flask-RESTFul -> flask_restful \"\"\" if self . mapping : name = self . mapping . get ( name , name ) return name . lower (). replace ( \"-\" , \"_\" ) def find ( self , module_name: str ) -> Optional [ str ] : # required lib not installed yet if not self . enabled : return None module_name , _ sep , _ submodules = module_name . partition ( \".\" ) module_name = module_name . lower () if not module_name: return None for name in self . names : if module_name == name : return self . sections . THIRDPARTY return None class RequirementsFinder ( ReqsBaseFinder ) : exts = ( \".txt\" , \".in\" ) enabled = bool ( parse_requirements ) def _ get_files_from_dir ( self , path : str ) -> Iterator [ str ] : \"\"\"Return paths to requirements files from passed dir. \"\"\" yield from self . _ get_files_from_dir_cached ( path ) @classmethod @ lru_cache ( maxsize = 16 ) def _ get_files_from_dir_cached ( cls , path : str ) -> List [ str ] : results = [] for fname in os . listdir ( path ) : if \"requirements\" not in fname : continue full_path = os . path . join ( path , fname ) # * requirements*/*. { txt , in } if os . path . isdir ( full_path ) : for subfile_name in os . listdir ( full_path ) : for ext in cls . exts : if subfile_name . endswith ( ext ) : results . append ( os . path . join ( full_path , subfile_name )) continue # * requirements*. { txt , in } if os . path . isfile ( full_path ) : for ext in cls . exts : if fname . endswith ( ext ) : results . append ( full_path ) break return results def _ get_names ( self , path : str ) -> Iterator [ str ] : \"\"\"Load required packages from path to requirements file \"\"\" yield from self . _ get_names_cached ( path ) @classmethod @ lru_cache ( maxsize = 16 ) def _ get_names_cached ( cls , path : str ) -> List [ str ] : result = [] with chdir ( os . path . dirname ( path )) : requirements = parse_requirements ( path ) for req in requirements . values () : if req . name : result . append ( req . name ) return result class PipfileFinder ( ReqsBaseFinder ) : enabled = bool ( Pipfile ) def _ get_names ( self , path : str ) -> Iterator [ str ] : with chdir ( path ) : project = Pipfile . load ( path ) for req in project . packages : yield req . name def _ get_files_from_dir ( self , path : str ) -> Iterator [ str ] : if \"Pipfile\" in os . listdir ( path ) : yield path class DefaultFinder ( BaseFinder ) : def find ( self , module_name: str ) -> Optional [ str ] : return self . config [ \"default_section\" ] class FindersManager : _ default_finders_classes = ( ForcedSeparateFinder , LocalFinder , KnownPatternFinder , PathFinder , PipfileFinder , RequirementsFinder , DefaultFinder , ) # type : Sequence [ Type [ BaseFinder ]] def __ init__ ( self , config : Mapping [ str , Any ], sections : Any , finder_classes: Optional [ Iterable [ Type [ BaseFinder ]]] = None , ) -> None : self . verbose = config . get ( \"verbose\" , False ) # type : bool if finder_classes is None : finder_classes = self . _ default_finders_classes finders = [] # type : List [ BaseFinder ] for finder_cls in finder_classes: try : finders . append ( finder_cls ( config , sections )) except Exception as exception : # if one finder fails to instantiate isort can continue using the rest if self . verbose : print ( \"{} encountered an error ({}) during instantiation and cannot be used\" . format ( finder_cls . __ name__ , str ( exception ) ) ) self . finders = tuple ( finders ) # type : Tuple [ BaseFinder , ...] def find ( self , module_name: str ) -> Optional [ str ] : for finder in self . finders : try : section = finder . find ( module_name ) except Exception as exception : # isort has to be able to keep trying to identify the correct import section even if one approach fails if self . verbose : print ( \"{} encountered an error ({}) while trying to identify the {} module\" . format ( finder . __ class__ . __ name__ , str ( exception ), module_name ) ) if section is not None : return section return None Variables KNOWN_SECTION_MAPPING Classes BaseFinder class BaseFinder ( config : Mapping [ str , Any ], sections : Any ) View Source class BaseFinder ( metaclass = ABCMeta ) : def __init__ ( self , config : Mapping [ str, Any ] , sections : Any ) -> None : self . config = config self . sections = sections @abstractmethod def find ( self , module_name : str ) -> Optional [ str ] : raise NotImplementedError Descendants isort.finders.ForcedSeparateFinder isort.finders.LocalFinder isort.finders.KnownPatternFinder isort.finders.PathFinder isort.finders.ReqsBaseFinder isort.finders.DefaultFinder Methods find def find ( self , module_name : str ) -> Union [ str , NoneType ] View Source @abstractmethod def find ( self , module_name : str ) -> Optional [ str ] : raise NotImplementedError DefaultFinder class DefaultFinder ( config : Mapping [ str , Any ], sections : Any ) View Source class DefaultFinder ( BaseFinder ) : def find ( self , module_name : str ) -> Optional [ str ]: return self . config [ \" default_section \" ] Ancestors (in MRO) isort.finders.BaseFinder Methods find def find ( self , module_name : str ) -> Union [ str , NoneType ] View Source def find ( self , module_name : str ) -> Optional [ str ]: return self . config [ \" default_section \" ] FindersManager class FindersManager ( config : Mapping [ str , Any ], sections : Any , finder_classes : Union [ Iterable [ Type [ isort . finders . BaseFinder ]], NoneType ] = None ) View Source class FindersManager : _default_finders_classes = ( ForcedSeparateFinder , LocalFinder , KnownPatternFinder , PathFinder , PipfileFinder , RequirementsFinder , DefaultFinder , ) # type : Sequence [ Type [ BaseFinder ]] def __init__ ( self , config : Mapping [ str , Any ], sections : Any , finder_classes : Optional [ Iterable [ Type [ BaseFinder ]]] = None , ) -> None : self . verbose = config . get ( \" verbose \" , False ) # type : bool if finder_classes is None : finder_classes = self . _default_finders_classes finders = [] # type : List [ BaseFinder ] for finder_cls in finder_classes : try : finders . append ( finder_cls ( config , sections )) except Exception as exception : # if one finder fails to instantiate isort can continue using the rest if self . verbose : print ( \" {} encountered an error ({}) during instantiation and cannot be used \" . format ( finder_cls . __name__ , str ( exception ) ) ) self . finders = tuple ( finders ) # type : Tuple [ BaseFinder , ...] def find ( self , module_name : str ) -> Optional [ str ]: for finder in self . finders : try : section = finder . find ( module_name ) except Exception as exception : # isort has to be able to keep trying to identify the correct import section even if one approach fails if self . verbose : print ( \" {} encountered an error ({}) while trying to identify the {} module \" . format ( finder . __class__ . __name__ , str ( exception ) , module_name ) ) if section is not None : return section return None Methods find def find ( self , module_name : str ) -> Union [ str , NoneType ] View Source def find ( self , module_name : str ) -> Optional [ str ]: for finder in self . finders : try : section = finder . find ( module_name ) except Exception as exception : # isort has to be able to keep trying to identify the correct import section even if one approach fails if self . verbose : print ( \"{} encountered an error ({}) while trying to identify the {} module\" . format ( finder . __class__ . __name__ , str ( exception ), module_name ) ) if section is not None : return section return None ForcedSeparateFinder class ForcedSeparateFinder ( config : Mapping [ str , Any ], sections : Any ) View Source class ForcedSeparateFinder ( BaseFinder ) : def find ( self , module_name : str ) -> Optional [ str ]: for forced_separate in self . config [ \" forced_separate \" ]: # Ensure all forced_separate patterns will match to end of string path_glob = forced_separate if not forced_separate . endswith ( \" * \" ) : path_glob = \" %s* \" % forced_separate if fnmatch ( module_name , path_glob ) or fnmatch ( module_name , \" . \" + path_glob ) : return forced_separate return None Ancestors (in MRO) isort.finders.BaseFinder Methods find def find ( self , module_name : str ) -> Union [ str , NoneType ] View Source def find ( self , module_name : str ) -> Optional [ str ]: for forced_separate in self . config [ \" forced_separate \" ]: # Ensure all forced_separate patterns will match to end of string path_glob = forced_separate if not forced_separate . endswith ( \" * \" ) : path_glob = \" %s* \" % forced_separate if fnmatch ( module_name , path_glob ) or fnmatch ( module_name , \" . \" + path_glob ) : return forced_separate return None KnownPatternFinder class KnownPatternFinder ( config : Mapping [ str , Any ], sections : Any ) View Source class KnownPatternFinder ( BaseFinder ) : def __init__ ( self , config : Mapping [ str , Any ], sections : Any ) -> None : super () . __init__ ( config , sections ) self . known_patterns = [] # type : List [ Tuple [ Pattern [ str ], str ]] for placement in reversed ( self . sections ) : known_placement = KNOWN_SECTION_MAPPING . get ( placement , placement ) config_key = \" known_{} \" . format ( known_placement . lower ()) known_patterns = self . config . get ( config_key , [] ) known_patterns = [ pattern for known_pattern in known_patterns for pattern in self . _parse_known_pattern ( known_pattern ) ] for known_pattern in known_patterns : regexp = \" ^ \" + known_pattern . replace ( \" * \" , \" .* \" ) . replace ( \" ? \" , \" .? \" ) + \" $ \" self . known_patterns . append (( re . compile ( regexp ) , placement )) def _parse_known_pattern ( self , pattern : str ) -> List [ str ]: \"\"\" Expand pattern if identified as a directory and return found sub packages \"\"\" if pattern . endswith ( os . path . sep ) : patterns = [ filename for filename in os . listdir ( pattern ) if os . path . isdir ( os . path . join ( pattern , filename )) ] else : patterns = [ pattern ] return patterns def find ( self , module_name : str ) -> Optional [ str ]: # Try to find most specific placement instruction match ( if any ) parts = module_name . split ( \" . \" ) module_names_to_check = ( \" . \" . join ( parts [: first_k ] ) for first_k in range ( len ( parts ) , 0 , - 1 ) ) for module_name_to_check in module_names_to_check : for pattern , placement in self . known_patterns : if pattern . match ( module_name_to_check ) : return placement return None Ancestors (in MRO) isort.finders.BaseFinder Methods find def find ( self , module_name : str ) -> Union [ str , NoneType ] View Source def find ( self , module_name : str ) -> Optional [ str ]: # Try to find most specific placement instruction match ( if any ) parts = module_name . split ( \" . \" ) module_names_to_check = ( \" . \" . join ( parts [: first_k ] ) for first_k in range ( len ( parts ) , 0 , - 1 ) ) for module_name_to_check in module_names_to_check : for pattern , placement in self . known_patterns : if pattern . match ( module_name_to_check ) : return placement return None LocalFinder class LocalFinder ( config : Mapping [ str , Any ], sections : Any ) View Source class LocalFinder ( BaseFinder ) : def find ( self , module_name : str ) -> Optional [ str ]: if module_name . startswith ( \" . \" ) : return self . sections . LOCALFOLDER return None Ancestors (in MRO) isort.finders.BaseFinder Methods find def find ( self , module_name : str ) -> Union [ str , NoneType ] View Source def find ( self , module_name : str ) -> Optional [ str ]: if module_name . startswith ( \" . \" ) : return self . sections . LOCALFOLDER return None PathFinder class PathFinder ( config : Mapping [ str , Any ], sections : Any ) View Source class PathFinder ( BaseFinder ): def __init__ ( self , config : Mapping [ str , Any ], sections : Any ) -> None : super () . __init__ ( config , sections ) # restore the original import path (i.e. not the path to bin/isort) root_dir = os . getcwd () src_dir = \"{0}/src\" . format ( root_dir ) self . paths = [ root_dir , src_dir ] # virtual env self . virtual_env = self . config . get ( \"virtual_env\" ) or os . environ . get ( \"VIRTUAL_ENV\" ) if self . virtual_env : self . virtual_env = os . path . realpath ( self . virtual_env ) self . virtual_env_src = \"\" if self . virtual_env : self . virtual_env_src = \"{}/src/\" . format ( self . virtual_env ) for path in glob ( \"{}/lib/python*/site-packages\" . format ( self . virtual_env )): if path not in self . paths : self . paths . append ( path ) for path in glob ( \"{}/lib/python*/*/site-packages\" . format ( self . virtual_env )): if path not in self . paths : self . paths . append ( path ) for path in glob ( \"{}/src/*\" . format ( self . virtual_env )): if os . path . isdir ( path ): self . paths . append ( path ) # conda self . conda_env = ( self . config . get ( \"conda_env\" ) or os . environ . get ( \"CONDA_PREFIX\" ) or \"\" ) if self . conda_env : self . conda_env = os . path . realpath ( self . conda_env ) for path in glob ( \"{}/lib/python*/site-packages\" . format ( self . conda_env )): if path not in self . paths : self . paths . append ( path ) for path in glob ( \"{}/lib/python*/*/site-packages\" . format ( self . conda_env )): if path not in self . paths : self . paths . append ( path ) # handle case-insensitive paths on windows self . stdlib_lib_prefix = os . path . normcase ( sysconfig . get_paths ()[ \"stdlib\" ]) if self . stdlib_lib_prefix not in self . paths : self . paths . append ( self . stdlib_lib_prefix ) # handle compiled libraries self . ext_suffix = sysconfig . get_config_var ( \"EXT_SUFFIX\" ) or \".so\" # add system paths for path in sys . path [ 1 :]: if path not in self . paths : self . paths . append ( path ) def find ( self , module_name : str ) -> Optional [ str ]: for prefix in self . paths : package_path = \"/\" . join (( prefix , module_name . split ( \".\" )[ 0 ])) is_module = ( exists_case_sensitive ( package_path + \".py\" ) or exists_case_sensitive ( package_path + \".so\" ) or exists_case_sensitive ( package_path + self . ext_suffix ) or exists_case_sensitive ( package_path + \"/__init__.py\" ) ) is_package = exists_case_sensitive ( package_path ) and os . path . isdir ( package_path ) if is_module or is_package : if \"site-packages\" in prefix : return self . sections . THIRDPARTY if \"dist-packages\" in prefix : return self . sections . THIRDPARTY if self . virtual_env and self . virtual_env_src in prefix : return self . sections . THIRDPARTY if self . conda_env and self . conda_env in prefix : return self . sections . THIRDPARTY if os . path . normcase ( prefix ) . startswith ( self . stdlib_lib_prefix ): return self . sections . STDLIB return self . config [ \"default_section\" ] return None Ancestors (in MRO) isort.finders.BaseFinder Methods find def find ( self , module_name : str ) -> Union [ str , NoneType ] View Source def find ( self , module_name : str ) -> Optional [ str ]: for prefix in self . paths : package_path = \" / \" . join (( prefix , module_name . split ( \" . \" ) [ 0 ] )) is_module = ( exists_case_sensitive ( package_path + \" .py \" ) or exists_case_sensitive ( package_path + \" .so \" ) or exists_case_sensitive ( package_path + self . ext_suffix ) or exists_case_sensitive ( package_path + \" /__init__.py \" ) ) is_package = exists_case_sensitive ( package_path ) and os . path . isdir ( package_path ) if is_module or is_package : if \" site-packages \" in prefix : return self . sections . THIRDPARTY if \" dist-packages \" in prefix : return self . sections . THIRDPARTY if self . virtual_env and self . virtual_env_src in prefix : return self . sections . THIRDPARTY if self . conda_env and self . conda_env in prefix : return self . sections . THIRDPARTY if os . path . normcase ( prefix ) . startswith ( self . stdlib_lib_prefix ) : return self . sections . STDLIB return self . config [ \" default_section \" ] return None PipfileFinder class PipfileFinder ( config : Mapping [ str , Any ], sections : Any , path : str = '.' ) View Source class PipfileFinder ( ReqsBaseFinder ) : enabled = bool ( Pipfile ) def _get_names ( self , path : str ) -> Iterator [ str ]: with chdir ( path ) : project = Pipfile . load ( path ) for req in project . packages : yield req . name def _get_files_from_dir ( self , path : str ) -> Iterator [ str ]: if \" Pipfile \" in os . listdir ( path ) : yield path Ancestors (in MRO) isort.finders.ReqsBaseFinder isort.finders.BaseFinder Class variables enabled Methods find def find ( self , module_name : str ) -> Union [ str , NoneType ] View Source def find ( self , module_name : str ) -> Optional [ str ]: # required lib not installed yet if not self . enabled : return None module_name , _sep , _submodules = module_name . partition ( \" . \" ) module_name = module_name . lower () if not module_name : return None for name in self . names : if module_name == name : return self . sections . THIRDPARTY return None ReqsBaseFinder class ReqsBaseFinder ( config : Mapping [ str , Any ], sections : Any , path : str = '.' ) View Source class ReqsBaseFinder ( BaseFinder ) : enabled = False def __ init__ ( self , config : Mapping [ str , Any ], sections : Any , path : str = \".\" ) -> None : super (). __ init__ ( config , sections ) self . path = path if self . enabled : self . mapping = self . _ load_mapping () self . names = self . _ load_names () @abstractmethod def _ get_names ( self , path : str ) -> Iterator [ str ] : raise NotImplementedError @abstractmethod def _ get_files_from_dir ( self , path : str ) -> Iterator [ str ] : raise NotImplementedError @staticmethod def _ load_mapping () -> Optional [ Dict [ str , str ]] : \"\"\"Return list of mappings `package_name -> module_name` Example: django-haystack -> haystack \"\"\" if not pipreqs : return None path = os . path . dirname ( inspect . getfile ( pipreqs )) path = os . path . join ( path , \"mapping\" ) with open ( path ) as f : # pypi_name: import_name mappings = {} # type : Dict [ str , str ] for line in f : import_name , _ , pypi_name = line . strip (). partition ( \":\" ) mappings [ pypi_name ] = import_name return mappings # return dict ( tuple ( line . strip (). split ( \":\" )[ ::- 1 ]) for line in f ) def _ load_names ( self ) -> List [ str ] : \"\"\"Return list of thirdparty modules from requirements \"\"\" names = [] for path in self . _ get_files () : for name in self . _ get_names ( path ) : names . append ( self . _ normalize_name ( name )) return names @staticmethod def _ get_parents ( path : str ) -> Iterator [ str ] : prev = \"\" while path ! = prev : prev = path yield path path = os . path . dirname ( path ) def _ get_files ( self ) -> Iterator [ str ] : \"\"\"Return paths to all requirements files \"\"\" path = os . path . abspath ( self . path ) if os . path . isfile ( path ) : path = os . path . dirname ( path ) for path in self . _ get_parents ( path ) : yield from self . _ get_files_from_dir ( path ) def _ normalize_name ( self , name : str ) -> str : \"\"\"Convert package name to module name Examples: Django -> django django-haystack -> django_haystack Flask-RESTFul -> flask_restful \"\"\" if self . mapping : name = self . mapping . get ( name , name ) return name . lower (). replace ( \"-\" , \"_\" ) def find ( self , module_name: str ) -> Optional [ str ] : # required lib not installed yet if not self . enabled : return None module_name , _ sep , _ submodules = module_name . partition ( \".\" ) module_name = module_name . lower () if not module_name: return None for name in self . names : if module_name == name : return self . sections . THIRDPARTY return None Ancestors (in MRO) isort.finders.BaseFinder Descendants isort.finders.RequirementsFinder isort.finders.PipfileFinder Class variables enabled Methods find def find ( self , module_name : str ) -> Union [ str , NoneType ] View Source def find ( self , module_name : str ) -> Optional [ str ]: # required lib not installed yet if not self . enabled : return None module_name , _sep , _submodules = module_name . partition ( \" . \" ) module_name = module_name . lower () if not module_name : return None for name in self . names : if module_name == name : return self . sections . THIRDPARTY return None RequirementsFinder class RequirementsFinder ( config : Mapping [ str , Any ], sections : Any , path : str = '.' ) View Source class RequirementsFinder ( ReqsBaseFinder ) : exts = ( \" .txt \" , \" .in \" ) enabled = bool ( parse_requirements ) def _get_files_from_dir ( self , path : str ) -> Iterator [ str ]: \"\"\" Return paths to requirements files from passed dir. \"\"\" yield from self . _get_files_from_dir_cached ( path ) @ classmethod @ lru_cache ( maxsize = 16 ) def _get_files_from_dir_cached ( cls , path : str ) -> List [ str ]: results = [] for fname in os . listdir ( path ) : if \" requirements \" not in fname : continue full_path = os . path . join ( path , fname ) # * requirements */* .{ txt , in } if os . path . isdir ( full_path ) : for subfile_name in os . listdir ( full_path ) : for ext in cls . exts : if subfile_name . endswith ( ext ) : results . append ( os . path . join ( full_path , subfile_name )) continue # * requirements * .{ txt , in } if os . path . isfile ( full_path ) : for ext in cls . exts : if fname . endswith ( ext ) : results . append ( full_path ) break return results def _get_names ( self , path : str ) -> Iterator [ str ]: \"\"\" Load required packages from path to requirements file \"\"\" yield from self . _get_names_cached ( path ) @ classmethod @ lru_cache ( maxsize = 16 ) def _get_names_cached ( cls , path : str ) -> List [ str ]: result = [] with chdir ( os . path . dirname ( path )) : requirements = parse_requirements ( path ) for req in requirements . values () : if req . name : result . append ( req . name ) return result Ancestors (in MRO) isort.finders.ReqsBaseFinder isort.finders.BaseFinder Class variables enabled exts Methods find def find ( self , module_name : str ) -> Union [ str , NoneType ] View Source def find ( self , module_name : str ) -> Optional [ str ]: # required lib not installed yet if not self . enabled : return None module_name , _sep , _submodules = module_name . partition ( \" . \" ) module_name = module_name . lower () if not module_name : return None for name in self . names : if module_name == name : return self . sections . THIRDPARTY return None","title":"Finders"},{"location":"reference/isort/finders/#module-isortfinders","text":"Finders try to find right section for passed module name View Source \"\"\"Finders try to find right section for passed module name \"\"\" import inspect import os import os . path import re import sys import sysconfig from abc import ABCMeta , abstractmethod from fnmatch import fnmatch from functools import lru_cache from glob import glob from typing import ( Any , Dict , Iterable , Iterator , List , Mapping , Optional , Pattern , Sequence , Tuple , Type , ) from . utils import chdir , exists_case_sensitive try : from pipreqs import pipreqs except ImportError : pipreqs = None try : from pip_api import parse_requirements except ImportError : parse_requirements = None try : from requirementslib import Pipfile except ImportError : Pipfile = None KNOWN_SECTION_MAPPING = { \"STDLIB\" : \"STANDARD_LIBRARY\" , \"FUTURE\" : \"FUTURE_LIBRARY\" , \"FIRSTPARTY\" : \"FIRST_PARTY\" , \"THIRDPARTY\" : \"THIRD_PARTY\" , } class BaseFinder ( metaclass = ABCMeta ) : def __ init__ ( self , config : Mapping [ str , Any ], sections : Any ) -> None : self . config = config self . sections = sections @abstractmethod def find ( self , module_name: str ) -> Optional [ str ] : raise NotImplementedError class ForcedSeparateFinder ( BaseFinder ) : def find ( self , module_name: str ) -> Optional [ str ] : for forced_separate in self . config [ \"forced_separate\" ] : # Ensure all forced_separate patterns will match to end of string path_glob = forced_separate if not forced_separate . endswith ( \"*\" ) : path_glob = \"%s*\" % forced_separate if fnmatch ( module_name , path_glob ) or fnmatch ( module_name , \".\" + path_glob ) : return forced_separate return None class LocalFinder ( BaseFinder ) : def find ( self , module_name: str ) -> Optional [ str ] : if module_name . startswith ( \".\" ) : return self . sections . LOCALFOLDER return None class KnownPatternFinder ( BaseFinder ) : def __ init__ ( self , config : Mapping [ str , Any ], sections : Any ) -> None : super (). __ init__ ( config , sections ) self . known_patterns = [] # type : List [ Tuple [ Pattern [ str ], str ]] for placement in reversed ( self . sections ) : known_placement = KNOWN_SECTION_MAPPING . get ( placement , placement ) config_key = \"known_{}\" . format ( known_placement . lower ()) known_patterns = self . config . get ( config_key , []) known_patterns = [ pattern for known_pattern in known_patterns for pattern in self . _ parse_known_pattern ( known_pattern ) ] for known_pattern in known_patterns: regexp = \"^\" + known_pattern . replace ( \"*\" , \".*\" ). replace ( \"?\" , \".?\" ) + \"$\" self . known_patterns . append (( re . compile ( regexp ), placement )) def _ parse_known_pattern ( self , pattern : str ) -> List [ str ] : \"\"\" Expand pattern if identified as a directory and return found sub packages \"\"\" if pattern . endswith ( os . path . sep ) : patterns = [ filename for filename in os . listdir ( pattern ) if os . path . isdir ( os . path . join ( pattern , filename )) ] else : patterns = [ pattern ] return patterns def find ( self , module_name: str ) -> Optional [ str ] : # Try to find most specific placement instruction match ( if any ) parts = module_name . split ( \".\" ) module_names_to_check = ( \".\" . join ( parts [ :first_k ]) for first_k in range ( len ( parts ), 0 , - 1 ) ) for module_name_to_check in module_names_to_check: for pattern , placement in self . known_patterns: if pattern . match ( module_name_to_check ) : return placement return None class PathFinder ( BaseFinder ) : def __ init__ ( self , config : Mapping [ str , Any ], sections : Any ) -> None : super (). __ init__ ( config , sections ) # restore the original import path ( i . e . not the path to bin / isort ) root_dir = os . getcwd () src_dir = \"{0}/src\" . format ( root_dir ) self . paths = [ root_dir , src_dir ] # virtual env self . virtual_env = self . config . get ( \"virtual_env\" ) or os . environ . get ( \"VIRTUAL_ENV\" ) if self . virtual_env: self . virtual_env = os . path . realpath ( self . virtual_env ) self . virtual_env_src = \"\" if self . virtual_env: self . virtual_env_src = \"{}/src/\" . format ( self . virtual_env ) for path in glob ( \"{}/lib/python*/site-packages\" . format ( self . virtual_env )) : if path not in self . paths : self . paths . append ( path ) for path in glob ( \"{}/lib/python*/*/site-packages\" . format ( self . virtual_env )) : if path not in self . paths : self . paths . append ( path ) for path in glob ( \"{}/src/*\" . format ( self . virtual_env )) : if os . path . isdir ( path ) : self . paths . append ( path ) # conda self . conda_env = ( self . config . get ( \"conda_env\" ) or os . environ . get ( \"CONDA_PREFIX\" ) or \"\" ) if self . conda_env: self . conda_env = os . path . realpath ( self . conda_env ) for path in glob ( \"{}/lib/python*/site-packages\" . format ( self . conda_env )) : if path not in self . paths : self . paths . append ( path ) for path in glob ( \"{}/lib/python*/*/site-packages\" . format ( self . conda_env )) : if path not in self . paths : self . paths . append ( path ) # handle case - insensitive paths on windows self . stdlib_lib_prefix = os . path . normcase ( sysconfig . get_paths ()[ \"stdlib\" ]) if self . stdlib_lib_prefix not in self . paths : self . paths . append ( self . stdlib_lib_prefix ) # handle compiled libraries self . ext_suffix = sysconfig . get_config_var ( \"EXT_SUFFIX\" ) or \".so\" # add system paths for path in sys . path [ 1 : ] : if path not in self . paths : self . paths . append ( path ) def find ( self , module_name: str ) -> Optional [ str ] : for prefix in self . paths : package_path = \"/\" . join (( prefix , module_name . split ( \".\" )[ 0 ])) is_module = ( exists_case_sensitive ( package_path + \".py\" ) or exists_case_sensitive ( package_path + \".so\" ) or exists_case_sensitive ( package_path + self . ext_suffix ) or exists_case_sensitive ( package_path + \"/__init__.py\" ) ) is_package = exists_case_sensitive ( package_path ) and os . path . isdir ( package_path ) if is_module or is_package: if \"site-packages\" in prefix : return self . sections . THIRDPARTY if \"dist-packages\" in prefix : return self . sections . THIRDPARTY if self . virtual_env and self . virtual_env_src in prefix : return self . sections . THIRDPARTY if self . conda_env and self . conda_env in prefix : return self . sections . THIRDPARTY if os . path . normcase ( prefix ). startswith ( self . stdlib_lib_prefix ) : return self . sections . STDLIB return self . config [ \"default_section\" ] return None class ReqsBaseFinder ( BaseFinder ) : enabled = False def __ init__ ( self , config : Mapping [ str , Any ], sections : Any , path : str = \".\" ) -> None : super (). __ init__ ( config , sections ) self . path = path if self . enabled : self . mapping = self . _ load_mapping () self . names = self . _ load_names () @abstractmethod def _ get_names ( self , path : str ) -> Iterator [ str ] : raise NotImplementedError @abstractmethod def _ get_files_from_dir ( self , path : str ) -> Iterator [ str ] : raise NotImplementedError @staticmethod def _ load_mapping () -> Optional [ Dict [ str , str ]] : \"\"\"Return list of mappings `package_name -> module_name` Example: django-haystack -> haystack \"\"\" if not pipreqs : return None path = os . path . dirname ( inspect . getfile ( pipreqs )) path = os . path . join ( path , \"mapping\" ) with open ( path ) as f : # pypi_name: import_name mappings = {} # type : Dict [ str , str ] for line in f : import_name , _ , pypi_name = line . strip (). partition ( \":\" ) mappings [ pypi_name ] = import_name return mappings # return dict ( tuple ( line . strip (). split ( \":\" )[ ::- 1 ]) for line in f ) def _ load_names ( self ) -> List [ str ] : \"\"\"Return list of thirdparty modules from requirements \"\"\" names = [] for path in self . _ get_files () : for name in self . _ get_names ( path ) : names . append ( self . _ normalize_name ( name )) return names @staticmethod def _ get_parents ( path : str ) -> Iterator [ str ] : prev = \"\" while path ! = prev : prev = path yield path path = os . path . dirname ( path ) def _ get_files ( self ) -> Iterator [ str ] : \"\"\"Return paths to all requirements files \"\"\" path = os . path . abspath ( self . path ) if os . path . isfile ( path ) : path = os . path . dirname ( path ) for path in self . _ get_parents ( path ) : yield from self . _ get_files_from_dir ( path ) def _ normalize_name ( self , name : str ) -> str : \"\"\"Convert package name to module name Examples: Django -> django django-haystack -> django_haystack Flask-RESTFul -> flask_restful \"\"\" if self . mapping : name = self . mapping . get ( name , name ) return name . lower (). replace ( \"-\" , \"_\" ) def find ( self , module_name: str ) -> Optional [ str ] : # required lib not installed yet if not self . enabled : return None module_name , _ sep , _ submodules = module_name . partition ( \".\" ) module_name = module_name . lower () if not module_name: return None for name in self . names : if module_name == name : return self . sections . THIRDPARTY return None class RequirementsFinder ( ReqsBaseFinder ) : exts = ( \".txt\" , \".in\" ) enabled = bool ( parse_requirements ) def _ get_files_from_dir ( self , path : str ) -> Iterator [ str ] : \"\"\"Return paths to requirements files from passed dir. \"\"\" yield from self . _ get_files_from_dir_cached ( path ) @classmethod @ lru_cache ( maxsize = 16 ) def _ get_files_from_dir_cached ( cls , path : str ) -> List [ str ] : results = [] for fname in os . listdir ( path ) : if \"requirements\" not in fname : continue full_path = os . path . join ( path , fname ) # * requirements*/*. { txt , in } if os . path . isdir ( full_path ) : for subfile_name in os . listdir ( full_path ) : for ext in cls . exts : if subfile_name . endswith ( ext ) : results . append ( os . path . join ( full_path , subfile_name )) continue # * requirements*. { txt , in } if os . path . isfile ( full_path ) : for ext in cls . exts : if fname . endswith ( ext ) : results . append ( full_path ) break return results def _ get_names ( self , path : str ) -> Iterator [ str ] : \"\"\"Load required packages from path to requirements file \"\"\" yield from self . _ get_names_cached ( path ) @classmethod @ lru_cache ( maxsize = 16 ) def _ get_names_cached ( cls , path : str ) -> List [ str ] : result = [] with chdir ( os . path . dirname ( path )) : requirements = parse_requirements ( path ) for req in requirements . values () : if req . name : result . append ( req . name ) return result class PipfileFinder ( ReqsBaseFinder ) : enabled = bool ( Pipfile ) def _ get_names ( self , path : str ) -> Iterator [ str ] : with chdir ( path ) : project = Pipfile . load ( path ) for req in project . packages : yield req . name def _ get_files_from_dir ( self , path : str ) -> Iterator [ str ] : if \"Pipfile\" in os . listdir ( path ) : yield path class DefaultFinder ( BaseFinder ) : def find ( self , module_name: str ) -> Optional [ str ] : return self . config [ \"default_section\" ] class FindersManager : _ default_finders_classes = ( ForcedSeparateFinder , LocalFinder , KnownPatternFinder , PathFinder , PipfileFinder , RequirementsFinder , DefaultFinder , ) # type : Sequence [ Type [ BaseFinder ]] def __ init__ ( self , config : Mapping [ str , Any ], sections : Any , finder_classes: Optional [ Iterable [ Type [ BaseFinder ]]] = None , ) -> None : self . verbose = config . get ( \"verbose\" , False ) # type : bool if finder_classes is None : finder_classes = self . _ default_finders_classes finders = [] # type : List [ BaseFinder ] for finder_cls in finder_classes: try : finders . append ( finder_cls ( config , sections )) except Exception as exception : # if one finder fails to instantiate isort can continue using the rest if self . verbose : print ( \"{} encountered an error ({}) during instantiation and cannot be used\" . format ( finder_cls . __ name__ , str ( exception ) ) ) self . finders = tuple ( finders ) # type : Tuple [ BaseFinder , ...] def find ( self , module_name: str ) -> Optional [ str ] : for finder in self . finders : try : section = finder . find ( module_name ) except Exception as exception : # isort has to be able to keep trying to identify the correct import section even if one approach fails if self . verbose : print ( \"{} encountered an error ({}) while trying to identify the {} module\" . format ( finder . __ class__ . __ name__ , str ( exception ), module_name ) ) if section is not None : return section return None","title":"Module isort.finders"},{"location":"reference/isort/finders/#variables","text":"KNOWN_SECTION_MAPPING","title":"Variables"},{"location":"reference/isort/finders/#classes","text":"","title":"Classes"},{"location":"reference/isort/finders/#basefinder","text":"class BaseFinder ( config : Mapping [ str , Any ], sections : Any ) View Source class BaseFinder ( metaclass = ABCMeta ) : def __init__ ( self , config : Mapping [ str, Any ] , sections : Any ) -> None : self . config = config self . sections = sections @abstractmethod def find ( self , module_name : str ) -> Optional [ str ] : raise NotImplementedError","title":"BaseFinder"},{"location":"reference/isort/finders/#descendants","text":"isort.finders.ForcedSeparateFinder isort.finders.LocalFinder isort.finders.KnownPatternFinder isort.finders.PathFinder isort.finders.ReqsBaseFinder isort.finders.DefaultFinder","title":"Descendants"},{"location":"reference/isort/finders/#methods","text":"","title":"Methods"},{"location":"reference/isort/finders/#find","text":"def find ( self , module_name : str ) -> Union [ str , NoneType ] View Source @abstractmethod def find ( self , module_name : str ) -> Optional [ str ] : raise NotImplementedError","title":"find"},{"location":"reference/isort/finders/#defaultfinder","text":"class DefaultFinder ( config : Mapping [ str , Any ], sections : Any ) View Source class DefaultFinder ( BaseFinder ) : def find ( self , module_name : str ) -> Optional [ str ]: return self . config [ \" default_section \" ]","title":"DefaultFinder"},{"location":"reference/isort/finders/#ancestors-in-mro","text":"isort.finders.BaseFinder","title":"Ancestors (in MRO)"},{"location":"reference/isort/finders/#methods_1","text":"","title":"Methods"},{"location":"reference/isort/finders/#find_1","text":"def find ( self , module_name : str ) -> Union [ str , NoneType ] View Source def find ( self , module_name : str ) -> Optional [ str ]: return self . config [ \" default_section \" ]","title":"find"},{"location":"reference/isort/finders/#findersmanager","text":"class FindersManager ( config : Mapping [ str , Any ], sections : Any , finder_classes : Union [ Iterable [ Type [ isort . finders . BaseFinder ]], NoneType ] = None ) View Source class FindersManager : _default_finders_classes = ( ForcedSeparateFinder , LocalFinder , KnownPatternFinder , PathFinder , PipfileFinder , RequirementsFinder , DefaultFinder , ) # type : Sequence [ Type [ BaseFinder ]] def __init__ ( self , config : Mapping [ str , Any ], sections : Any , finder_classes : Optional [ Iterable [ Type [ BaseFinder ]]] = None , ) -> None : self . verbose = config . get ( \" verbose \" , False ) # type : bool if finder_classes is None : finder_classes = self . _default_finders_classes finders = [] # type : List [ BaseFinder ] for finder_cls in finder_classes : try : finders . append ( finder_cls ( config , sections )) except Exception as exception : # if one finder fails to instantiate isort can continue using the rest if self . verbose : print ( \" {} encountered an error ({}) during instantiation and cannot be used \" . format ( finder_cls . __name__ , str ( exception ) ) ) self . finders = tuple ( finders ) # type : Tuple [ BaseFinder , ...] def find ( self , module_name : str ) -> Optional [ str ]: for finder in self . finders : try : section = finder . find ( module_name ) except Exception as exception : # isort has to be able to keep trying to identify the correct import section even if one approach fails if self . verbose : print ( \" {} encountered an error ({}) while trying to identify the {} module \" . format ( finder . __class__ . __name__ , str ( exception ) , module_name ) ) if section is not None : return section return None","title":"FindersManager"},{"location":"reference/isort/finders/#methods_2","text":"","title":"Methods"},{"location":"reference/isort/finders/#find_2","text":"def find ( self , module_name : str ) -> Union [ str , NoneType ] View Source def find ( self , module_name : str ) -> Optional [ str ]: for finder in self . finders : try : section = finder . find ( module_name ) except Exception as exception : # isort has to be able to keep trying to identify the correct import section even if one approach fails if self . verbose : print ( \"{} encountered an error ({}) while trying to identify the {} module\" . format ( finder . __class__ . __name__ , str ( exception ), module_name ) ) if section is not None : return section return None","title":"find"},{"location":"reference/isort/finders/#forcedseparatefinder","text":"class ForcedSeparateFinder ( config : Mapping [ str , Any ], sections : Any ) View Source class ForcedSeparateFinder ( BaseFinder ) : def find ( self , module_name : str ) -> Optional [ str ]: for forced_separate in self . config [ \" forced_separate \" ]: # Ensure all forced_separate patterns will match to end of string path_glob = forced_separate if not forced_separate . endswith ( \" * \" ) : path_glob = \" %s* \" % forced_separate if fnmatch ( module_name , path_glob ) or fnmatch ( module_name , \" . \" + path_glob ) : return forced_separate return None","title":"ForcedSeparateFinder"},{"location":"reference/isort/finders/#ancestors-in-mro_1","text":"isort.finders.BaseFinder","title":"Ancestors (in MRO)"},{"location":"reference/isort/finders/#methods_3","text":"","title":"Methods"},{"location":"reference/isort/finders/#find_3","text":"def find ( self , module_name : str ) -> Union [ str , NoneType ] View Source def find ( self , module_name : str ) -> Optional [ str ]: for forced_separate in self . config [ \" forced_separate \" ]: # Ensure all forced_separate patterns will match to end of string path_glob = forced_separate if not forced_separate . endswith ( \" * \" ) : path_glob = \" %s* \" % forced_separate if fnmatch ( module_name , path_glob ) or fnmatch ( module_name , \" . \" + path_glob ) : return forced_separate return None","title":"find"},{"location":"reference/isort/finders/#knownpatternfinder","text":"class KnownPatternFinder ( config : Mapping [ str , Any ], sections : Any ) View Source class KnownPatternFinder ( BaseFinder ) : def __init__ ( self , config : Mapping [ str , Any ], sections : Any ) -> None : super () . __init__ ( config , sections ) self . known_patterns = [] # type : List [ Tuple [ Pattern [ str ], str ]] for placement in reversed ( self . sections ) : known_placement = KNOWN_SECTION_MAPPING . get ( placement , placement ) config_key = \" known_{} \" . format ( known_placement . lower ()) known_patterns = self . config . get ( config_key , [] ) known_patterns = [ pattern for known_pattern in known_patterns for pattern in self . _parse_known_pattern ( known_pattern ) ] for known_pattern in known_patterns : regexp = \" ^ \" + known_pattern . replace ( \" * \" , \" .* \" ) . replace ( \" ? \" , \" .? \" ) + \" $ \" self . known_patterns . append (( re . compile ( regexp ) , placement )) def _parse_known_pattern ( self , pattern : str ) -> List [ str ]: \"\"\" Expand pattern if identified as a directory and return found sub packages \"\"\" if pattern . endswith ( os . path . sep ) : patterns = [ filename for filename in os . listdir ( pattern ) if os . path . isdir ( os . path . join ( pattern , filename )) ] else : patterns = [ pattern ] return patterns def find ( self , module_name : str ) -> Optional [ str ]: # Try to find most specific placement instruction match ( if any ) parts = module_name . split ( \" . \" ) module_names_to_check = ( \" . \" . join ( parts [: first_k ] ) for first_k in range ( len ( parts ) , 0 , - 1 ) ) for module_name_to_check in module_names_to_check : for pattern , placement in self . known_patterns : if pattern . match ( module_name_to_check ) : return placement return None","title":"KnownPatternFinder"},{"location":"reference/isort/finders/#ancestors-in-mro_2","text":"isort.finders.BaseFinder","title":"Ancestors (in MRO)"},{"location":"reference/isort/finders/#methods_4","text":"","title":"Methods"},{"location":"reference/isort/finders/#find_4","text":"def find ( self , module_name : str ) -> Union [ str , NoneType ] View Source def find ( self , module_name : str ) -> Optional [ str ]: # Try to find most specific placement instruction match ( if any ) parts = module_name . split ( \" . \" ) module_names_to_check = ( \" . \" . join ( parts [: first_k ] ) for first_k in range ( len ( parts ) , 0 , - 1 ) ) for module_name_to_check in module_names_to_check : for pattern , placement in self . known_patterns : if pattern . match ( module_name_to_check ) : return placement return None","title":"find"},{"location":"reference/isort/finders/#localfinder","text":"class LocalFinder ( config : Mapping [ str , Any ], sections : Any ) View Source class LocalFinder ( BaseFinder ) : def find ( self , module_name : str ) -> Optional [ str ]: if module_name . startswith ( \" . \" ) : return self . sections . LOCALFOLDER return None","title":"LocalFinder"},{"location":"reference/isort/finders/#ancestors-in-mro_3","text":"isort.finders.BaseFinder","title":"Ancestors (in MRO)"},{"location":"reference/isort/finders/#methods_5","text":"","title":"Methods"},{"location":"reference/isort/finders/#find_5","text":"def find ( self , module_name : str ) -> Union [ str , NoneType ] View Source def find ( self , module_name : str ) -> Optional [ str ]: if module_name . startswith ( \" . \" ) : return self . sections . LOCALFOLDER return None","title":"find"},{"location":"reference/isort/finders/#pathfinder","text":"class PathFinder ( config : Mapping [ str , Any ], sections : Any ) View Source class PathFinder ( BaseFinder ): def __init__ ( self , config : Mapping [ str , Any ], sections : Any ) -> None : super () . __init__ ( config , sections ) # restore the original import path (i.e. not the path to bin/isort) root_dir = os . getcwd () src_dir = \"{0}/src\" . format ( root_dir ) self . paths = [ root_dir , src_dir ] # virtual env self . virtual_env = self . config . get ( \"virtual_env\" ) or os . environ . get ( \"VIRTUAL_ENV\" ) if self . virtual_env : self . virtual_env = os . path . realpath ( self . virtual_env ) self . virtual_env_src = \"\" if self . virtual_env : self . virtual_env_src = \"{}/src/\" . format ( self . virtual_env ) for path in glob ( \"{}/lib/python*/site-packages\" . format ( self . virtual_env )): if path not in self . paths : self . paths . append ( path ) for path in glob ( \"{}/lib/python*/*/site-packages\" . format ( self . virtual_env )): if path not in self . paths : self . paths . append ( path ) for path in glob ( \"{}/src/*\" . format ( self . virtual_env )): if os . path . isdir ( path ): self . paths . append ( path ) # conda self . conda_env = ( self . config . get ( \"conda_env\" ) or os . environ . get ( \"CONDA_PREFIX\" ) or \"\" ) if self . conda_env : self . conda_env = os . path . realpath ( self . conda_env ) for path in glob ( \"{}/lib/python*/site-packages\" . format ( self . conda_env )): if path not in self . paths : self . paths . append ( path ) for path in glob ( \"{}/lib/python*/*/site-packages\" . format ( self . conda_env )): if path not in self . paths : self . paths . append ( path ) # handle case-insensitive paths on windows self . stdlib_lib_prefix = os . path . normcase ( sysconfig . get_paths ()[ \"stdlib\" ]) if self . stdlib_lib_prefix not in self . paths : self . paths . append ( self . stdlib_lib_prefix ) # handle compiled libraries self . ext_suffix = sysconfig . get_config_var ( \"EXT_SUFFIX\" ) or \".so\" # add system paths for path in sys . path [ 1 :]: if path not in self . paths : self . paths . append ( path ) def find ( self , module_name : str ) -> Optional [ str ]: for prefix in self . paths : package_path = \"/\" . join (( prefix , module_name . split ( \".\" )[ 0 ])) is_module = ( exists_case_sensitive ( package_path + \".py\" ) or exists_case_sensitive ( package_path + \".so\" ) or exists_case_sensitive ( package_path + self . ext_suffix ) or exists_case_sensitive ( package_path + \"/__init__.py\" ) ) is_package = exists_case_sensitive ( package_path ) and os . path . isdir ( package_path ) if is_module or is_package : if \"site-packages\" in prefix : return self . sections . THIRDPARTY if \"dist-packages\" in prefix : return self . sections . THIRDPARTY if self . virtual_env and self . virtual_env_src in prefix : return self . sections . THIRDPARTY if self . conda_env and self . conda_env in prefix : return self . sections . THIRDPARTY if os . path . normcase ( prefix ) . startswith ( self . stdlib_lib_prefix ): return self . sections . STDLIB return self . config [ \"default_section\" ] return None","title":"PathFinder"},{"location":"reference/isort/finders/#ancestors-in-mro_4","text":"isort.finders.BaseFinder","title":"Ancestors (in MRO)"},{"location":"reference/isort/finders/#methods_6","text":"","title":"Methods"},{"location":"reference/isort/finders/#find_6","text":"def find ( self , module_name : str ) -> Union [ str , NoneType ] View Source def find ( self , module_name : str ) -> Optional [ str ]: for prefix in self . paths : package_path = \" / \" . join (( prefix , module_name . split ( \" . \" ) [ 0 ] )) is_module = ( exists_case_sensitive ( package_path + \" .py \" ) or exists_case_sensitive ( package_path + \" .so \" ) or exists_case_sensitive ( package_path + self . ext_suffix ) or exists_case_sensitive ( package_path + \" /__init__.py \" ) ) is_package = exists_case_sensitive ( package_path ) and os . path . isdir ( package_path ) if is_module or is_package : if \" site-packages \" in prefix : return self . sections . THIRDPARTY if \" dist-packages \" in prefix : return self . sections . THIRDPARTY if self . virtual_env and self . virtual_env_src in prefix : return self . sections . THIRDPARTY if self . conda_env and self . conda_env in prefix : return self . sections . THIRDPARTY if os . path . normcase ( prefix ) . startswith ( self . stdlib_lib_prefix ) : return self . sections . STDLIB return self . config [ \" default_section \" ] return None","title":"find"},{"location":"reference/isort/finders/#pipfilefinder","text":"class PipfileFinder ( config : Mapping [ str , Any ], sections : Any , path : str = '.' ) View Source class PipfileFinder ( ReqsBaseFinder ) : enabled = bool ( Pipfile ) def _get_names ( self , path : str ) -> Iterator [ str ]: with chdir ( path ) : project = Pipfile . load ( path ) for req in project . packages : yield req . name def _get_files_from_dir ( self , path : str ) -> Iterator [ str ]: if \" Pipfile \" in os . listdir ( path ) : yield path","title":"PipfileFinder"},{"location":"reference/isort/finders/#ancestors-in-mro_5","text":"isort.finders.ReqsBaseFinder isort.finders.BaseFinder","title":"Ancestors (in MRO)"},{"location":"reference/isort/finders/#class-variables","text":"enabled","title":"Class variables"},{"location":"reference/isort/finders/#methods_7","text":"","title":"Methods"},{"location":"reference/isort/finders/#find_7","text":"def find ( self , module_name : str ) -> Union [ str , NoneType ] View Source def find ( self , module_name : str ) -> Optional [ str ]: # required lib not installed yet if not self . enabled : return None module_name , _sep , _submodules = module_name . partition ( \" . \" ) module_name = module_name . lower () if not module_name : return None for name in self . names : if module_name == name : return self . sections . THIRDPARTY return None","title":"find"},{"location":"reference/isort/finders/#reqsbasefinder","text":"class ReqsBaseFinder ( config : Mapping [ str , Any ], sections : Any , path : str = '.' ) View Source class ReqsBaseFinder ( BaseFinder ) : enabled = False def __ init__ ( self , config : Mapping [ str , Any ], sections : Any , path : str = \".\" ) -> None : super (). __ init__ ( config , sections ) self . path = path if self . enabled : self . mapping = self . _ load_mapping () self . names = self . _ load_names () @abstractmethod def _ get_names ( self , path : str ) -> Iterator [ str ] : raise NotImplementedError @abstractmethod def _ get_files_from_dir ( self , path : str ) -> Iterator [ str ] : raise NotImplementedError @staticmethod def _ load_mapping () -> Optional [ Dict [ str , str ]] : \"\"\"Return list of mappings `package_name -> module_name` Example: django-haystack -> haystack \"\"\" if not pipreqs : return None path = os . path . dirname ( inspect . getfile ( pipreqs )) path = os . path . join ( path , \"mapping\" ) with open ( path ) as f : # pypi_name: import_name mappings = {} # type : Dict [ str , str ] for line in f : import_name , _ , pypi_name = line . strip (). partition ( \":\" ) mappings [ pypi_name ] = import_name return mappings # return dict ( tuple ( line . strip (). split ( \":\" )[ ::- 1 ]) for line in f ) def _ load_names ( self ) -> List [ str ] : \"\"\"Return list of thirdparty modules from requirements \"\"\" names = [] for path in self . _ get_files () : for name in self . _ get_names ( path ) : names . append ( self . _ normalize_name ( name )) return names @staticmethod def _ get_parents ( path : str ) -> Iterator [ str ] : prev = \"\" while path ! = prev : prev = path yield path path = os . path . dirname ( path ) def _ get_files ( self ) -> Iterator [ str ] : \"\"\"Return paths to all requirements files \"\"\" path = os . path . abspath ( self . path ) if os . path . isfile ( path ) : path = os . path . dirname ( path ) for path in self . _ get_parents ( path ) : yield from self . _ get_files_from_dir ( path ) def _ normalize_name ( self , name : str ) -> str : \"\"\"Convert package name to module name Examples: Django -> django django-haystack -> django_haystack Flask-RESTFul -> flask_restful \"\"\" if self . mapping : name = self . mapping . get ( name , name ) return name . lower (). replace ( \"-\" , \"_\" ) def find ( self , module_name: str ) -> Optional [ str ] : # required lib not installed yet if not self . enabled : return None module_name , _ sep , _ submodules = module_name . partition ( \".\" ) module_name = module_name . lower () if not module_name: return None for name in self . names : if module_name == name : return self . sections . THIRDPARTY return None","title":"ReqsBaseFinder"},{"location":"reference/isort/finders/#ancestors-in-mro_6","text":"isort.finders.BaseFinder","title":"Ancestors (in MRO)"},{"location":"reference/isort/finders/#descendants_1","text":"isort.finders.RequirementsFinder isort.finders.PipfileFinder","title":"Descendants"},{"location":"reference/isort/finders/#class-variables_1","text":"enabled","title":"Class variables"},{"location":"reference/isort/finders/#methods_8","text":"","title":"Methods"},{"location":"reference/isort/finders/#find_8","text":"def find ( self , module_name : str ) -> Union [ str , NoneType ] View Source def find ( self , module_name : str ) -> Optional [ str ]: # required lib not installed yet if not self . enabled : return None module_name , _sep , _submodules = module_name . partition ( \" . \" ) module_name = module_name . lower () if not module_name : return None for name in self . names : if module_name == name : return self . sections . THIRDPARTY return None","title":"find"},{"location":"reference/isort/finders/#requirementsfinder","text":"class RequirementsFinder ( config : Mapping [ str , Any ], sections : Any , path : str = '.' ) View Source class RequirementsFinder ( ReqsBaseFinder ) : exts = ( \" .txt \" , \" .in \" ) enabled = bool ( parse_requirements ) def _get_files_from_dir ( self , path : str ) -> Iterator [ str ]: \"\"\" Return paths to requirements files from passed dir. \"\"\" yield from self . _get_files_from_dir_cached ( path ) @ classmethod @ lru_cache ( maxsize = 16 ) def _get_files_from_dir_cached ( cls , path : str ) -> List [ str ]: results = [] for fname in os . listdir ( path ) : if \" requirements \" not in fname : continue full_path = os . path . join ( path , fname ) # * requirements */* .{ txt , in } if os . path . isdir ( full_path ) : for subfile_name in os . listdir ( full_path ) : for ext in cls . exts : if subfile_name . endswith ( ext ) : results . append ( os . path . join ( full_path , subfile_name )) continue # * requirements * .{ txt , in } if os . path . isfile ( full_path ) : for ext in cls . exts : if fname . endswith ( ext ) : results . append ( full_path ) break return results def _get_names ( self , path : str ) -> Iterator [ str ]: \"\"\" Load required packages from path to requirements file \"\"\" yield from self . _get_names_cached ( path ) @ classmethod @ lru_cache ( maxsize = 16 ) def _get_names_cached ( cls , path : str ) -> List [ str ]: result = [] with chdir ( os . path . dirname ( path )) : requirements = parse_requirements ( path ) for req in requirements . values () : if req . name : result . append ( req . name ) return result","title":"RequirementsFinder"},{"location":"reference/isort/finders/#ancestors-in-mro_7","text":"isort.finders.ReqsBaseFinder isort.finders.BaseFinder","title":"Ancestors (in MRO)"},{"location":"reference/isort/finders/#class-variables_2","text":"enabled exts","title":"Class variables"},{"location":"reference/isort/finders/#methods_9","text":"","title":"Methods"},{"location":"reference/isort/finders/#find_9","text":"def find ( self , module_name : str ) -> Union [ str , NoneType ] View Source def find ( self , module_name : str ) -> Optional [ str ]: # required lib not installed yet if not self . enabled : return None module_name , _sep , _submodules = module_name . partition ( \" . \" ) module_name = module_name . lower () if not module_name : return None for name in self . names : if module_name == name : return self . sections . THIRDPARTY return None","title":"find"},{"location":"reference/isort/format/","text":"Module isort.format View Source import sys from datetime import datetime from difflib import unified_diff from pathlib import Path from typing import Optional def format_simplified ( import_line : str ) -> str : import_line = import_line . strip () if import_line . startswith ( \"from \" ): import_line = import_line . replace ( \"from \" , \"\" ) import_line = import_line . replace ( \" import \" , \".\" ) elif import_line . startswith ( \"import \" ): import_line = import_line . replace ( \"import \" , \"\" ) return import_line def format_natural ( import_line : str ) -> str : import_line = import_line . strip () if not import_line . startswith ( \"from \" ) and not import_line . startswith ( \"import \" ): if \".\" not in import_line : return \"import {}\" . format ( import_line ) parts = import_line . split ( \".\" ) end = parts . pop ( - 1 ) return \"from {} import {}\" . format ( \".\" . join ( parts ), end ) return import_line def show_unified_diff ( * , file_input : str , file_output : str , file_path : Optional [ Path ] ) -> None : file_name = \"\" if file_path is None else str ( file_path ) file_mtime = str ( datetime . now () if file_path is None else datetime . fromtimestamp ( file_path . stat () . st_mtime ) ) unified_diff_lines = unified_diff ( file_input . splitlines ( keepends = True ), file_output . splitlines ( keepends = True ), fromfile = file_name + \":before\" , tofile = file_name + \":after\" , fromfiledate = file_mtime , tofiledate = str ( datetime . now ()), ) for line in unified_diff_lines : sys . stdout . write ( line ) def ask_whether_to_apply_changes_to_file ( file_path : str ) -> bool : answer = None while answer not in ( \"yes\" , \"y\" , \"no\" , \"n\" , \"quit\" , \"q\" ): answer = input ( \"Apply suggested changes to '{}' [y/n/q]? \" . format ( file_path ) ) . lower () if answer in ( \"no\" , \"n\" ): return False if answer in ( \"quit\" , \"q\" ): sys . exit ( 1 ) return True Functions ask_whether_to_apply_changes_to_file def ask_whether_to_apply_changes_to_file ( file_path : str ) -> bool View Source def ask_whether_to_apply_changes_to_file ( file_path : str ) -> bool : answer = None while answer not in ( \" yes \" , \" y \" , \" no \" , \" n \" , \" quit \" , \" q \" ) : answer = input ( \" Apply suggested changes to '{}' [y/n/q]? \" . format ( file_path ) ) . lower () if answer in ( \" no \" , \" n \" ) : return False if answer in ( \" quit \" , \" q \" ) : sys . exit ( 1 ) return True format_natural def format_natural ( import_line : str ) -> str View Source def format_natural ( import_line : str ) -> str : import_line = import_line . strip () if not import_line . startswith ( \"from \" ) and not import_line . startswith ( \"import \" ): if \".\" not in import_line : return \"import {}\" . format ( import_line ) parts = import_line . split ( \".\" ) end = parts . pop ( - 1 ) return \"from {} import {}\" . format ( \".\" . join ( parts ), end ) return import_line format_simplified def format_simplified ( import_line : str ) -> str View Source def format_simplified ( import_line : str ) -> str : import_line = import_line . strip () if import_line . startswith ( \"from \" ): import_line = import_line . replace ( \"from \" , \"\" ) import_line = import_line . replace ( \" import \" , \".\" ) elif import_line . startswith ( \"import \" ): import_line = import_line . replace ( \"import \" , \"\" ) return import_line show_unified_diff def show_unified_diff ( * , file_input : str , file_output : str , file_path : Union [ pathlib . Path , NoneType ] ) -> None View Source def show_unified_diff ( * , file_input : str , file_output : str , file_path : Optional [ Path ] ) -> None : file_name = \"\" if file_path is None else str ( file_path ) file_mtime = str ( datetime . now () if file_path is None else datetime . fromtimestamp ( file_path . stat () . st_mtime ) ) unified_diff_lines = unified_diff ( file_input . splitlines ( keepends = True ) , file_output . splitlines ( keepends = True ) , fromfile = file_name + \" :before \" , tofile = file_name + \" :after \" , fromfiledate = file_mtime , tofiledate = str ( datetime . now ()) , ) for line in unified_diff_lines : sys . stdout . write ( line )","title":"Format"},{"location":"reference/isort/format/#module-isortformat","text":"View Source import sys from datetime import datetime from difflib import unified_diff from pathlib import Path from typing import Optional def format_simplified ( import_line : str ) -> str : import_line = import_line . strip () if import_line . startswith ( \"from \" ): import_line = import_line . replace ( \"from \" , \"\" ) import_line = import_line . replace ( \" import \" , \".\" ) elif import_line . startswith ( \"import \" ): import_line = import_line . replace ( \"import \" , \"\" ) return import_line def format_natural ( import_line : str ) -> str : import_line = import_line . strip () if not import_line . startswith ( \"from \" ) and not import_line . startswith ( \"import \" ): if \".\" not in import_line : return \"import {}\" . format ( import_line ) parts = import_line . split ( \".\" ) end = parts . pop ( - 1 ) return \"from {} import {}\" . format ( \".\" . join ( parts ), end ) return import_line def show_unified_diff ( * , file_input : str , file_output : str , file_path : Optional [ Path ] ) -> None : file_name = \"\" if file_path is None else str ( file_path ) file_mtime = str ( datetime . now () if file_path is None else datetime . fromtimestamp ( file_path . stat () . st_mtime ) ) unified_diff_lines = unified_diff ( file_input . splitlines ( keepends = True ), file_output . splitlines ( keepends = True ), fromfile = file_name + \":before\" , tofile = file_name + \":after\" , fromfiledate = file_mtime , tofiledate = str ( datetime . now ()), ) for line in unified_diff_lines : sys . stdout . write ( line ) def ask_whether_to_apply_changes_to_file ( file_path : str ) -> bool : answer = None while answer not in ( \"yes\" , \"y\" , \"no\" , \"n\" , \"quit\" , \"q\" ): answer = input ( \"Apply suggested changes to '{}' [y/n/q]? \" . format ( file_path ) ) . lower () if answer in ( \"no\" , \"n\" ): return False if answer in ( \"quit\" , \"q\" ): sys . exit ( 1 ) return True","title":"Module isort.format"},{"location":"reference/isort/format/#functions","text":"","title":"Functions"},{"location":"reference/isort/format/#ask_whether_to_apply_changes_to_file","text":"def ask_whether_to_apply_changes_to_file ( file_path : str ) -> bool View Source def ask_whether_to_apply_changes_to_file ( file_path : str ) -> bool : answer = None while answer not in ( \" yes \" , \" y \" , \" no \" , \" n \" , \" quit \" , \" q \" ) : answer = input ( \" Apply suggested changes to '{}' [y/n/q]? \" . format ( file_path ) ) . lower () if answer in ( \" no \" , \" n \" ) : return False if answer in ( \" quit \" , \" q \" ) : sys . exit ( 1 ) return True","title":"ask_whether_to_apply_changes_to_file"},{"location":"reference/isort/format/#format_natural","text":"def format_natural ( import_line : str ) -> str View Source def format_natural ( import_line : str ) -> str : import_line = import_line . strip () if not import_line . startswith ( \"from \" ) and not import_line . startswith ( \"import \" ): if \".\" not in import_line : return \"import {}\" . format ( import_line ) parts = import_line . split ( \".\" ) end = parts . pop ( - 1 ) return \"from {} import {}\" . format ( \".\" . join ( parts ), end ) return import_line","title":"format_natural"},{"location":"reference/isort/format/#format_simplified","text":"def format_simplified ( import_line : str ) -> str View Source def format_simplified ( import_line : str ) -> str : import_line = import_line . strip () if import_line . startswith ( \"from \" ): import_line = import_line . replace ( \"from \" , \"\" ) import_line = import_line . replace ( \" import \" , \".\" ) elif import_line . startswith ( \"import \" ): import_line = import_line . replace ( \"import \" , \"\" ) return import_line","title":"format_simplified"},{"location":"reference/isort/format/#show_unified_diff","text":"def show_unified_diff ( * , file_input : str , file_output : str , file_path : Union [ pathlib . Path , NoneType ] ) -> None View Source def show_unified_diff ( * , file_input : str , file_output : str , file_path : Optional [ Path ] ) -> None : file_name = \"\" if file_path is None else str ( file_path ) file_mtime = str ( datetime . now () if file_path is None else datetime . fromtimestamp ( file_path . stat () . st_mtime ) ) unified_diff_lines = unified_diff ( file_input . splitlines ( keepends = True ) , file_output . splitlines ( keepends = True ) , fromfile = file_name + \" :before \" , tofile = file_name + \" :after \" , fromfiledate = file_mtime , tofiledate = str ( datetime . now ()) , ) for line in unified_diff_lines : sys . stdout . write ( line )","title":"show_unified_diff"},{"location":"reference/isort/hooks/","text":"Module isort.hooks isort.py. Defines a git hook to allow pre-commit warnings and errors about import order. usage: exit_code = git_hook(strict=True|False, modify=True|False) Copyright (C) 2015 Helen Sherwood-Taylor Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. View Source \"\"\"isort.py. Defines a git hook to allow pre-commit warnings and errors about import order. usage: exit_code = git_hook(strict=True|False, modify=True|False) Copyright (C) 2015 Helen Sherwood-Taylor Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. \"\"\" import subprocess from typing import List from isort import SortImports def get_output ( command : List [ str ]) -> str : \"\"\" Run a command and return raw output :param str command: the command to run :returns: the stdout output of the command \"\"\" result = subprocess . run ( command , stdout = subprocess . PIPE , check = True ) return result . stdout . decode () def get_lines ( command : List [ str ]) -> List [ str ]: \"\"\" Run a command and return lines of output :param str command: the command to run :returns: list of whitespace-stripped lines output by command \"\"\" stdout = get_output ( command ) return [ line . strip () for line in stdout . splitlines ()] def git_hook ( strict : bool = False , modify : bool = False ) -> int : \"\"\" Git pre-commit hook to check staged files for isort errors :param bool strict - if True, return number of errors on exit, causing the hook to fail. If False, return zero so it will just act as a warning. :param bool modify - if True, fix the sources if they are not sorted properly. If False, only report result without modifying anything. :return number of errors if in strict mode, 0 otherwise. \"\"\" # Get list of files modified and staged diff_cmd = [ \"git\" , \"diff-index\" , \"--cached\" , \"--name-only\" , \"--diff-filter=ACMRTUXB HEAD\" , ] files_modified = get_lines ( diff_cmd ) errors = 0 for filename in files_modified : if filename . endswith ( \".py\" ): # Get the staged contents of the file staged_cmd = [ \"git\" , \"show\" , \": %s \" % filename ] staged_contents = get_output ( staged_cmd ) sort = SortImports ( file_path = filename , file_contents = staged_contents , check = True ) if sort . incorrectly_sorted : errors += 1 if modify : SortImports ( file_path = filename , file_contents = staged_contents , check = False ) return errors if strict else 0 Functions get_lines def get_lines ( command : List [ str ] ) -> List [ str ] Run a command and return lines of output :param str command: the command to run :returns: list of whitespace-stripped lines output by command View Source def get_lines ( command : List [ str ] ) -> List [ str ]: \"\"\" Run a command and return lines of output : param str command : the command to run : returns : list of whitespace - stripped lines output by command \"\"\" stdout = get_output ( command ) return [ line . strip () for line in stdout . splitlines () ] get_output def get_output ( command : List [ str ] ) -> str Run a command and return raw output :param str command: the command to run :returns: the stdout output of the command View Source def get_output ( command : List [ str ] ) -> str : \"\"\" Run a command and return raw output : param str command : the command to run : returns : the stdout output of the command \"\"\" result = subprocess . run ( command , stdout = subprocess . PIPE , check = True ) return result . stdout . decode () git_hook def git_hook ( strict : bool = False , modify : bool = False ) -> int Git pre-commit hook to check staged files for isort errors :param bool strict - if True, return number of errors on exit, causing the hook to fail. If False, return zero so it will just act as a warning. :param bool modify - if True, fix the sources if they are not sorted properly. If False, only report result without modifying anything. :return number of errors if in strict mode, 0 otherwise. View Source def git_hook ( strict : bool = False , modify : bool = False ) -> int : \"\"\" Git pre - commit hook to check staged files for isort errors : param bool strict - if True , return number of errors on exit , causing the hook to fail . If False , return zero so it will just act as a warning . : param bool modify - if True , fix the sources if they are not sorted properly . If False , only report result without modifying anything . : return number of errors if in strict mode , 0 otherwise . \"\"\" # Get list of files modified and staged diff_cmd = [ \" git \" , \" diff-index \" , \" --cached \" , \" --name-only \" , \" --diff-filter=ACMRTUXB HEAD \" , ] files_modified = get_lines ( diff_cmd ) errors = 0 for filename in files_modified : if filename . endswith ( \" .py \" ) : # Get the staged contents of the file staged_cmd = [ \" git \" , \" show \" , \" :%s \" % filename ] staged_contents = get_output ( staged_cmd ) sort = SortImports ( file_path = filename , file_contents = staged_contents , check = True ) if sort . incorrectly_sorted : errors += 1 if modify : SortImports ( file_path = filename , file_contents = staged_contents , check = False ) return errors if strict else 0","title":"Hooks"},{"location":"reference/isort/hooks/#module-isorthooks","text":"isort.py. Defines a git hook to allow pre-commit warnings and errors about import order. usage: exit_code = git_hook(strict=True|False, modify=True|False) Copyright (C) 2015 Helen Sherwood-Taylor Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. View Source \"\"\"isort.py. Defines a git hook to allow pre-commit warnings and errors about import order. usage: exit_code = git_hook(strict=True|False, modify=True|False) Copyright (C) 2015 Helen Sherwood-Taylor Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. \"\"\" import subprocess from typing import List from isort import SortImports def get_output ( command : List [ str ]) -> str : \"\"\" Run a command and return raw output :param str command: the command to run :returns: the stdout output of the command \"\"\" result = subprocess . run ( command , stdout = subprocess . PIPE , check = True ) return result . stdout . decode () def get_lines ( command : List [ str ]) -> List [ str ]: \"\"\" Run a command and return lines of output :param str command: the command to run :returns: list of whitespace-stripped lines output by command \"\"\" stdout = get_output ( command ) return [ line . strip () for line in stdout . splitlines ()] def git_hook ( strict : bool = False , modify : bool = False ) -> int : \"\"\" Git pre-commit hook to check staged files for isort errors :param bool strict - if True, return number of errors on exit, causing the hook to fail. If False, return zero so it will just act as a warning. :param bool modify - if True, fix the sources if they are not sorted properly. If False, only report result without modifying anything. :return number of errors if in strict mode, 0 otherwise. \"\"\" # Get list of files modified and staged diff_cmd = [ \"git\" , \"diff-index\" , \"--cached\" , \"--name-only\" , \"--diff-filter=ACMRTUXB HEAD\" , ] files_modified = get_lines ( diff_cmd ) errors = 0 for filename in files_modified : if filename . endswith ( \".py\" ): # Get the staged contents of the file staged_cmd = [ \"git\" , \"show\" , \": %s \" % filename ] staged_contents = get_output ( staged_cmd ) sort = SortImports ( file_path = filename , file_contents = staged_contents , check = True ) if sort . incorrectly_sorted : errors += 1 if modify : SortImports ( file_path = filename , file_contents = staged_contents , check = False ) return errors if strict else 0","title":"Module isort.hooks"},{"location":"reference/isort/hooks/#functions","text":"","title":"Functions"},{"location":"reference/isort/hooks/#get_lines","text":"def get_lines ( command : List [ str ] ) -> List [ str ] Run a command and return lines of output :param str command: the command to run :returns: list of whitespace-stripped lines output by command View Source def get_lines ( command : List [ str ] ) -> List [ str ]: \"\"\" Run a command and return lines of output : param str command : the command to run : returns : list of whitespace - stripped lines output by command \"\"\" stdout = get_output ( command ) return [ line . strip () for line in stdout . splitlines () ]","title":"get_lines"},{"location":"reference/isort/hooks/#get_output","text":"def get_output ( command : List [ str ] ) -> str Run a command and return raw output :param str command: the command to run :returns: the stdout output of the command View Source def get_output ( command : List [ str ] ) -> str : \"\"\" Run a command and return raw output : param str command : the command to run : returns : the stdout output of the command \"\"\" result = subprocess . run ( command , stdout = subprocess . PIPE , check = True ) return result . stdout . decode ()","title":"get_output"},{"location":"reference/isort/hooks/#git_hook","text":"def git_hook ( strict : bool = False , modify : bool = False ) -> int Git pre-commit hook to check staged files for isort errors :param bool strict - if True, return number of errors on exit, causing the hook to fail. If False, return zero so it will just act as a warning. :param bool modify - if True, fix the sources if they are not sorted properly. If False, only report result without modifying anything. :return number of errors if in strict mode, 0 otherwise. View Source def git_hook ( strict : bool = False , modify : bool = False ) -> int : \"\"\" Git pre - commit hook to check staged files for isort errors : param bool strict - if True , return number of errors on exit , causing the hook to fail . If False , return zero so it will just act as a warning . : param bool modify - if True , fix the sources if they are not sorted properly . If False , only report result without modifying anything . : return number of errors if in strict mode , 0 otherwise . \"\"\" # Get list of files modified and staged diff_cmd = [ \" git \" , \" diff-index \" , \" --cached \" , \" --name-only \" , \" --diff-filter=ACMRTUXB HEAD \" , ] files_modified = get_lines ( diff_cmd ) errors = 0 for filename in files_modified : if filename . endswith ( \" .py \" ) : # Get the staged contents of the file staged_cmd = [ \" git \" , \" show \" , \" :%s \" % filename ] staged_contents = get_output ( staged_cmd ) sort = SortImports ( file_path = filename , file_contents = staged_contents , check = True ) if sort . incorrectly_sorted : errors += 1 if modify : SortImports ( file_path = filename , file_contents = staged_contents , check = False ) return errors if strict else 0","title":"git_hook"},{"location":"reference/isort/isort/","text":"Module isort.isort isort.py. Exposes a simple library to sort through imports within Python code usage: SortImports(file_name) or: sorted = SortImports(file_contents=file_contents).output Copyright (C) 2013 Timothy Edmund Crosley Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. View Source \"\"\"isort.py. Exposes a simple library to sort through imports within Python code usage: SortImports(file_name) or: sorted = SortImports(file_contents=file_contents).output Copyright (C) 2013 Timothy Edmund Crosley Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \" Software \"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \" AS IS \", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. \"\"\" import copy import itertools import re from collections import OrderedDict , defaultdict , namedtuple from typing import ( TYPE_CHECKING , Any , Dict , Iterable , List , Mapping , Optional , Sequence , Tuple , ) from isort import utils from isort . format import format_natural , format_simplified from . import settings from . finders import FindersManager from . natural import nsorted from . settings import WrapModes if TYPE_CHECKING : from mypy_extensions import TypedDict CommentsAboveDict = TypedDict ( \"CommentsAboveDict\" , { \"straight\" : Dict [ str , Any ], \"from\" : Dict [ str , Any ]} ) CommentsDict = TypedDict ( \"CommentsDict\" , { \"from\" : Dict [ str , Any ], \"straight\" : Dict [ str , Any ], \"nested\" : Dict [ str , Any ], \"above\" : CommentsAboveDict , }, ) class _ SortImports : _ import_line_intro_re = re . compile ( \"^(?:from|import) \" ) _ import_line_midline_import_re = re . compile ( \" import \" ) def __ init__ ( self , file_contents: str , config : Dict [ str , Any ], extension : str = \"py\" ) -> None : self . config = config self . extension = extension self . place_imports = {} # type : Dict [ str , List [ str ]] self . import_placements = {} # type : Dict [ str , str ] self . remove_imports = [ format_simplified ( removal ) for removal in self . config [ \"remove_imports\" ] ] self . add_imports = [ format_natural ( addition ) for addition in self . config [ \"add_imports\" ] ] self . _ section_comments = [ \"# \" + value for key , value in self . config . items () if key . startswith ( \"import_heading\" ) and value ] self . line_separator = self . determine_line_separator ( file_contents ) self . in_lines = file_contents . split ( self . line_separator ) self . original_num_of_lines = len ( self . in_lines ) if ( self . original_num_of_lines > 1 or self . in_lines [ : 1 ] not in ([], [ \"\" ]) ) or self . config [ \"force_adds\" ] : for add_import in self . add_imports: self . in_lines . append ( add_import ) self . number_of_lines = len ( self . in_lines ) self . out_lines = [] # type : List [ str ] self . comments = { \"from\" : {}, \"straight\" : {}, \"nested\" : {}, \"above\" : { \"straight\" : {}, \"from\" : {}}, } # type : CommentsDict self . imports = OrderedDict () # type : OrderedDict [ str , Dict [ str , Any ]] self . as_map = defaultdict ( list ) # type : Dict [ str , List [ str ]] section_names = self . config [ \"sections\" ] self . sections = namedtuple ( \"Sections\" , section_names )( * [ name for name in section_names ] ) # type : Any for section in itertools . chain ( self . sections , self . config [ \"forced_separate\" ]) : self . imports [ section ] = { \"straight\" : OrderedDict (), \"from\" : OrderedDict ()} self . finder = FindersManager ( config = self . config , sections = self . sections ) self . index = 0 self . import_index = - 1 self . _ first_comment_index_start = - 1 self . _ first_comment_index_end = - 1 self . _ parse () if self . import_index ! = - 1 : self . _ add_formatted_imports () self . length_change = len ( self . out_lines ) - self . original_num_of_lines while self . out_lines and self . out_lines [ - 1 ]. strip () == \"\" : self . out_lines . pop ( - 1 ) self . out_lines . append ( \"\" ) self . output = self . line_separator . join ( self . out_lines ) def remove_whitespaces ( self , contents : str ) -> str : contents = ( contents . replace ( self . line_separator , \"\" ) . replace ( \" \" , \"\" ) . replace ( \" \\x0c \", \"\") ) return contents def get_out_lines_without_top_comment(self) -> str: return self._strip_top_comments(self.out_lines, self.line_separator) def get_in_lines_without_top_comment(self) -> str: return self._strip_top_comments(self.in_lines, self.line_separator) def check_if_input_already_sorted( self, output: str, check_against: str, *, logging_file_path: str ) -> bool: if output.strip() == check_against.strip(): if self.config[\" verbose \"]: print(\" SUCCESS : {} Everything Looks Good ! \".format(logging_file_path)) return True print(\" ERROR : {} Imports are incorrectly sorted . \".format(logging_file_path)) return False def determine_line_separator(self, file_contents: str) -> str: if self.config[\" line_ending \"]: return self.config[\" line_ending \"] else: return utils.infer_line_separator(file_contents) @staticmethod def _strip_top_comments(lines: Sequence[str], line_separator: str) -> str: \"\"\" Strips # comments that exist at the top of the given lines \"\"\" lines = copy.copy(lines) while lines and lines[0].startswith(\" # \"): lines = lines[1:] return line_separator.join(lines) def place_module(self, module_name: str) -> Optional[str]: \"\"\" Tries to determine if a module is a python std import , third party import , or project code : if it can't determine - it assumes it is project code \"\"\" return self.finder.find(module_name) def _get_line(self) -> str: \"\"\"Returns the current line from the file while incrementing the index.\"\"\" line = self.in_lines[self.index] self.index += 1 return line @staticmethod def _import_type(line: str) -> Optional[str]: \"\"\"If the current line is an import line it will return its type (from or straight)\"\"\" if \"isort:skip\" in line or \"NOQA\" in line: return None elif line.startswith(\"import \"): return \"straight\" elif line.startswith(\"from \"): return \"from\" return None def _at_end(self) -> bool: \"\"\"returns True if we are at the end of the file.\"\"\" return self.index == self.number_of_lines @staticmethod def _module_key( module_name: str, config: Mapping[str, Any], sub_imports: bool = False, ignore_case: bool = False, section_name: Optional[Any] = None, ) -> str: match = re.match(r\"^(\\.+)\\s*(.*)\", module_name) if match: sep = \" \" if config[\"reverse_relative\"] else \"_\" module_name = sep.join(match.groups()) prefix = \"\" if ignore_case: module_name = str(module_name).lower() else: module_name = str(module_name) if sub_imports and config[\"order_by_type\"]: if module_name.isupper() and len(module_name) > 1: # see issue #376 prefix = \"A\" elif module_name[0:1].isupper(): prefix = \"B\" else: prefix = \"C\" if not config[\"case_sensitive\"]: module_name = module_name.lower() if ( section_name is None or \"length_sort_\" + str(section_name).lower() not in config ): length_sort = config[\"length_sort\"] else: length_sort = config[\"length_sort_\" + str(section_name).lower()] return \"{}{}{}\".format( module_name in config[\"force_to_top\"] and \"A\" or \"B\", prefix, length_sort and (str(len(module_name)) + \":\" + module_name) or module_name, ) def _add_comments( self, comments: Optional[Sequence[str]], original_string: str = \"\" ) -> str: \"\"\" Returns a string with comments added if ignore_comments is not set. \"\"\" if self.config[\"ignore_comments\"]: return self._strip_comments(original_string)[0] if not comments: return original_string else: return \"{}{} {}\".format( self._strip_comments(original_string)[0], self.config[\"comment_prefix\"], \"; \".join(comments), ) def _wrap(self, line: str) -> str: \"\"\" Returns an import wrapped to the specified line-length, if possible. \"\"\" wrap_mode = self.config[\"multi_line_output\"] if len(line) > self.config[\"line_length\"] and wrap_mode != WrapModes.NOQA: line_without_comment = line comment = None if \"#\" in line: line_without_comment, comment = line.split(\"#\", 1) for splitter in (\"import \", \".\", \"as \"): exp = r\"\\b\" + re.escape(splitter) + r\"\\b\" if re.search( exp, line_without_comment ) and not line_without_comment.strip().startswith(splitter): line_parts = re.split(exp, line_without_comment) if comment: line_parts[-1] = \"{}{} #{}\".format( line_parts[-1].strip(), \",\" if self.config[\"include_trailing_comma\"] else \"\", comment, ) next_line = [] while (len(line) + 2) > ( self.config[\"wrap_length\"] or self.config[\"line_length\"] ) and line_parts: next_line.append(line_parts.pop()) line = splitter.join(line_parts) if not line: line = next_line.pop() cont_line = self._wrap( self.config[\"indent\"] + splitter.join(next_line).lstrip() ) if self.config[\"use_parentheses\"]: if splitter == \"as \": output = \"{}{}{}\".format(line, splitter, cont_line.lstrip()) else: output = \"{}{}({}{}{}{})\".format( line, splitter, self.line_separator, cont_line, \",\" if self.config[\"include_trailing_comma\"] and not comment else \"\", self.line_separator if wrap_mode in { WrapModes.VERTICAL_HANGING_INDENT, WrapModes.VERTICAL_GRID_GROUPED, } else \"\", ) lines = output.split(self.line_separator) if self.config[\"comment_prefix\"] in lines[-1] and lines[ -1 ].endswith(\")\"): line, comment = lines[-1].split( self.config[\"comment_prefix\"], 1 ) lines[-1] = ( line + \")\" + self.config[\"comment_prefix\"] + comment[:-1] ) return self.line_separator.join(lines) return \"{}{}\\\\{}{}\".format( line, splitter, self.line_separator, cont_line ) elif ( len(line) > self.config[\"line_length\"] and wrap_mode == settings.WrapModes.NOQA ): if \"# NOQA\" not in line: return \"{}{} NOQA\".format(line, self.config[\"comment_prefix\"]) return line def _add_straight_imports( self, straight_modules: Iterable[str], section: str, section_output: List[str] ) -> None: for module in straight_modules: if module in self.remove_imports: continue import_definition = [] if module in self.as_map: if ( self.config[\"keep_direct_and_as_imports\"] and self.imports[section][\"straight\"][module] ): import_definition.append(\"import {}\".format(module)) import_definition.extend( \"import {} as {}\".format(module, as_import) for as_import in self.as_map[module] ) else: import_definition.append(\"import {}\".format(module)) comments_above = self.comments[\"above\"][\"straight\"].pop(module, None) if comments_above: if section_output and self.config.get(\"ensure_newline_before_comments\"): section_output.append(\"\") section_output.extend(comments_above) section_output.extend( self._add_comments(self.comments[\"straight\"].get(module), idef) for idef in import_definition ) def _add_from_imports( self, from_modules: Iterable[str], section: str, section_output: List[str], ignore_case: bool, ) -> None: for module in from_modules: if module in self.remove_imports: continue import_start = \"from {} import \".format(module) from_imports = list(self.imports[section][\"from\"][module]) if not self.config[\"no_inline_sort\"] or self.config[\"force_single_line\"]: from_imports = nsorted( from_imports, key=lambda key: self._module_key( key, self.config, True, ignore_case, section_name=section ), ) if self.remove_imports: from_imports = [ line for line in from_imports if not \"{}.{}\".format(module, line) in self.remove_imports ] sub_modules = [ \"{}.{}\".format(module, from_import) for from_import in from_imports ] as_imports = { from_import: [ \"{} as {}\".format(from_import, as_module) for as_module in self.as_map[sub_module] ] for from_import, sub_module in zip(from_imports, sub_modules) if sub_module in self.as_map } if self.config[\"combine_as_imports\"] and not ( \"*\" in from_imports and self.config[\"combine_star\"] ): if not self.config[\"no_inline_sort\"]: for as_import in as_imports: as_imports[as_import] = nsorted(as_imports[as_import]) for from_import in copy.copy(from_imports): if from_import in as_imports: idx = from_imports.index(from_import) if ( self.config[\"keep_direct_and_as_imports\"] and self.imports[section][\"from\"][module][from_import] ): from_imports[(idx + 1) : (idx + 1)] = as_imports.pop( from_import ) else: from_imports[idx : (idx + 1)] = as_imports.pop(from_import) while from_imports: comments = self.comments[\"from\"].pop(module, ()) if \"*\" in from_imports and self.config[\"combine_star\"]: import_statement = self._wrap( self._add_comments(comments, \"{}*\".format(import_start)) ) from_imports = None elif self.config[\"force_single_line\"]: import_statement = None while from_imports: from_import = from_imports.pop(0) single_import_line = self._add_comments( comments, import_start + from_import ) comment = ( self.comments[\"nested\"] .get(module, {}) .pop(from_import, None) ) if comment: single_import_line += \"{} {}\".format( comments and \";\" or self.config[\"comment_prefix\"], comment, ) if from_import in as_imports: if ( self.config[\"keep_direct_and_as_imports\"] and self.imports[section][\"from\"][module][from_import] ): section_output.append(self._wrap(single_import_line)) from_comments = self.comments[\"straight\"].get( \"{}.{}\".format(module, from_import) ) section_output.extend( self._add_comments( from_comments, self._wrap(import_start + as_import) ) for as_import in nsorted(as_imports[from_import]) ) else: section_output.append(self._wrap(single_import_line)) comments = None else: while from_imports and from_imports[0] in as_imports: from_import = from_imports.pop(0) as_imports[from_import] = nsorted(as_imports[from_import]) from_comments = self.comments[\"straight\"].get( \"{}.{}\".format(module, from_import) ) above_comments = self.comments[\"above\"][\"from\"].pop( module, None ) if above_comments: if section_output and self.config.get( \"ensure_newline_before_comments\" ): section_output.append(\"\") section_output.extend(above_comments) if ( self.config[\"keep_direct_and_as_imports\"] and self.imports[section][\"from\"][module][from_import] ): section_output.append( self._add_comments( from_comments, self._wrap(import_start + from_import), ) ) section_output.extend( self._add_comments( from_comments, self._wrap(import_start + as_import) ) for as_import in as_imports[from_import] ) star_import = False if \"*\" in from_imports: section_output.append( self._add_comments(comments, \"{}*\".format(import_start)) ) from_imports.remove(\"*\") star_import = True comments = None for from_import in copy.copy(from_imports): if ( from_import in as_imports and not self.config[\"keep_direct_and_as_imports\"] ): continue comment = ( self.comments[\"nested\"] .get(module, {}) .pop(from_import, None) ) if comment: single_import_line = self._add_comments( comments, import_start + from_import ) single_import_line += \"{} {}\".format( comments and \";\" or self.config[\"comment_prefix\"], comment, ) above_comments = self.comments[\"above\"][\"from\"].pop( module, None ) if above_comments: if section_output and self.config.get( \"ensure_newline_before_comments\" ): section_output.append(\"\") section_output.extend(above_comments) section_output.append(self._wrap(single_import_line)) from_imports.remove(from_import) comments = None from_import_section = [] while from_imports and ( from_imports[0] not in as_imports or ( self.config[\"keep_direct_and_as_imports\"] and self.config[\"combine_as_imports\"] and self.imports[section][\"from\"][module][from_import] ) ): from_import_section.append(from_imports.pop(0)) if star_import: import_statement = import_start + (\", \").join( from_import_section ) else: import_statement = self._add_comments( comments, import_start + (\", \").join(from_import_section) ) if not from_import_section: import_statement = \"\" do_multiline_reformat = False force_grid_wrap = self.config[\"force_grid_wrap\"] if force_grid_wrap and len(from_import_section) >= force_grid_wrap: do_multiline_reformat = True if ( len(import_statement) > self.config[\"line_length\"] and len(from_import_section) > 1 ): do_multiline_reformat = True # If line too long AND have imports AND we are NOT using GRID or VERTICAL wrap modes if ( len(import_statement) > self.config[\"line_length\"] and len(from_import_section) > 0 and self.config[\"multi_line_output\"] not in (settings.WrapModes.GRID, settings.WrapModes.VERTICAL) ): do_multiline_reformat = True if do_multiline_reformat: import_statement = self._multi_line_reformat( import_start, from_import_section, comments ) if self.config[\"multi_line_output\"] == settings.WrapModes.GRID: self.config[ \"multi_line_output\" ] = settings.WrapModes.VERTICAL_GRID try: other_import_statement = self._multi_line_reformat( import_start, from_import_section, comments ) if ( max(len(x) for x in import_statement.split(\"\\n\")) > self.config[\"line_length\"] ): import_statement = other_import_statement finally: self.config[ \"multi_line_output\" ] = settings.WrapModes.GRID if ( not do_multiline_reformat and len(import_statement) > self.config[\"line_length\"] ): import_statement = self._wrap(import_statement) if import_statement: above_comments = self.comments[\"above\"][\"from\"].pop(module, None) if above_comments: if section_output and self.config.get( \"ensure_newline_before_comments\" ): section_output.append(\"\") section_output.extend(above_comments) section_output.append(import_statement) def _multi_line_reformat( self, import_start: str, from_imports: List[str], comments: Sequence[str] ) -> str: output_mode = self.config[\"multi_line_output\"].name.lower() formatter = getattr(self, \"_output_\" + output_mode, self._output_grid) dynamic_indent = \" \" * (len(import_start) + 1) indent = self.config[\"indent\"] line_length = self.config[\"wrap_length\"] or self.config[\"line_length\"] import_statement = formatter( import_start, copy.copy(from_imports), dynamic_indent, indent, line_length, comments, ) if self.config[\"balanced_wrapping\"]: lines = import_statement.split(self.line_separator) line_count = len(lines) if len(lines) > 1: minimum_length = min(len(line) for line in lines[:-1]) else: minimum_length = 0 new_import_statement = import_statement while ( len(lines[-1]) < minimum_length and len(lines) == line_count and line_length > 10 ): import_statement = new_import_statement line_length -= 1 new_import_statement = formatter( import_start, copy.copy(from_imports), dynamic_indent, indent, line_length, comments, ) lines = new_import_statement.split(self.line_separator) if import_statement.count(self.line_separator) == 0: return self._wrap(import_statement) return import_statement def _add_formatted_imports(self) -> None: \"\"\"Adds the imports back to the file. (at the index of the first import) sorted alphabetically and split between groups \"\"\" sort_ignore_case = self.config[\"force_alphabetical_sort_within_sections\"] sections = itertools.chain( self.sections, self.config[\"forced_separate\"] ) # type: Iterable[str] if self.config[\"no_sections\"]: self.imports[\"no_sections\"] = {\"straight\": [], \"from\": {}} for section in sections: self.imports[\"no_sections\"][\"straight\"].extend( self.imports[section].get(\"straight\", []) ) self.imports[\"no_sections\"][\"from\"].update( self.imports[section].get(\"from\", {}) ) sections = (\"no_sections\",) output = [] # type: List[str] pending_lines_before = False for section in sections: straight_modules = self.imports[section][\"straight\"] straight_modules = nsorted( straight_modules, key=lambda key: self._module_key( key, self.config, section_name=section ), ) from_modules = self.imports[section][\"from\"] from_modules = nsorted( from_modules, key=lambda key: self._module_key( key, self.config, section_name=section ), ) if self.config[\"force_sort_within_sections\"]: copied_comments = copy.deepcopy(self.comments) section_output = [] # type: List[str] if self.config[\"from_first\"]: self._add_from_imports( from_modules, section, section_output, sort_ignore_case ) if ( self.config[\"lines_between_types\"] and from_modules and straight_modules ): section_output.extend([\"\"] * self.config[\"lines_between_types\"]) self._add_straight_imports(straight_modules, section, section_output) else: self._add_straight_imports(straight_modules, section, section_output) if ( self.config[\"lines_between_types\"] and from_modules and straight_modules ): section_output.extend([\"\"] * self.config[\"lines_between_types\"]) self._add_from_imports( from_modules, section, section_output, sort_ignore_case ) if self.config[\"force_sort_within_sections\"]: def by_module(line: str) -> str: section = \"B\" line = self._import_line_intro_re.sub( \"\", self._import_line_midline_import_re.sub(\".\", line) ) if line.split(\" \")[0] in self.config[\"force_to_top\"]: section = \"A\" if not self.config[\"order_by_type\"]: line = line.lower() return \"{}{}\".format(section, line) # Remove comments section_output = [ line for line in section_output if not line.startswith(\"#\") ] section_output = nsorted(section_output, key=by_module) # Add comments back all_comments = copied_comments[\"above\"][\"from\"] all_comments.update(copied_comments[\"above\"][\"straight\"]) comment_indexes = {} for module, comment_list in all_comments.items(): for idx, line in enumerate(section_output): if module in line: comment_indexes[idx] = comment_list added = 0 for idx, comment_list in comment_indexes.items(): for comment in comment_list: section_output.insert(idx + added, comment) added += 1 section_name = section no_lines_before = section_name in self.config[\"no_lines_before\"] if section_output: if section_name in self.place_imports: self.place_imports[section_name] = section_output continue section_title = self.config.get( \"import_heading_\" + str(section_name).lower(), \"\" ) if section_title: section_comment = \"# {}\".format(section_title) if ( section_comment not in self.out_lines[0:1] and section_comment not in self.in_lines[0:1] ): section_output.insert(0, section_comment) if pending_lines_before or not no_lines_before: output += [\"\"] * self.config[\"lines_between_sections\"] output += section_output pending_lines_before = False else: pending_lines_before = pending_lines_before or not no_lines_before while output and output[-1].strip() == \"\": output.pop() while output and output[0].strip() == \"\": output.pop(0) output_at = 0 if self.import_index < self.original_num_of_lines: output_at = self.import_index elif ( self._first_comment_index_end != -1 and self._first_comment_index_start <= 2 ): output_at = self._first_comment_index_end self.out_lines[output_at:0] = output imports_tail = output_at + len(output) while [ character.strip() for character in self.out_lines[imports_tail : imports_tail + 1] ] == [\"\"]: self.out_lines.pop(imports_tail) if len(self.out_lines) > imports_tail: next_construct = \"\" self._in_quote = False # type: Any tail = self.out_lines[imports_tail:] for index, line in enumerate(tail): in_quote = self._in_quote if not self._skip_line(line) and line.strip(): if ( line.strip().startswith(\"#\") and len(tail) > (index + 1) and tail[index + 1].strip() ): continue next_construct = line break elif not in_quote: parts = line.split() if ( len(parts) >= 3 and parts[1] == \"=\" and \"' \" not in parts[0] and '\" ' not in parts[0] ): next_construct = line break if self.config[\"lines_after_imports\"] != -1: self.out_lines[imports_tail:0] = [ \"\" for line in range(self.config[\"lines_after_imports\"]) ] elif self.extension != \"pyi\" and ( next_construct.startswith(\"def \") or next_construct.startswith(\"class \") or next_construct.startswith(\"@\") or next_construct.startswith(\"async def\") ): self.out_lines[imports_tail:0] = [\"\", \"\"] else: self.out_lines[imports_tail:0] = [\"\"] if self.place_imports: new_out_lines = [] for index, line in enumerate(self.out_lines): new_out_lines.append(line) if line in self.import_placements: new_out_lines.extend( self.place_imports[self.import_placements[line]] ) if ( len(self.out_lines) <= index or self.out_lines[index + 1].strip() != \"\" ): new_out_lines.append(\"\") self.out_lines = new_out_lines def _output_grid( self, statement: str, imports: List[str], white_space: str, indent: str, line_length: int, comments: Sequence[str], ) -> str: statement += \"(\" + imports.pop(0) while imports: next_import = imports.pop(0) next_statement = self._add_comments( comments, statement + \", \" + next_import ) if len(next_statement.split(self.line_separator)[-1]) + 1 > line_length: lines = [\"{}{}\".format(white_space, next_import.split(\" \")[0])] for part in next_import.split(\" \")[1:]: new_line = \"{} {}\".format(lines[-1], part) if len(new_line) + 1 > line_length: lines.append(\"{}{}\".format(white_space, part)) else: lines[-1] = new_line next_import = self.line_separator.join(lines) statement = self._add_comments( comments, \"{},\".format(statement) ) + \"{}{}\".format(self.line_separator, next_import) comments = None else: statement += \", \" + next_import return statement + (\",\" if self.config[\"include_trailing_comma\"] else \"\") + \")\" def _output_vertical( self, statement: str, imports: List[str], white_space: str, indent: str, line_length: int, comments: Sequence[str], ) -> str: first_import = ( self._add_comments(comments, imports.pop(0) + \",\") + self.line_separator + white_space ) return \"{}({}{}{})\".format( statement, first_import, (\",\" + self.line_separator + white_space).join(imports), \",\" if self.config[\"include_trailing_comma\"] else \"\", ) def _output_hanging_indent( self, statement: str, imports: List[str], white_space: str, indent: str, line_length: int, comments: Sequence[str], ) -> str: statement += imports.pop(0) while imports: next_import = imports.pop(0) next_statement = self._add_comments( comments, statement + \", \" + next_import ) if len(next_statement.split(self.line_separator)[-1]) + 3 > line_length: next_statement = self._add_comments( comments, \"{}, \\\\\".format(statement) ) + \"{}{}{}\".format(self.line_separator, indent, next_import) comments = None statement = next_statement return statement def _output_vertical_hanging_indent( self, statement: str, imports: List[str], white_space: str, indent: str, line_length: int, comments: Sequence[str], ) -> str: return \"{0}({1}{2}{3}{4}{5}{2})\".format( statement, self._add_comments(comments), self.line_separator, indent, (\",\" + self.line_separator + indent).join(imports), \",\" if self.config[\"include_trailing_comma\"] else \"\", ) def _output_vertical_grid_common( self, statement: str, imports: List[str], white_space: str, indent: str, line_length: int, comments: Sequence[str], need_trailing_char: bool, ) -> str: statement += ( self._add_comments(comments, \"(\") + self.line_separator + indent + imports.pop(0) ) while imports: next_import = imports.pop(0) next_statement = \"{}, {}\".format(statement, next_import) current_line_length = len(next_statement.split(self.line_separator)[-1]) if imports or need_trailing_char: # If we have more imports we need to account for a comma after this import # We might also need to account for a closing ) we're going to add . current_line_length += 1 if current_line_length > line_length: next_statement = \"{},{}{}{}\" . format ( statement , self . line_separator , indent , next_import ) statement = next_statement if self . config [ \"include_trailing_comma\" ] : statement += \",\" return statement def _ output_vertical_grid ( self , statement : str , imports : List [ str ], white_space: str , indent : str , line_length: int , comments : Sequence [ str ], ) -> str : return ( self . _ output_vertical_grid_common ( statement , imports , white_space , indent , line_length , comments , True ) + \")\" ) def _ output_vertical_grid_grouped ( self , statement : str , imports : List [ str ], white_space: str , indent : str , line_length: int , comments : Sequence [ str ], ) -> str : return ( self . _ output_vertical_grid_common ( statement , imports , white_space , indent , line_length , comments , True ) + self . line_separator + \")\" ) def _ output_vertical_grid_grouped_no_comma ( self , statement : str , imports : List [ str ], white_space: str , indent : str , line_length: int , comments : Sequence [ str ], ) -> str : return ( self . _ output_vertical_grid_common ( statement , imports , white_space , indent , line_length , comments , False ) + self . line_separator + \")\" ) def _ output_noqa ( self , statement : str , imports : List [ str ], white_space: str , indent : str , line_length: int , comments : Sequence [ str ], ) -> str : retval = \"{}{}\" . format ( statement , \", \" . join ( imports )) comment_str = \" \" . join ( comments ) if comments : if ( len ( retval ) + len ( self . config [ \"comment_prefix\" ]) + 1 + len ( comment_str ) <= line_length ) : return \"{}{} {}\" . format ( retval , self . config [ \"comment_prefix\" ], comment_str ) else : if len ( retval ) <= line_length: return retval if comments : if \"NOQA\" in comments : return \"{}{} {}\" . format ( retval , self . config [ \"comment_prefix\" ], comment_str ) else : return \"{}{} NOQA {}\" . format ( retval , self . config [ \"comment_prefix\" ], comment_str ) else : return \"{}{} NOQA\" . format ( retval , self . config [ \"comment_prefix\" ]) @staticmethod def _ strip_comments ( line : str , comments : Optional [ List [ str ]] = None ) -> Tuple [ str , List [ str ], bool ] : \"\"\"Removes comments from import line.\"\"\" if comments is None : comments = [] new_comments = False comment_start = line . find ( \"#\" ) if comment_start ! = - 1 : comments . append ( line [ comment_start + 1 : ]. strip ()) new_comments = True line = line [ :comment_start ] return line , comments , new_comments def _ skip_line ( self , line : str ) -> bool : skip_line = self . _ in_quote if self . index == 1 and line . startswith ( \"#\" ) : self . _ in_top_comment = True return True elif self . _ in_top_comment: if not line . startswith ( \"#\" ) or line in self . _ section_comments: self . _ in_top_comment = False self . _ first_comment_index_end = self . index - 1 if '\"' in line or \"'\" in line : index = 0 if self . _ first_comment_index_start == - 1 and ( line . startswith ( '\"' ) or line . startswith ( \"'\" ) ) : self . _ first_comment_index_start = self . index while index < len ( line ) : if line [ index ] == \" \\\\ \": index += 1 elif self._in_quote: if line[index : index + len(self._in_quote)] == self._in_quote: self._in_quote = False if ( self._first_comment_index_end < self._first_comment_index_start ): self._first_comment_index_end = self.index elif line[index] in (\" '\", ' \"'): long_quote = line[index : index + 3] if long_quote in ('\"\"\" ', \"''' \"): self._in_quote = long_quote index += 2 else: self._in_quote = line[index] elif line[index] == \" # \": break index += 1 return skip_line or self._in_quote or self._in_top_comment def _strip_syntax(self, import_string: str) -> str: import_string = import_string.replace(\" _ import \", \" [[ i ]] \") for remove_syntax in [\" \\\\ \", \" ( \", \" ) \", \" , \"]: import_string = import_string.replace(remove_syntax, \" \") import_list = import_string.split() for key in (\" from \", \" import \"): if key in import_list: import_list.remove(key) import_string = \" \".join(import_list) import_string = import_string.replace(\" [[ i ]] \", \" _ import \") return import_string.replace(\" { \", \" {| \").replace(\" } \", \" |} \") def _parse(self) -> None: \"\"\" Parses a python file taking out and categorizing imports . \"\"\" self._in_quote = False self._in_top_comment = False while not self._at_end(): raw_line = line = self._get_line() line = line.replace(\" from . import \", \" from . import \") line = line.replace(\" \\t \", \" \").replace(\" import* \", \" import * \") line = line.replace(\" . import \", \" . import \") statement_index = self.index skip_line = self._skip_line(line) if line in self._section_comments and not skip_line: if self.import_index == -1: self.import_index = self.index - 1 continue if \" isort : imports- \" in line and line.startswith(\" # \"): section = line.split(\" isort : imports- \")[-1].split()[0].upper() self.place_imports[section] = [] self.import_placements[line] = section if \" ; \" in line: for part in (part.strip() for part in line.split(\" ; \")): if ( part and not part.startswith(\" from \") and not part.startswith(\" import \") ): skip_line = True import_type = self._import_type(line) if not import_type or skip_line: self.out_lines.append(raw_line) continue for line in (line.strip() for line in line.split(\" ; \")): import_type = self._import_type(line) if not import_type: self.out_lines.append(line) continue if self.import_index == -1: self.import_index = self.index - 1 nested_comments = {} import_string, comments, new_comments = self._strip_comments(line) line_parts = [ part for part in self._strip_syntax(import_string).strip().split(\" \") if part ] if ( import_type == \" from \" and len(line_parts) == 2 and line_parts[1] != \" * \" and new_comments ): nested_comments[line_parts[-1]] = comments[0] if \" ( \" in line.split(\" # \")[0] and not self._at_end(): while not line.strip().endswith(\" ) \") and not self._at_end(): line, comments, new_comments = self._strip_comments( self._get_line(), comments ) stripped_line = self._strip_syntax(line).strip() if ( import_type == \" from \" and stripped_line and \" \" not in stripped_line and new_comments ): nested_comments[stripped_line] = comments[-1] import_string += self.line_separator + line else: while line.strip().endswith(\" \\\\ \"): line, comments, new_comments = self._strip_comments( self._get_line(), comments ) # Still need to check for parentheses after an escaped line if ( \" ( \" in line.split(\" # \")[0] and \" ) \" not in line.split(\" # \")[0] and not self._at_end() ): stripped_line = self._strip_syntax(line).strip() if ( import_type == \" from \" and stripped_line and \" \" not in stripped_line and new_comments ): nested_comments[stripped_line] = comments[-1] import_string += self.line_separator + line while not line.strip().endswith(\" ) \") and not self._at_end(): line, comments, new_comments = self._strip_comments( self._get_line(), comments ) stripped_line = self._strip_syntax(line).strip() if ( import_type == \" from \" and stripped_line and \" \" not in stripped_line and new_comments ): nested_comments[stripped_line] = comments[-1] import_string += self.line_separator + line stripped_line = self._strip_syntax(line).strip() if ( import_type == \" from \" and stripped_line and \" \" not in stripped_line and new_comments ): nested_comments[stripped_line] = comments[-1] if import_string.strip().endswith( \" import \" ) or line.strip().startswith(\" import \"): import_string += self.line_separator + line else: import_string = ( import_string.rstrip().rstrip(\" \\\\ \") + \" \" + line.lstrip() ) if import_type == \" from \": import_string = import_string.replace(\" import ( \", \" import ( \") parts = import_string.split(\" import \") from_import = parts[0].split(\" \") import_string = \" import \".join( [from_import[0] + \" \" + \"\".join(from_import[1:])] + parts[1:] ) imports = [ item.replace(\" {| \", \" { \").replace(\" |} \", \" } \") for item in self._strip_syntax(import_string).split() ] straight_import = True if \" as \" in imports and (imports.index(\" as \") + 1) < len(imports): straight_import = False while \" as \" in imports: index = imports.index(\" as \") if import_type == \" from \": module = imports[0] + \" . \" + imports[index - 1] self.as_map[module].append(imports[index + 1]) else: module = imports[index - 1] self.as_map[module].append(imports[index + 1]) if not self.config[\" combine_as_imports \"]: self.comments[\" straight \"][module] = comments comments = [] del imports[index : index + 2] if import_type == \" from \": import_from = imports.pop(0) placed_module = self.place_module(import_from) if self.config[\" verbose \"]: print( \" from - type place_module for {} returned {} \".format( import_from, placed_module ) ) if placed_module == \"\": print( \" WARNING : could not place module {} of line {} -- \" \" Do you need to define a default section? \".format( import_from, line ) ) root = self.imports[placed_module][import_type] for import_name in imports: associated_comment = nested_comments.get(import_name) if associated_comment: self.comments[\" nested \"].setdefault(import_from, {})[ import_name ] = associated_comment comments.pop(comments.index(associated_comment)) if comments: self.comments[\" from \"].setdefault(import_from, []).extend( comments ) if ( len(self.out_lines) > max(self.import_index, self._first_comment_index_end + 1, 1) - 1 ): last = self.out_lines and self.out_lines[-1].rstrip() or \"\" while ( last.startswith(\" # \") and not last.endswith('\"\"\" ') and not last.endswith(\"''' \") and \" isort : imports- \" not in last ): self.comments[\" above \"][\" from \"].setdefault( import_from, [] ).insert(0, self.out_lines.pop(-1)) if ( len(self.out_lines) > max( self.import_index - 1, self._first_comment_index_end + 1, 1, ) - 1 ): last = self.out_lines[-1].rstrip() else: last = \"\" if statement_index - 1 == self.import_index: self.import_index -= len( self.comments[\" above \"][\" from \"].get(import_from, []) ) if import_from not in root: root[import_from] = OrderedDict( (module, straight_import) for module in imports ) else: root[import_from].update( ( module, straight_import | root[import_from].get(module, False), ) for module in imports ) else: for module in imports: if comments: self.comments[\" straight \"][module] = comments comments = None if ( len(self.out_lines) > max( self.import_index, self._first_comment_index_end + 1, 1 ) - 1 ): last = self.out_lines and self.out_lines[-1].rstrip() or \"\" while ( last.startswith(\" # \") and not last.endswith('\"\"\" ') and not last.endswith(\"''' \") and \" isort : imports- \" not in last ): self.comments[\" above \"][\" straight \"].setdefault( module, [] ).insert(0, self.out_lines.pop(-1)) if ( len(self.out_lines) > 0 and len(self.out_lines) != self._first_comment_index_end ): last = self.out_lines[-1].rstrip() else: last = \"\" if self.index - 1 == self.import_index: self.import_index -= len( self.comments[\" above \"][\" straight \"].get(module, []) ) placed_module = self.place_module(module) if self.config[\" verbose \"]: print( \" else - type place_module for {} returned {} \".format( module, placed_module ) ) if placed_module == \"\": print( \" WARNING : could not place module {} of line {} -- \" \" Do you need to define a default section? \" . format ( import_from , line ) ) straight_import | = self . imports [ placed_module ][ import_type ]. get ( module , False ) self . imports [ placed_module ][ import_type ][ module ] = straight_import Variables TYPE_CHECKING","title":"Isort"},{"location":"reference/isort/isort/#module-isortisort","text":"isort.py. Exposes a simple library to sort through imports within Python code usage: SortImports(file_name) or: sorted = SortImports(file_contents=file_contents).output Copyright (C) 2013 Timothy Edmund Crosley Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. View Source \"\"\"isort.py. Exposes a simple library to sort through imports within Python code usage: SortImports(file_name) or: sorted = SortImports(file_contents=file_contents).output Copyright (C) 2013 Timothy Edmund Crosley Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \" Software \"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \" AS IS \", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. \"\"\" import copy import itertools import re from collections import OrderedDict , defaultdict , namedtuple from typing import ( TYPE_CHECKING , Any , Dict , Iterable , List , Mapping , Optional , Sequence , Tuple , ) from isort import utils from isort . format import format_natural , format_simplified from . import settings from . finders import FindersManager from . natural import nsorted from . settings import WrapModes if TYPE_CHECKING : from mypy_extensions import TypedDict CommentsAboveDict = TypedDict ( \"CommentsAboveDict\" , { \"straight\" : Dict [ str , Any ], \"from\" : Dict [ str , Any ]} ) CommentsDict = TypedDict ( \"CommentsDict\" , { \"from\" : Dict [ str , Any ], \"straight\" : Dict [ str , Any ], \"nested\" : Dict [ str , Any ], \"above\" : CommentsAboveDict , }, ) class _ SortImports : _ import_line_intro_re = re . compile ( \"^(?:from|import) \" ) _ import_line_midline_import_re = re . compile ( \" import \" ) def __ init__ ( self , file_contents: str , config : Dict [ str , Any ], extension : str = \"py\" ) -> None : self . config = config self . extension = extension self . place_imports = {} # type : Dict [ str , List [ str ]] self . import_placements = {} # type : Dict [ str , str ] self . remove_imports = [ format_simplified ( removal ) for removal in self . config [ \"remove_imports\" ] ] self . add_imports = [ format_natural ( addition ) for addition in self . config [ \"add_imports\" ] ] self . _ section_comments = [ \"# \" + value for key , value in self . config . items () if key . startswith ( \"import_heading\" ) and value ] self . line_separator = self . determine_line_separator ( file_contents ) self . in_lines = file_contents . split ( self . line_separator ) self . original_num_of_lines = len ( self . in_lines ) if ( self . original_num_of_lines > 1 or self . in_lines [ : 1 ] not in ([], [ \"\" ]) ) or self . config [ \"force_adds\" ] : for add_import in self . add_imports: self . in_lines . append ( add_import ) self . number_of_lines = len ( self . in_lines ) self . out_lines = [] # type : List [ str ] self . comments = { \"from\" : {}, \"straight\" : {}, \"nested\" : {}, \"above\" : { \"straight\" : {}, \"from\" : {}}, } # type : CommentsDict self . imports = OrderedDict () # type : OrderedDict [ str , Dict [ str , Any ]] self . as_map = defaultdict ( list ) # type : Dict [ str , List [ str ]] section_names = self . config [ \"sections\" ] self . sections = namedtuple ( \"Sections\" , section_names )( * [ name for name in section_names ] ) # type : Any for section in itertools . chain ( self . sections , self . config [ \"forced_separate\" ]) : self . imports [ section ] = { \"straight\" : OrderedDict (), \"from\" : OrderedDict ()} self . finder = FindersManager ( config = self . config , sections = self . sections ) self . index = 0 self . import_index = - 1 self . _ first_comment_index_start = - 1 self . _ first_comment_index_end = - 1 self . _ parse () if self . import_index ! = - 1 : self . _ add_formatted_imports () self . length_change = len ( self . out_lines ) - self . original_num_of_lines while self . out_lines and self . out_lines [ - 1 ]. strip () == \"\" : self . out_lines . pop ( - 1 ) self . out_lines . append ( \"\" ) self . output = self . line_separator . join ( self . out_lines ) def remove_whitespaces ( self , contents : str ) -> str : contents = ( contents . replace ( self . line_separator , \"\" ) . replace ( \" \" , \"\" ) . replace ( \" \\x0c \", \"\") ) return contents def get_out_lines_without_top_comment(self) -> str: return self._strip_top_comments(self.out_lines, self.line_separator) def get_in_lines_without_top_comment(self) -> str: return self._strip_top_comments(self.in_lines, self.line_separator) def check_if_input_already_sorted( self, output: str, check_against: str, *, logging_file_path: str ) -> bool: if output.strip() == check_against.strip(): if self.config[\" verbose \"]: print(\" SUCCESS : {} Everything Looks Good ! \".format(logging_file_path)) return True print(\" ERROR : {} Imports are incorrectly sorted . \".format(logging_file_path)) return False def determine_line_separator(self, file_contents: str) -> str: if self.config[\" line_ending \"]: return self.config[\" line_ending \"] else: return utils.infer_line_separator(file_contents) @staticmethod def _strip_top_comments(lines: Sequence[str], line_separator: str) -> str: \"\"\" Strips # comments that exist at the top of the given lines \"\"\" lines = copy.copy(lines) while lines and lines[0].startswith(\" # \"): lines = lines[1:] return line_separator.join(lines) def place_module(self, module_name: str) -> Optional[str]: \"\"\" Tries to determine if a module is a python std import , third party import , or project code : if it can't determine - it assumes it is project code \"\"\" return self.finder.find(module_name) def _get_line(self) -> str: \"\"\"Returns the current line from the file while incrementing the index.\"\"\" line = self.in_lines[self.index] self.index += 1 return line @staticmethod def _import_type(line: str) -> Optional[str]: \"\"\"If the current line is an import line it will return its type (from or straight)\"\"\" if \"isort:skip\" in line or \"NOQA\" in line: return None elif line.startswith(\"import \"): return \"straight\" elif line.startswith(\"from \"): return \"from\" return None def _at_end(self) -> bool: \"\"\"returns True if we are at the end of the file.\"\"\" return self.index == self.number_of_lines @staticmethod def _module_key( module_name: str, config: Mapping[str, Any], sub_imports: bool = False, ignore_case: bool = False, section_name: Optional[Any] = None, ) -> str: match = re.match(r\"^(\\.+)\\s*(.*)\", module_name) if match: sep = \" \" if config[\"reverse_relative\"] else \"_\" module_name = sep.join(match.groups()) prefix = \"\" if ignore_case: module_name = str(module_name).lower() else: module_name = str(module_name) if sub_imports and config[\"order_by_type\"]: if module_name.isupper() and len(module_name) > 1: # see issue #376 prefix = \"A\" elif module_name[0:1].isupper(): prefix = \"B\" else: prefix = \"C\" if not config[\"case_sensitive\"]: module_name = module_name.lower() if ( section_name is None or \"length_sort_\" + str(section_name).lower() not in config ): length_sort = config[\"length_sort\"] else: length_sort = config[\"length_sort_\" + str(section_name).lower()] return \"{}{}{}\".format( module_name in config[\"force_to_top\"] and \"A\" or \"B\", prefix, length_sort and (str(len(module_name)) + \":\" + module_name) or module_name, ) def _add_comments( self, comments: Optional[Sequence[str]], original_string: str = \"\" ) -> str: \"\"\" Returns a string with comments added if ignore_comments is not set. \"\"\" if self.config[\"ignore_comments\"]: return self._strip_comments(original_string)[0] if not comments: return original_string else: return \"{}{} {}\".format( self._strip_comments(original_string)[0], self.config[\"comment_prefix\"], \"; \".join(comments), ) def _wrap(self, line: str) -> str: \"\"\" Returns an import wrapped to the specified line-length, if possible. \"\"\" wrap_mode = self.config[\"multi_line_output\"] if len(line) > self.config[\"line_length\"] and wrap_mode != WrapModes.NOQA: line_without_comment = line comment = None if \"#\" in line: line_without_comment, comment = line.split(\"#\", 1) for splitter in (\"import \", \".\", \"as \"): exp = r\"\\b\" + re.escape(splitter) + r\"\\b\" if re.search( exp, line_without_comment ) and not line_without_comment.strip().startswith(splitter): line_parts = re.split(exp, line_without_comment) if comment: line_parts[-1] = \"{}{} #{}\".format( line_parts[-1].strip(), \",\" if self.config[\"include_trailing_comma\"] else \"\", comment, ) next_line = [] while (len(line) + 2) > ( self.config[\"wrap_length\"] or self.config[\"line_length\"] ) and line_parts: next_line.append(line_parts.pop()) line = splitter.join(line_parts) if not line: line = next_line.pop() cont_line = self._wrap( self.config[\"indent\"] + splitter.join(next_line).lstrip() ) if self.config[\"use_parentheses\"]: if splitter == \"as \": output = \"{}{}{}\".format(line, splitter, cont_line.lstrip()) else: output = \"{}{}({}{}{}{})\".format( line, splitter, self.line_separator, cont_line, \",\" if self.config[\"include_trailing_comma\"] and not comment else \"\", self.line_separator if wrap_mode in { WrapModes.VERTICAL_HANGING_INDENT, WrapModes.VERTICAL_GRID_GROUPED, } else \"\", ) lines = output.split(self.line_separator) if self.config[\"comment_prefix\"] in lines[-1] and lines[ -1 ].endswith(\")\"): line, comment = lines[-1].split( self.config[\"comment_prefix\"], 1 ) lines[-1] = ( line + \")\" + self.config[\"comment_prefix\"] + comment[:-1] ) return self.line_separator.join(lines) return \"{}{}\\\\{}{}\".format( line, splitter, self.line_separator, cont_line ) elif ( len(line) > self.config[\"line_length\"] and wrap_mode == settings.WrapModes.NOQA ): if \"# NOQA\" not in line: return \"{}{} NOQA\".format(line, self.config[\"comment_prefix\"]) return line def _add_straight_imports( self, straight_modules: Iterable[str], section: str, section_output: List[str] ) -> None: for module in straight_modules: if module in self.remove_imports: continue import_definition = [] if module in self.as_map: if ( self.config[\"keep_direct_and_as_imports\"] and self.imports[section][\"straight\"][module] ): import_definition.append(\"import {}\".format(module)) import_definition.extend( \"import {} as {}\".format(module, as_import) for as_import in self.as_map[module] ) else: import_definition.append(\"import {}\".format(module)) comments_above = self.comments[\"above\"][\"straight\"].pop(module, None) if comments_above: if section_output and self.config.get(\"ensure_newline_before_comments\"): section_output.append(\"\") section_output.extend(comments_above) section_output.extend( self._add_comments(self.comments[\"straight\"].get(module), idef) for idef in import_definition ) def _add_from_imports( self, from_modules: Iterable[str], section: str, section_output: List[str], ignore_case: bool, ) -> None: for module in from_modules: if module in self.remove_imports: continue import_start = \"from {} import \".format(module) from_imports = list(self.imports[section][\"from\"][module]) if not self.config[\"no_inline_sort\"] or self.config[\"force_single_line\"]: from_imports = nsorted( from_imports, key=lambda key: self._module_key( key, self.config, True, ignore_case, section_name=section ), ) if self.remove_imports: from_imports = [ line for line in from_imports if not \"{}.{}\".format(module, line) in self.remove_imports ] sub_modules = [ \"{}.{}\".format(module, from_import) for from_import in from_imports ] as_imports = { from_import: [ \"{} as {}\".format(from_import, as_module) for as_module in self.as_map[sub_module] ] for from_import, sub_module in zip(from_imports, sub_modules) if sub_module in self.as_map } if self.config[\"combine_as_imports\"] and not ( \"*\" in from_imports and self.config[\"combine_star\"] ): if not self.config[\"no_inline_sort\"]: for as_import in as_imports: as_imports[as_import] = nsorted(as_imports[as_import]) for from_import in copy.copy(from_imports): if from_import in as_imports: idx = from_imports.index(from_import) if ( self.config[\"keep_direct_and_as_imports\"] and self.imports[section][\"from\"][module][from_import] ): from_imports[(idx + 1) : (idx + 1)] = as_imports.pop( from_import ) else: from_imports[idx : (idx + 1)] = as_imports.pop(from_import) while from_imports: comments = self.comments[\"from\"].pop(module, ()) if \"*\" in from_imports and self.config[\"combine_star\"]: import_statement = self._wrap( self._add_comments(comments, \"{}*\".format(import_start)) ) from_imports = None elif self.config[\"force_single_line\"]: import_statement = None while from_imports: from_import = from_imports.pop(0) single_import_line = self._add_comments( comments, import_start + from_import ) comment = ( self.comments[\"nested\"] .get(module, {}) .pop(from_import, None) ) if comment: single_import_line += \"{} {}\".format( comments and \";\" or self.config[\"comment_prefix\"], comment, ) if from_import in as_imports: if ( self.config[\"keep_direct_and_as_imports\"] and self.imports[section][\"from\"][module][from_import] ): section_output.append(self._wrap(single_import_line)) from_comments = self.comments[\"straight\"].get( \"{}.{}\".format(module, from_import) ) section_output.extend( self._add_comments( from_comments, self._wrap(import_start + as_import) ) for as_import in nsorted(as_imports[from_import]) ) else: section_output.append(self._wrap(single_import_line)) comments = None else: while from_imports and from_imports[0] in as_imports: from_import = from_imports.pop(0) as_imports[from_import] = nsorted(as_imports[from_import]) from_comments = self.comments[\"straight\"].get( \"{}.{}\".format(module, from_import) ) above_comments = self.comments[\"above\"][\"from\"].pop( module, None ) if above_comments: if section_output and self.config.get( \"ensure_newline_before_comments\" ): section_output.append(\"\") section_output.extend(above_comments) if ( self.config[\"keep_direct_and_as_imports\"] and self.imports[section][\"from\"][module][from_import] ): section_output.append( self._add_comments( from_comments, self._wrap(import_start + from_import), ) ) section_output.extend( self._add_comments( from_comments, self._wrap(import_start + as_import) ) for as_import in as_imports[from_import] ) star_import = False if \"*\" in from_imports: section_output.append( self._add_comments(comments, \"{}*\".format(import_start)) ) from_imports.remove(\"*\") star_import = True comments = None for from_import in copy.copy(from_imports): if ( from_import in as_imports and not self.config[\"keep_direct_and_as_imports\"] ): continue comment = ( self.comments[\"nested\"] .get(module, {}) .pop(from_import, None) ) if comment: single_import_line = self._add_comments( comments, import_start + from_import ) single_import_line += \"{} {}\".format( comments and \";\" or self.config[\"comment_prefix\"], comment, ) above_comments = self.comments[\"above\"][\"from\"].pop( module, None ) if above_comments: if section_output and self.config.get( \"ensure_newline_before_comments\" ): section_output.append(\"\") section_output.extend(above_comments) section_output.append(self._wrap(single_import_line)) from_imports.remove(from_import) comments = None from_import_section = [] while from_imports and ( from_imports[0] not in as_imports or ( self.config[\"keep_direct_and_as_imports\"] and self.config[\"combine_as_imports\"] and self.imports[section][\"from\"][module][from_import] ) ): from_import_section.append(from_imports.pop(0)) if star_import: import_statement = import_start + (\", \").join( from_import_section ) else: import_statement = self._add_comments( comments, import_start + (\", \").join(from_import_section) ) if not from_import_section: import_statement = \"\" do_multiline_reformat = False force_grid_wrap = self.config[\"force_grid_wrap\"] if force_grid_wrap and len(from_import_section) >= force_grid_wrap: do_multiline_reformat = True if ( len(import_statement) > self.config[\"line_length\"] and len(from_import_section) > 1 ): do_multiline_reformat = True # If line too long AND have imports AND we are NOT using GRID or VERTICAL wrap modes if ( len(import_statement) > self.config[\"line_length\"] and len(from_import_section) > 0 and self.config[\"multi_line_output\"] not in (settings.WrapModes.GRID, settings.WrapModes.VERTICAL) ): do_multiline_reformat = True if do_multiline_reformat: import_statement = self._multi_line_reformat( import_start, from_import_section, comments ) if self.config[\"multi_line_output\"] == settings.WrapModes.GRID: self.config[ \"multi_line_output\" ] = settings.WrapModes.VERTICAL_GRID try: other_import_statement = self._multi_line_reformat( import_start, from_import_section, comments ) if ( max(len(x) for x in import_statement.split(\"\\n\")) > self.config[\"line_length\"] ): import_statement = other_import_statement finally: self.config[ \"multi_line_output\" ] = settings.WrapModes.GRID if ( not do_multiline_reformat and len(import_statement) > self.config[\"line_length\"] ): import_statement = self._wrap(import_statement) if import_statement: above_comments = self.comments[\"above\"][\"from\"].pop(module, None) if above_comments: if section_output and self.config.get( \"ensure_newline_before_comments\" ): section_output.append(\"\") section_output.extend(above_comments) section_output.append(import_statement) def _multi_line_reformat( self, import_start: str, from_imports: List[str], comments: Sequence[str] ) -> str: output_mode = self.config[\"multi_line_output\"].name.lower() formatter = getattr(self, \"_output_\" + output_mode, self._output_grid) dynamic_indent = \" \" * (len(import_start) + 1) indent = self.config[\"indent\"] line_length = self.config[\"wrap_length\"] or self.config[\"line_length\"] import_statement = formatter( import_start, copy.copy(from_imports), dynamic_indent, indent, line_length, comments, ) if self.config[\"balanced_wrapping\"]: lines = import_statement.split(self.line_separator) line_count = len(lines) if len(lines) > 1: minimum_length = min(len(line) for line in lines[:-1]) else: minimum_length = 0 new_import_statement = import_statement while ( len(lines[-1]) < minimum_length and len(lines) == line_count and line_length > 10 ): import_statement = new_import_statement line_length -= 1 new_import_statement = formatter( import_start, copy.copy(from_imports), dynamic_indent, indent, line_length, comments, ) lines = new_import_statement.split(self.line_separator) if import_statement.count(self.line_separator) == 0: return self._wrap(import_statement) return import_statement def _add_formatted_imports(self) -> None: \"\"\"Adds the imports back to the file. (at the index of the first import) sorted alphabetically and split between groups \"\"\" sort_ignore_case = self.config[\"force_alphabetical_sort_within_sections\"] sections = itertools.chain( self.sections, self.config[\"forced_separate\"] ) # type: Iterable[str] if self.config[\"no_sections\"]: self.imports[\"no_sections\"] = {\"straight\": [], \"from\": {}} for section in sections: self.imports[\"no_sections\"][\"straight\"].extend( self.imports[section].get(\"straight\", []) ) self.imports[\"no_sections\"][\"from\"].update( self.imports[section].get(\"from\", {}) ) sections = (\"no_sections\",) output = [] # type: List[str] pending_lines_before = False for section in sections: straight_modules = self.imports[section][\"straight\"] straight_modules = nsorted( straight_modules, key=lambda key: self._module_key( key, self.config, section_name=section ), ) from_modules = self.imports[section][\"from\"] from_modules = nsorted( from_modules, key=lambda key: self._module_key( key, self.config, section_name=section ), ) if self.config[\"force_sort_within_sections\"]: copied_comments = copy.deepcopy(self.comments) section_output = [] # type: List[str] if self.config[\"from_first\"]: self._add_from_imports( from_modules, section, section_output, sort_ignore_case ) if ( self.config[\"lines_between_types\"] and from_modules and straight_modules ): section_output.extend([\"\"] * self.config[\"lines_between_types\"]) self._add_straight_imports(straight_modules, section, section_output) else: self._add_straight_imports(straight_modules, section, section_output) if ( self.config[\"lines_between_types\"] and from_modules and straight_modules ): section_output.extend([\"\"] * self.config[\"lines_between_types\"]) self._add_from_imports( from_modules, section, section_output, sort_ignore_case ) if self.config[\"force_sort_within_sections\"]: def by_module(line: str) -> str: section = \"B\" line = self._import_line_intro_re.sub( \"\", self._import_line_midline_import_re.sub(\".\", line) ) if line.split(\" \")[0] in self.config[\"force_to_top\"]: section = \"A\" if not self.config[\"order_by_type\"]: line = line.lower() return \"{}{}\".format(section, line) # Remove comments section_output = [ line for line in section_output if not line.startswith(\"#\") ] section_output = nsorted(section_output, key=by_module) # Add comments back all_comments = copied_comments[\"above\"][\"from\"] all_comments.update(copied_comments[\"above\"][\"straight\"]) comment_indexes = {} for module, comment_list in all_comments.items(): for idx, line in enumerate(section_output): if module in line: comment_indexes[idx] = comment_list added = 0 for idx, comment_list in comment_indexes.items(): for comment in comment_list: section_output.insert(idx + added, comment) added += 1 section_name = section no_lines_before = section_name in self.config[\"no_lines_before\"] if section_output: if section_name in self.place_imports: self.place_imports[section_name] = section_output continue section_title = self.config.get( \"import_heading_\" + str(section_name).lower(), \"\" ) if section_title: section_comment = \"# {}\".format(section_title) if ( section_comment not in self.out_lines[0:1] and section_comment not in self.in_lines[0:1] ): section_output.insert(0, section_comment) if pending_lines_before or not no_lines_before: output += [\"\"] * self.config[\"lines_between_sections\"] output += section_output pending_lines_before = False else: pending_lines_before = pending_lines_before or not no_lines_before while output and output[-1].strip() == \"\": output.pop() while output and output[0].strip() == \"\": output.pop(0) output_at = 0 if self.import_index < self.original_num_of_lines: output_at = self.import_index elif ( self._first_comment_index_end != -1 and self._first_comment_index_start <= 2 ): output_at = self._first_comment_index_end self.out_lines[output_at:0] = output imports_tail = output_at + len(output) while [ character.strip() for character in self.out_lines[imports_tail : imports_tail + 1] ] == [\"\"]: self.out_lines.pop(imports_tail) if len(self.out_lines) > imports_tail: next_construct = \"\" self._in_quote = False # type: Any tail = self.out_lines[imports_tail:] for index, line in enumerate(tail): in_quote = self._in_quote if not self._skip_line(line) and line.strip(): if ( line.strip().startswith(\"#\") and len(tail) > (index + 1) and tail[index + 1].strip() ): continue next_construct = line break elif not in_quote: parts = line.split() if ( len(parts) >= 3 and parts[1] == \"=\" and \"' \" not in parts[0] and '\" ' not in parts[0] ): next_construct = line break if self.config[\"lines_after_imports\"] != -1: self.out_lines[imports_tail:0] = [ \"\" for line in range(self.config[\"lines_after_imports\"]) ] elif self.extension != \"pyi\" and ( next_construct.startswith(\"def \") or next_construct.startswith(\"class \") or next_construct.startswith(\"@\") or next_construct.startswith(\"async def\") ): self.out_lines[imports_tail:0] = [\"\", \"\"] else: self.out_lines[imports_tail:0] = [\"\"] if self.place_imports: new_out_lines = [] for index, line in enumerate(self.out_lines): new_out_lines.append(line) if line in self.import_placements: new_out_lines.extend( self.place_imports[self.import_placements[line]] ) if ( len(self.out_lines) <= index or self.out_lines[index + 1].strip() != \"\" ): new_out_lines.append(\"\") self.out_lines = new_out_lines def _output_grid( self, statement: str, imports: List[str], white_space: str, indent: str, line_length: int, comments: Sequence[str], ) -> str: statement += \"(\" + imports.pop(0) while imports: next_import = imports.pop(0) next_statement = self._add_comments( comments, statement + \", \" + next_import ) if len(next_statement.split(self.line_separator)[-1]) + 1 > line_length: lines = [\"{}{}\".format(white_space, next_import.split(\" \")[0])] for part in next_import.split(\" \")[1:]: new_line = \"{} {}\".format(lines[-1], part) if len(new_line) + 1 > line_length: lines.append(\"{}{}\".format(white_space, part)) else: lines[-1] = new_line next_import = self.line_separator.join(lines) statement = self._add_comments( comments, \"{},\".format(statement) ) + \"{}{}\".format(self.line_separator, next_import) comments = None else: statement += \", \" + next_import return statement + (\",\" if self.config[\"include_trailing_comma\"] else \"\") + \")\" def _output_vertical( self, statement: str, imports: List[str], white_space: str, indent: str, line_length: int, comments: Sequence[str], ) -> str: first_import = ( self._add_comments(comments, imports.pop(0) + \",\") + self.line_separator + white_space ) return \"{}({}{}{})\".format( statement, first_import, (\",\" + self.line_separator + white_space).join(imports), \",\" if self.config[\"include_trailing_comma\"] else \"\", ) def _output_hanging_indent( self, statement: str, imports: List[str], white_space: str, indent: str, line_length: int, comments: Sequence[str], ) -> str: statement += imports.pop(0) while imports: next_import = imports.pop(0) next_statement = self._add_comments( comments, statement + \", \" + next_import ) if len(next_statement.split(self.line_separator)[-1]) + 3 > line_length: next_statement = self._add_comments( comments, \"{}, \\\\\".format(statement) ) + \"{}{}{}\".format(self.line_separator, indent, next_import) comments = None statement = next_statement return statement def _output_vertical_hanging_indent( self, statement: str, imports: List[str], white_space: str, indent: str, line_length: int, comments: Sequence[str], ) -> str: return \"{0}({1}{2}{3}{4}{5}{2})\".format( statement, self._add_comments(comments), self.line_separator, indent, (\",\" + self.line_separator + indent).join(imports), \",\" if self.config[\"include_trailing_comma\"] else \"\", ) def _output_vertical_grid_common( self, statement: str, imports: List[str], white_space: str, indent: str, line_length: int, comments: Sequence[str], need_trailing_char: bool, ) -> str: statement += ( self._add_comments(comments, \"(\") + self.line_separator + indent + imports.pop(0) ) while imports: next_import = imports.pop(0) next_statement = \"{}, {}\".format(statement, next_import) current_line_length = len(next_statement.split(self.line_separator)[-1]) if imports or need_trailing_char: # If we have more imports we need to account for a comma after this import # We might also need to account for a closing ) we're going to add . current_line_length += 1 if current_line_length > line_length: next_statement = \"{},{}{}{}\" . format ( statement , self . line_separator , indent , next_import ) statement = next_statement if self . config [ \"include_trailing_comma\" ] : statement += \",\" return statement def _ output_vertical_grid ( self , statement : str , imports : List [ str ], white_space: str , indent : str , line_length: int , comments : Sequence [ str ], ) -> str : return ( self . _ output_vertical_grid_common ( statement , imports , white_space , indent , line_length , comments , True ) + \")\" ) def _ output_vertical_grid_grouped ( self , statement : str , imports : List [ str ], white_space: str , indent : str , line_length: int , comments : Sequence [ str ], ) -> str : return ( self . _ output_vertical_grid_common ( statement , imports , white_space , indent , line_length , comments , True ) + self . line_separator + \")\" ) def _ output_vertical_grid_grouped_no_comma ( self , statement : str , imports : List [ str ], white_space: str , indent : str , line_length: int , comments : Sequence [ str ], ) -> str : return ( self . _ output_vertical_grid_common ( statement , imports , white_space , indent , line_length , comments , False ) + self . line_separator + \")\" ) def _ output_noqa ( self , statement : str , imports : List [ str ], white_space: str , indent : str , line_length: int , comments : Sequence [ str ], ) -> str : retval = \"{}{}\" . format ( statement , \", \" . join ( imports )) comment_str = \" \" . join ( comments ) if comments : if ( len ( retval ) + len ( self . config [ \"comment_prefix\" ]) + 1 + len ( comment_str ) <= line_length ) : return \"{}{} {}\" . format ( retval , self . config [ \"comment_prefix\" ], comment_str ) else : if len ( retval ) <= line_length: return retval if comments : if \"NOQA\" in comments : return \"{}{} {}\" . format ( retval , self . config [ \"comment_prefix\" ], comment_str ) else : return \"{}{} NOQA {}\" . format ( retval , self . config [ \"comment_prefix\" ], comment_str ) else : return \"{}{} NOQA\" . format ( retval , self . config [ \"comment_prefix\" ]) @staticmethod def _ strip_comments ( line : str , comments : Optional [ List [ str ]] = None ) -> Tuple [ str , List [ str ], bool ] : \"\"\"Removes comments from import line.\"\"\" if comments is None : comments = [] new_comments = False comment_start = line . find ( \"#\" ) if comment_start ! = - 1 : comments . append ( line [ comment_start + 1 : ]. strip ()) new_comments = True line = line [ :comment_start ] return line , comments , new_comments def _ skip_line ( self , line : str ) -> bool : skip_line = self . _ in_quote if self . index == 1 and line . startswith ( \"#\" ) : self . _ in_top_comment = True return True elif self . _ in_top_comment: if not line . startswith ( \"#\" ) or line in self . _ section_comments: self . _ in_top_comment = False self . _ first_comment_index_end = self . index - 1 if '\"' in line or \"'\" in line : index = 0 if self . _ first_comment_index_start == - 1 and ( line . startswith ( '\"' ) or line . startswith ( \"'\" ) ) : self . _ first_comment_index_start = self . index while index < len ( line ) : if line [ index ] == \" \\\\ \": index += 1 elif self._in_quote: if line[index : index + len(self._in_quote)] == self._in_quote: self._in_quote = False if ( self._first_comment_index_end < self._first_comment_index_start ): self._first_comment_index_end = self.index elif line[index] in (\" '\", ' \"'): long_quote = line[index : index + 3] if long_quote in ('\"\"\" ', \"''' \"): self._in_quote = long_quote index += 2 else: self._in_quote = line[index] elif line[index] == \" # \": break index += 1 return skip_line or self._in_quote or self._in_top_comment def _strip_syntax(self, import_string: str) -> str: import_string = import_string.replace(\" _ import \", \" [[ i ]] \") for remove_syntax in [\" \\\\ \", \" ( \", \" ) \", \" , \"]: import_string = import_string.replace(remove_syntax, \" \") import_list = import_string.split() for key in (\" from \", \" import \"): if key in import_list: import_list.remove(key) import_string = \" \".join(import_list) import_string = import_string.replace(\" [[ i ]] \", \" _ import \") return import_string.replace(\" { \", \" {| \").replace(\" } \", \" |} \") def _parse(self) -> None: \"\"\" Parses a python file taking out and categorizing imports . \"\"\" self._in_quote = False self._in_top_comment = False while not self._at_end(): raw_line = line = self._get_line() line = line.replace(\" from . import \", \" from . import \") line = line.replace(\" \\t \", \" \").replace(\" import* \", \" import * \") line = line.replace(\" . import \", \" . import \") statement_index = self.index skip_line = self._skip_line(line) if line in self._section_comments and not skip_line: if self.import_index == -1: self.import_index = self.index - 1 continue if \" isort : imports- \" in line and line.startswith(\" # \"): section = line.split(\" isort : imports- \")[-1].split()[0].upper() self.place_imports[section] = [] self.import_placements[line] = section if \" ; \" in line: for part in (part.strip() for part in line.split(\" ; \")): if ( part and not part.startswith(\" from \") and not part.startswith(\" import \") ): skip_line = True import_type = self._import_type(line) if not import_type or skip_line: self.out_lines.append(raw_line) continue for line in (line.strip() for line in line.split(\" ; \")): import_type = self._import_type(line) if not import_type: self.out_lines.append(line) continue if self.import_index == -1: self.import_index = self.index - 1 nested_comments = {} import_string, comments, new_comments = self._strip_comments(line) line_parts = [ part for part in self._strip_syntax(import_string).strip().split(\" \") if part ] if ( import_type == \" from \" and len(line_parts) == 2 and line_parts[1] != \" * \" and new_comments ): nested_comments[line_parts[-1]] = comments[0] if \" ( \" in line.split(\" # \")[0] and not self._at_end(): while not line.strip().endswith(\" ) \") and not self._at_end(): line, comments, new_comments = self._strip_comments( self._get_line(), comments ) stripped_line = self._strip_syntax(line).strip() if ( import_type == \" from \" and stripped_line and \" \" not in stripped_line and new_comments ): nested_comments[stripped_line] = comments[-1] import_string += self.line_separator + line else: while line.strip().endswith(\" \\\\ \"): line, comments, new_comments = self._strip_comments( self._get_line(), comments ) # Still need to check for parentheses after an escaped line if ( \" ( \" in line.split(\" # \")[0] and \" ) \" not in line.split(\" # \")[0] and not self._at_end() ): stripped_line = self._strip_syntax(line).strip() if ( import_type == \" from \" and stripped_line and \" \" not in stripped_line and new_comments ): nested_comments[stripped_line] = comments[-1] import_string += self.line_separator + line while not line.strip().endswith(\" ) \") and not self._at_end(): line, comments, new_comments = self._strip_comments( self._get_line(), comments ) stripped_line = self._strip_syntax(line).strip() if ( import_type == \" from \" and stripped_line and \" \" not in stripped_line and new_comments ): nested_comments[stripped_line] = comments[-1] import_string += self.line_separator + line stripped_line = self._strip_syntax(line).strip() if ( import_type == \" from \" and stripped_line and \" \" not in stripped_line and new_comments ): nested_comments[stripped_line] = comments[-1] if import_string.strip().endswith( \" import \" ) or line.strip().startswith(\" import \"): import_string += self.line_separator + line else: import_string = ( import_string.rstrip().rstrip(\" \\\\ \") + \" \" + line.lstrip() ) if import_type == \" from \": import_string = import_string.replace(\" import ( \", \" import ( \") parts = import_string.split(\" import \") from_import = parts[0].split(\" \") import_string = \" import \".join( [from_import[0] + \" \" + \"\".join(from_import[1:])] + parts[1:] ) imports = [ item.replace(\" {| \", \" { \").replace(\" |} \", \" } \") for item in self._strip_syntax(import_string).split() ] straight_import = True if \" as \" in imports and (imports.index(\" as \") + 1) < len(imports): straight_import = False while \" as \" in imports: index = imports.index(\" as \") if import_type == \" from \": module = imports[0] + \" . \" + imports[index - 1] self.as_map[module].append(imports[index + 1]) else: module = imports[index - 1] self.as_map[module].append(imports[index + 1]) if not self.config[\" combine_as_imports \"]: self.comments[\" straight \"][module] = comments comments = [] del imports[index : index + 2] if import_type == \" from \": import_from = imports.pop(0) placed_module = self.place_module(import_from) if self.config[\" verbose \"]: print( \" from - type place_module for {} returned {} \".format( import_from, placed_module ) ) if placed_module == \"\": print( \" WARNING : could not place module {} of line {} -- \" \" Do you need to define a default section? \".format( import_from, line ) ) root = self.imports[placed_module][import_type] for import_name in imports: associated_comment = nested_comments.get(import_name) if associated_comment: self.comments[\" nested \"].setdefault(import_from, {})[ import_name ] = associated_comment comments.pop(comments.index(associated_comment)) if comments: self.comments[\" from \"].setdefault(import_from, []).extend( comments ) if ( len(self.out_lines) > max(self.import_index, self._first_comment_index_end + 1, 1) - 1 ): last = self.out_lines and self.out_lines[-1].rstrip() or \"\" while ( last.startswith(\" # \") and not last.endswith('\"\"\" ') and not last.endswith(\"''' \") and \" isort : imports- \" not in last ): self.comments[\" above \"][\" from \"].setdefault( import_from, [] ).insert(0, self.out_lines.pop(-1)) if ( len(self.out_lines) > max( self.import_index - 1, self._first_comment_index_end + 1, 1, ) - 1 ): last = self.out_lines[-1].rstrip() else: last = \"\" if statement_index - 1 == self.import_index: self.import_index -= len( self.comments[\" above \"][\" from \"].get(import_from, []) ) if import_from not in root: root[import_from] = OrderedDict( (module, straight_import) for module in imports ) else: root[import_from].update( ( module, straight_import | root[import_from].get(module, False), ) for module in imports ) else: for module in imports: if comments: self.comments[\" straight \"][module] = comments comments = None if ( len(self.out_lines) > max( self.import_index, self._first_comment_index_end + 1, 1 ) - 1 ): last = self.out_lines and self.out_lines[-1].rstrip() or \"\" while ( last.startswith(\" # \") and not last.endswith('\"\"\" ') and not last.endswith(\"''' \") and \" isort : imports- \" not in last ): self.comments[\" above \"][\" straight \"].setdefault( module, [] ).insert(0, self.out_lines.pop(-1)) if ( len(self.out_lines) > 0 and len(self.out_lines) != self._first_comment_index_end ): last = self.out_lines[-1].rstrip() else: last = \"\" if self.index - 1 == self.import_index: self.import_index -= len( self.comments[\" above \"][\" straight \"].get(module, []) ) placed_module = self.place_module(module) if self.config[\" verbose \"]: print( \" else - type place_module for {} returned {} \".format( module, placed_module ) ) if placed_module == \"\": print( \" WARNING : could not place module {} of line {} -- \" \" Do you need to define a default section? \" . format ( import_from , line ) ) straight_import | = self . imports [ placed_module ][ import_type ]. get ( module , False ) self . imports [ placed_module ][ import_type ][ module ] = straight_import","title":"Module isort.isort"},{"location":"reference/isort/isort/#variables","text":"TYPE_CHECKING","title":"Variables"},{"location":"reference/isort/main/","text":"Module isort.main Tool for sorting imports alphabetically, and automatically separated into sections. Copyright (C) 2013 Timothy Edmund Crosley Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. View Source \"\"\" Tool for sorting imports alphabetically, and automatically separated into sections. Copyright (C) 2013 Timothy Edmund Crosley Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \" Software \"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \" AS IS \", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. \"\"\" import argparse import functools import glob import os import re import sys from typing import ( Any , Dict , Iterable , Iterator , List , MutableMapping , Optional , Sequence , ) import setuptools from isort import SortImports , __ version__ from isort . settings import ( DEFAULT_SECTIONS , WrapModes , default , file_should_be_skipped , from_path , ) INTRO = r \"\" \" /#######################################################################\\ ` sMMy ` . yyyy - ` ##soos## . / o . ` `` .. -.. ` `` ... ` . `` ` ```` `` - ssso ``` . s : - y - . + osssssso/. . / ossss+:so+: ` :+o- ` / osso : + sssssssso / . s : :y - osss+. `` . `` - ssss+-. ` - ossso ` ssssso/::..::+ ssss : ::. . s : :y - / ssss+//:-. ` ` ssss + ` ssss + sssso ` :ssss ` . s : :y - ` -/+oossssso / ` ssss / sssso ssss / :ssss ` . y-/y - ```` :ssss ` ossso . : ssss : ssss / :ssss . ` / so : ` ` -//::/osss + ` + ssss+-/ ossso : / sso - ` osssso/. \\/ ` -/oooo++/- . :/++:/++/- ` .. ` ://++/. isort your Python imports for you so you don't have to VERSION {} \\########################################################################/ \"\"\".format( __version__ ) shebang_re = re.compile(br\"^#!.*\\bpython[23w]?\\b\") def is_python_file(path: str) -> bool: _root, ext = os.path.splitext(path) if ext in (\".py\", \".pyi\"): return True if ext in (\".pex\",): return False # Skip editor backup files. if path.endswith(\"~\"): return False try: with open(path, \"rb\") as fp: line = fp.readline(100) except OSError: return False else: return bool(shebang_re.match(line)) class SortAttempt: def __init__(self, incorrectly_sorted: bool, skipped: bool) -> None: self.incorrectly_sorted = incorrectly_sorted self.skipped = skipped def sort_imports(file_name: str, **arguments: Any) -> Optional[SortAttempt]: try: result = SortImports(file_name, **arguments) return SortAttempt(result.incorrectly_sorted, result.skipped) except OSError as e: print(\"WARNING: Unable to parse file {} due to {}\".format(file_name, e)) return None def iter_source_code( paths: Iterable[str], config: MutableMapping[str, Any], skipped: List[str] ) -> Iterator[str]: \"\"\"Iterate over all Python source files defined in paths.\"\"\" if \"not_skip\" in config: config[\"skip\"] = list(set(config[\"skip\"]).difference(config[\"not_skip\"])) for path in paths: if os.path.isdir(path): for dirpath, dirnames, filenames in os.walk( path, topdown=True, followlinks=True ): for dirname in list(dirnames): if file_should_be_skipped(dirname, config, dirpath): skipped.append(dirname) dirnames.remove(dirname) for filename in filenames: filepath = os.path.join(dirpath, filename) if is_python_file(filepath): relative_file = os.path.relpath(filepath, path) if file_should_be_skipped(relative_file, config, path): skipped.append(filename) else: yield filepath else: yield path class ISortCommand(setuptools.Command): \"\"\"The :class:`ISortCommand` class is used by setuptools to perform imports checks on registered modules. \"\"\" description = \"Run isort on modules registered in setuptools\" user_options = [] # type: List[Any] def initialize_options(self) -> None: default_settings = default.copy() for key, value in default_settings.items(): setattr(self, key, value) def finalize_options(self) -> None: \"Get options from config files.\" self.arguments = {} # type: Dict[str, Any] computed_settings = from_path(os.getcwd()) for key, value in computed_settings.items(): self.arguments[key] = value def distribution_files(self) -> Iterator[str]: \"\"\"Find distribution packages.\"\"\" # This is verbatim from flake8 if self.distribution.packages: package_dirs = self.distribution.package_dir or {} for package in self.distribution.packages: pkg_dir = package if package in package_dirs: pkg_dir = package_dirs[package] elif \"\" in package_dirs: pkg_dir = package_dirs[\"\"] + os.path.sep + pkg_dir yield pkg_dir.replace(\".\", os.path.sep) if self.distribution.py_modules: for filename in self.distribution.py_modules: yield \"%s.py\" % filename # Don't miss the setup . py file itself yield \"setup.py\" def run ( self ) -> None : arguments = self . arguments wrong_sorted_files = False arguments [ \"check\" ] = True for path in self . distribution_files () : for python_file in glob . iglob ( os . path . join ( path , \"*.py\" )) : try : incorrectly_sorted = SortImports ( python_file , **arguments ). incorrectly_sorted if incorrectly_sorted: wrong_sorted_files = True except OSError as e : print ( \"WARNING: Unable to parse file {} due to {}\" . format ( python_file , e ) ) if wrong_sorted_files: sys . exit ( 1 ) def parse_args ( argv : Optional [ Sequence [ str ]] = None ) -> Dict [ str , Any ] : parser = argparse . ArgumentParser ( description= \"Sort Python import definitions alphabetically \" \"within logical sections. Run with no arguments to run \" \"interactively. Run with `-` as the first argument to read from \" \"stdin. Otherwise provide a list of files to sort.\" ) inline_args_group = parser . add_mutually_exclusive_group () parser . add_argument ( \"-a\" , \"--add-import\" , dest= \"add_imports\" , action= \"append\" , help= \"Adds the specified import line to all files, \" \"automatically determining correct placement.\" , ) parser . add_argument ( \"-ac\" , \"--atomic\" , dest= \"atomic\" , action= \"store_true\" , help= \"Ensures the output doesn't save if the resulting file contains syntax errors.\" , ) parser . add_argument ( \"-af\" , \"--force-adds\" , dest= \"force_adds\" , action= \"store_true\" , help= \"Forces import adds even if the original file is empty.\" , ) parser . add_argument ( \"-b\" , \"--builtin\" , dest= \"known_standard_library\" , action= \"append\" , help= \"Force sortImports to recognize a module as part of the python standard library.\" , ) parser . add_argument ( \"-c\" , \"--check-only\" , action= \"store_true\" , dest= \"check\" , help= \"Checks the file for unsorted / unformatted imports and prints them to the \" \"command line without modifying the file.\" , ) parser . add_argument ( \"-ca\" , \"--combine-as\" , dest= \"combine_as_imports\" , action= \"store_true\" , help= \"Combines as imports on the same line.\" , ) parser . add_argument ( \"-cs\" , \"--combine-star\" , dest= \"combine_star\" , action= \"store_true\" , help= \"Ensures that if a star import is present, nothing else is imported from that namespace.\" , ) parser . add_argument ( \"-d\" , \"--stdout\" , help= \"Force resulting output to stdout, instead of in-place.\" , dest= \"write_to_stdout\" , action= \"store_true\" , ) parser . add_argument ( \"-df\" , \"--diff\" , dest= \"show_diff\" , action= \"store_true\" , help= \"Prints a diff of all the changes isort would make to a file, instead of \" \"changing it in place\" , ) parser . add_argument ( \"-ds\" , \"--no-sections\" , help= \"Put all imports into the same section bucket\" , dest= \"no_sections\" , action= \"store_true\" , ) parser . add_argument ( \"-dt\" , \"--dont-order-by-type\" , dest= \"dont_order_by_type\" , action= \"store_true\" , help= \"Only order imports alphabetically, do not attempt type ordering\" , ) parser . add_argument ( \"-e\" , \"--balanced\" , dest= \"balanced_wrapping\" , action= \"store_true\" , help= \"Balances wrapping to produce the most consistent line length possible\" , ) parser . add_argument ( \"-f\" , \"--future\" , dest= \"known_future_library\" , action= \"append\" , help= \"Force sortImports to recognize a module as part of the future compatibility libraries.\" , ) parser . add_argument ( \"-fas\" , \"--force-alphabetical-sort\" , action= \"store_true\" , dest= \"force_alphabetical_sort\" , help= \"Force all imports to be sorted as a single section\" , ) parser . add_argument ( \"-fass\" , \"--force-alphabetical-sort-within-sections\" , action= \"store_true\" , dest= \"force_alphabetical_sort\" , help= \"Force all imports to be sorted alphabetically within a section\" , ) parser . add_argument ( \"-ff\" , \"--from-first\" , dest= \"from_first\" , help= \"Switches the typical ordering preference, showing from imports first then straight ones.\" , ) parser . add_argument ( \"-fgw\" , \"--force-grid-wrap\" , nargs= \"?\" , const = 2 , type = int , dest= \"force_grid_wrap\" , help= \"Force number of from imports (defaults to 2) to be grid wrapped regardless of line \" \"length\" , ) parser . add_argument ( \"-fss\" , \"--force-sort-within-sections\" , action= \"store_true\" , dest= \"force_sort_within_sections\" , help= \"Force imports to be sorted by module, independent of import_type\" , ) parser . add_argument ( \"-i\" , \"--indent\" , help='String to place for indents defaults to \" \" (4 spaces).' , dest= \"indent\" , type = str , ) parser . add_argument ( \"-j\" , \"--jobs\" , help= \"Number of files to process in parallel.\" , dest= \"jobs\" , type = int , ) parser . add_argument ( \"-k\" , \"--keep-direct-and-as\" , dest= \"keep_direct_and_as_imports\" , action= \"store_true\" , help= \"Turns off default behavior that removes direct imports when as imports exist.\" , ) parser . add_argument ( \"-l\" , \"--lines\" , help= \"[Deprecated] The max length of an import line (used for wrapping \" \"long imports).\" , dest= \"line_length\" , type = int , ) parser . add_argument ( \"-lai\" , \"--lines-after-imports\" , dest= \"lines_after_imports\" , type = int ) parser . add_argument ( \"-lbt\" , \"--lines-between-types\" , dest= \"lines_between_types\" , type = int ) parser . add_argument ( \"-le\" , \"--line-ending\" , dest= \"line_ending\" , help= \"Forces line endings to the specified value. If not set, values will be guessed per-file.\" , ) parser . add_argument ( \"-ls\" , \"--length-sort\" , help= \"Sort imports by their string length.\" , dest= \"length_sort\" , action= \"store_true\" , ) parser . add_argument ( \"-m\" , \"--multi-line\" , dest= \"multi_line_output\" , type = WrapModes . from_string , help= \"Multi line output (0-grid, 1-vertical, 2-hanging, 3-vert-hanging, 4-vert-grid, \" \"5-vert-grid-grouped, 6-vert-grid-grouped-no-comma).\" , ) inline_args_group . add_argument ( \"-nis\" , \"--no-inline-sort\" , dest= \"no_inline_sort\" , action= \"store_true\" , help= \"Leaves `from` imports with multiple imports 'as-is' (e.g. `from foo import a, c ,b`).\" , ) parser . add_argument ( \"-nlb\" , \"--no-lines-before\" , help= \"Sections which should not be split with previous by empty lines\" , dest= \"no_lines_before\" , action= \"append\" , ) parser . add_argument ( \"-ns\" , \"--dont-skip\" , help= \"Files that sort imports should never skip over.\" , dest= \"not_skip\" , action= \"append\" , ) parser . add_argument ( \"-o\" , \"--thirdparty\" , dest= \"known_third_party\" , action= \"append\" , help= \"Force sortImports to recognize a module as being part of a third party library.\" , ) parser . add_argument ( \"-ot\" , \"--order-by-type\" , dest= \"order_by_type\" , action= \"store_true\" , help= \"Order imports by type in addition to alphabetically\" , ) parser . add_argument ( \"-p\" , \"--project\" , dest= \"known_first_party\" , action= \"append\" , help= \"Force sortImports to recognize a module as being part of the current python project.\" , ) parser . add_argument ( \"-q\" , \"--quiet\" , action= \"store_true\" , dest= \"quiet\" , help= \"Shows extra quiet output, only errors are outputted.\" , ) parser . add_argument ( \"-r\" , dest= \"ambiguous_r_flag\" , action= \"store_true\" ) parser . add_argument ( \"-rm\" , \"--remove-import\" , dest= \"remove_imports\" , action= \"append\" , help= \"Removes the specified import from all files.\" , ) parser . add_argument ( \"-rr\" , \"--reverse-relative\" , dest= \"reverse_relative\" , action= \"store_true\" , help= \"Reverse order of relative imports.\" , ) parser . add_argument ( \"-rc\" , \"--recursive\" , dest= \"recursive\" , action= \"store_true\" , help= \"Recursively look for Python files of which to sort imports\" , ) parser . add_argument ( \"-s\" , \"--skip\" , help= \"Files that sort imports should skip over. If you want to skip multiple \" \"files you should specify twice: --skip file1 --skip file2.\" , dest= \"skip\" , action= \"append\" , ) parser . add_argument ( \"-sd\" , \"--section-default\" , dest= \"default_section\" , help= \"Sets the default section for imports (by default FIRSTPARTY) options: \" + str ( DEFAULT_SECTIONS ), ) parser . add_argument ( \"-sg\" , \"--skip-glob\" , help= \"Files that sort imports should skip over.\" , dest= \"skip_glob\" , action= \"append\" , ) inline_args_group . add_argument ( \"-sl\" , \"--force-single-line-imports\" , dest= \"force_single_line\" , action= \"store_true\" , help= \"Forces all from imports to appear on their own line\" , ) parser . add_argument ( \"-sp\" , \"--settings-path\" , dest= \"settings_path\" , help= \"Explicitly set the settings path instead of auto determining based on file location.\" , ) parser . add_argument ( \"-t\" , \"--top\" , help= \"Force specific imports to the top of their appropriate section.\" , dest= \"force_to_top\" , action= \"append\" , ) parser . add_argument ( \"-tc\" , \"--trailing-comma\" , dest= \"include_trailing_comma\" , action= \"store_true\" , help= \"Includes a trailing comma on multi line imports that include parentheses.\" , ) parser . add_argument ( \"-up\" , \"--use-parentheses\" , dest= \"use_parentheses\" , action= \"store_true\" , help= \"Use parenthesis for line continuation on length limit instead of slashes.\" , ) parser . add_argument ( \"-v\" , \"--version\" , action= \"store_true\" , dest= \"show_version\" ) parser . add_argument ( \"-vb\" , \"--verbose\" , action= \"store_true\" , dest= \"verbose\" , help= \"Shows verbose output, such as when files are skipped or when a check is successful.\" , ) parser . add_argument ( \"--virtual-env\" , dest= \"virtual_env\" , help= \"Virtual environment to use for determining whether a package is third-party\" , ) parser . add_argument ( \"--conda-env\" , dest= \"conda_env\" , help= \"Conda environment to use for determining whether a package is third-party\" , ) parser . add_argument ( \"-vn\" , \"--version-number\" , action= \"version\" , version= __ version__ , help= \"Returns just the current version number without the logo\" , ) parser . add_argument ( \"-w\" , \"--line-width\" , help= \"The max length of an import line (used for wrapping long imports).\" , dest= \"line_length\" , type = int , ) parser . add_argument ( \"-wl\" , \"--wrap-length\" , dest= \"wrap_length\" , type = int , help= \"Specifies how long lines that are wrapped should be, if not set line_length is used.\" , ) parser . add_argument ( \"-ws\" , \"--ignore-whitespace\" , action= \"store_true\" , dest= \"ignore_whitespace\" , help= \"Tells isort to ignore whitespace differences when --check-only is being used.\" , ) parser . add_argument ( \"-y\" , \"--apply\" , dest= \"apply\" , action= \"store_true\" , help= \"Tells isort to apply changes recursively without asking\" , ) parser . add_argument ( \"--unsafe\" , dest= \"unsafe\" , action= \"store_true\" , help= \"Tells isort to look for files in standard library directories, etc. \" \"where it may not be safe to operate in\" , ) parser . add_argument ( \"--case-sensitive\" , dest= \"case_sensitive\" , action= \"store_true\" , help= \"Tells isort to include casing when sorting module names\" , ) parser . add_argument ( \"--filter-files\" , dest= \"filter_files\" , action= \"store_true\" , help= \"Tells isort to filter files even when they are explicitly passed in as part of the command\" , ) parser . add_argument ( \"files\" , nargs= \"*\" , help= \"One or more Python source files that need their imports sorted.\" , ) parser . add_argument ( \"-py\" , \"--python-version\" , action= \"store\" , dest= \"py_version\" , help= \"Tells isort to sort the standard library based on the python version. \" \"Default is the version of the running interpreter, for instance: -py 3, -py 2.7\" , ) arguments = { key : value for key , value in vars ( parser . parse_args ( argv )). items () if value } if \"dont_order_by_type\" in arguments : arguments [ \"order_by_type\" ] = False if arguments . pop ( \"unsafe\" , False ) : arguments [ \"safety_excludes\" ] = False return arguments def main ( argv : Optional [ Sequence [ str ]] = None ) -> None : arguments = parse_args ( argv ) if arguments . get ( \"show_version\" ) : print ( INTRO ) return if arguments . get ( \"ambiguous_r_flag\" ) : print ( \"ERROR: Deprecated -r flag set. This flag has been replaced with -rm to remove ambiguity between it and \" \"-rc for recursive\" ) sys . exit ( 1 ) arguments [ \"check_skip\" ] = False if \"settings_path\" in arguments : sp = arguments [ \"settings_path\" ] arguments [ \"settings_path\" ] = ( os . path . abspath ( sp ) if os . path . isdir ( sp ) else os . path . dirname ( os . path . abspath ( sp )) ) if not os . path . isdir ( arguments [ \"settings_path\" ]) : print ( \"WARNING: settings_path dir does not exist: {}\" . format ( arguments [ \"settings_path\" ] ) ) if \"virtual_env\" in arguments : venv = arguments [ \"virtual_env\" ] arguments [ \"virtual_env\" ] = os . path . abspath ( venv ) if not os . path . isdir ( arguments [ \"virtual_env\" ]) : print ( \"WARNING: virtual_env dir does not exist: {}\" . format ( arguments [ \"virtual_env\" ] ) ) file_names = arguments . pop ( \"files\" , []) if file_names == [ \"-\" ] : SortImports ( file_contents = sys . stdin . read (), write_to_stdout = True , **arguments ) else : if not file_names: file_names = [ \".\" ] arguments [ \"recursive\" ] = True if not arguments . get ( \"apply\" , False ) : arguments [ \"ask_to_apply\" ] = True config = from_path ( arguments . get ( \"settings_path\" , \"\" ) or os . path . abspath ( file_names [ 0 ]) or os . getcwd () ). copy () config . update ( arguments ) wrong_sorted_files = False skipped = [] # type : List [ str ] if config . get ( \"filter_files\" ) : filtered_files = [] for file_name in file_names: if file_should_be_skipped ( file_name , config ) : skipped . append ( file_name ) else : filtered_files . append ( file_name ) file_names = filtered_files if arguments . get ( \"recursive\" , False ) : file_names = iter_source_code ( file_names , config , skipped ) num_skipped = 0 if config [ \"verbose\" ] or config . get ( \"show_logo\" , False ) : print ( INTRO ) jobs = arguments . get ( \"jobs\" ) if jobs : import multiprocessing executor = multiprocessing . Pool ( jobs ) attempt_iterator = executor . imap ( functools . partial ( sort_imports , **arguments ), file_names ) else : # https : // github . com / python / typeshed / pull / 2814 attempt_iterator = ( # type : ignore sort_imports ( file_name , **arguments ) for file_name in file_names ) for sort_attempt in attempt_iterator: if not sort_attempt: continue incorrectly_sorted = sort_attempt . incorrectly_sorted if arguments . get ( \"check\" , False ) and incorrectly_sorted: wrong_sorted_files = True if sort_attempt . skipped : num_skipped += 1 if wrong_sorted_files: sys . exit ( 1 ) num_skipped += len ( skipped ) if num_skipped and not arguments . get ( \"quiet\" , False ) : if config [ \"verbose\" ] : for was_skipped in skipped : print ( \"WARNING: {} was skipped as it's listed in 'skip' setting\" \" or matches a glob in 'skip_glob' setting\" . format ( was_skipped ) ) print ( \"Skipped {} files\" . format ( num_skipped )) if __ name__ == \"__main__\" : main () Variables DEFAULT_SECTIONS INTRO default shebang_re Functions is_python_file def is_python_file ( path : str ) -> bool View Source def is_python_file ( path : str ) -> bool : _root , ext = os . path . splitext ( path ) if ext in ( \" .py \" , \" .pyi \" ) : return True if ext in ( \" .pex \" , ) : return False # Skip editor backup files . if path . endswith ( \" ~ \" ) : return False try : with open ( path , \" rb \" ) as fp : line = fp . readline ( 100 ) except OSError : return False else : return bool ( shebang_re . match ( line )) iter_source_code def iter_source_code ( paths : Iterable [ str ], config : MutableMapping [ str , Any ], skipped : List [ str ] ) -> Iterator [ str ] Iterate over all Python source files defined in paths. View Source def iter_source_code ( paths : Iterable [ str ], config : MutableMapping [ str , Any ], skipped : List [ str ] ) -> Iterator [ str ]: \"\"\" Iterate over all Python source files defined in paths. \"\"\" if \" not_skip \" in config : config [ \" skip \" ] = list ( set ( config [ \" skip \" ] ) . difference ( config [ \" not_skip \" ] )) for path in paths : if os . path . isdir ( path ) : for dirpath , dirnames , filenames in os . walk ( path , topdown = True , followlinks = True ) : for dirname in list ( dirnames ) : if file_should_be_skipped ( dirname , config , dirpath ) : skipped . append ( dirname ) dirnames . remove ( dirname ) for filename in filenames : filepath = os . path . join ( dirpath , filename ) if is_python_file ( filepath ) : relative_file = os . path . relpath ( filepath , path ) if file_should_be_skipped ( relative_file , config , path ) : skipped . append ( filename ) else : yield filepath else : yield path main def main ( argv : Union [ Sequence [ str ], NoneType ] = None ) -> None View Source def main ( argv : Optional [ Sequence [ str ]] = None ) -> None : arguments = parse_args ( argv ) if arguments . get ( \" show_version \" ) : print ( INTRO ) return if arguments . get ( \" ambiguous_r_flag \" ) : print ( \" ERROR: Deprecated -r flag set. This flag has been replaced with -rm to remove ambiguity between it and \" \" -rc for recursive \" ) sys . exit ( 1 ) arguments [ \" check_skip \" ] = False if \" settings_path \" in arguments : sp = arguments [ \" settings_path \" ] arguments [ \" settings_path \" ] = ( os . path . abspath ( sp ) if os . path . isdir ( sp ) else os . path . dirname ( os . path . abspath ( sp )) ) if not os . path . isdir ( arguments [ \" settings_path \" ] ) : print ( \" WARNING: settings_path dir does not exist: {} \" . format ( arguments [ \" settings_path \" ] ) ) if \" virtual_env \" in arguments : venv = arguments [ \" virtual_env \" ] arguments [ \" virtual_env \" ] = os . path . abspath ( venv ) if not os . path . isdir ( arguments [ \" virtual_env \" ] ) : print ( \" WARNING: virtual_env dir does not exist: {} \" . format ( arguments [ \" virtual_env \" ] ) ) file_names = arguments . pop ( \" files \" , [] ) if file_names == [ \" - \" ]: SortImports ( file_contents = sys . stdin . read () , write_to_stdout = True , ** arguments ) else : if not file_names : file_names = [ \" . \" ] arguments [ \" recursive \" ] = True if not arguments . get ( \" apply \" , False ) : arguments [ \" ask_to_apply \" ] = True config = from_path ( arguments . get ( \" settings_path \" , \"\" ) or os . path . abspath ( file_names [ 0 ] ) or os . getcwd () ) . copy () config . update ( arguments ) wrong_sorted_files = False skipped = [] # type : List [ str ] if config . get ( \" filter_files \" ) : filtered_files = [] for file_name in file_names : if file_should_be_skipped ( file_name , config ) : skipped . append ( file_name ) else : filtered_files . append ( file_name ) file_names = filtered_files if arguments . get ( \" recursive \" , False ) : file_names = iter_source_code ( file_names , config , skipped ) num_skipped = 0 if config [ \" verbose \" ] or config . get ( \" show_logo \" , False ) : print ( INTRO ) jobs = arguments . get ( \" jobs \" ) if jobs : import multiprocessing executor = multiprocessing . Pool ( jobs ) attempt_iterator = executor . imap ( functools . partial ( sort_imports , ** arguments ) , file_names ) else : # https : // github . com / python / typeshed / pull / 2814 attempt_iterator = ( # type : ignore sort_imports ( file_name , ** arguments ) for file_name in file_names ) for sort_attempt in attempt_iterator : if not sort_attempt : continue incorrectly_sorted = sort_attempt . incorrectly_sorted if arguments . get ( \" check \" , False ) and incorrectly_sorted : wrong_sorted_files = True if sort_attempt . skipped : num_skipped += 1 if wrong_sorted_files : sys . exit ( 1 ) num_skipped += len ( skipped ) if num_skipped and not arguments . get ( \" quiet \" , False ) : if config [ \" verbose \" ]: for was_skipped in skipped : print ( \" WARNING: {} was skipped as it's listed in 'skip' setting \" \" or matches a glob in 'skip_glob' setting \" . format ( was_skipped ) ) print ( \" Skipped {} files \" . format ( num_skipped )) parse_args def parse_args ( argv : Union [ Sequence [ str ], NoneType ] = None ) -> Dict [ str , Any ] View Source def parse_args ( argv : Optional [ Sequence [ str ]] = None ) -> Dict [ str , Any ]: parser = argparse . ArgumentParser ( description = \"Sort Python import definitions alphabetically \" \"within logical sections. Run with no arguments to run \" \"interactively. Run with `-` as the first argument to read from \" \"stdin. Otherwise provide a list of files to sort.\" ) inline_args_group = parser . add_mutually_exclusive_group () parser . add_argument ( \"-a\" , \"--add-import\" , dest = \"add_imports\" , action = \"append\" , help = \"Adds the specified import line to all files, \" \"automatically determining correct placement.\" , ) parser . add_argument ( \"-ac\" , \"--atomic\" , dest = \"atomic\" , action = \"store_true\" , help = \"Ensures the output doesn't save if the resulting file contains syntax errors.\" , ) parser . add_argument ( \"-af\" , \"--force-adds\" , dest = \"force_adds\" , action = \"store_true\" , help = \"Forces import adds even if the original file is empty.\" , ) parser . add_argument ( \"-b\" , \"--builtin\" , dest = \"known_standard_library\" , action = \"append\" , help = \"Force sortImports to recognize a module as part of the python standard library.\" , ) parser . add_argument ( \"-c\" , \"--check-only\" , action = \"store_true\" , dest = \"check\" , help = \"Checks the file for unsorted / unformatted imports and prints them to the \" \"command line without modifying the file.\" , ) parser . add_argument ( \"-ca\" , \"--combine-as\" , dest = \"combine_as_imports\" , action = \"store_true\" , help = \"Combines as imports on the same line.\" , ) parser . add_argument ( \"-cs\" , \"--combine-star\" , dest = \"combine_star\" , action = \"store_true\" , help = \"Ensures that if a star import is present, nothing else is imported from that namespace.\" , ) parser . add_argument ( \"-d\" , \"--stdout\" , help = \"Force resulting output to stdout, instead of in-place.\" , dest = \"write_to_stdout\" , action = \"store_true\" , ) parser . add_argument ( \"-df\" , \"--diff\" , dest = \"show_diff\" , action = \"store_true\" , help = \"Prints a diff of all the changes isort would make to a file, instead of \" \"changing it in place\" , ) parser . add_argument ( \"-ds\" , \"--no-sections\" , help = \"Put all imports into the same section bucket\" , dest = \"no_sections\" , action = \"store_true\" , ) parser . add_argument ( \"-dt\" , \"--dont-order-by-type\" , dest = \"dont_order_by_type\" , action = \"store_true\" , help = \"Only order imports alphabetically, do not attempt type ordering\" , ) parser . add_argument ( \"-e\" , \"--balanced\" , dest = \"balanced_wrapping\" , action = \"store_true\" , help = \"Balances wrapping to produce the most consistent line length possible\" , ) parser . add_argument ( \"-f\" , \"--future\" , dest = \"known_future_library\" , action = \"append\" , help = \"Force sortImports to recognize a module as part of the future compatibility libraries.\" , ) parser . add_argument ( \"-fas\" , \"--force-alphabetical-sort\" , action = \"store_true\" , dest = \"force_alphabetical_sort\" , help = \"Force all imports to be sorted as a single section\" , ) parser . add_argument ( \"-fass\" , \"--force-alphabetical-sort-within-sections\" , action = \"store_true\" , dest = \"force_alphabetical_sort\" , help = \"Force all imports to be sorted alphabetically within a section\" , ) parser . add_argument ( \"-ff\" , \"--from-first\" , dest = \"from_first\" , help = \"Switches the typical ordering preference, showing from imports first then straight ones.\" , ) parser . add_argument ( \"-fgw\" , \"--force-grid-wrap\" , nargs = \"?\" , const = 2 , type = int , dest = \"force_grid_wrap\" , help = \"Force number of from imports (defaults to 2) to be grid wrapped regardless of line \" \"length\" , ) parser . add_argument ( \"-fss\" , \"--force-sort-within-sections\" , action = \"store_true\" , dest = \"force_sort_within_sections\" , help = \"Force imports to be sorted by module, independent of import_type\" , ) parser . add_argument ( \"-i\" , \"--indent\" , help = 'String to place for indents defaults to \" \" (4 spaces).' , dest = \"indent\" , type = str , ) parser . add_argument ( \"-j\" , \"--jobs\" , help = \"Number of files to process in parallel.\" , dest = \"jobs\" , type = int , ) parser . add_argument ( \"-k\" , \"--keep-direct-and-as\" , dest = \"keep_direct_and_as_imports\" , action = \"store_true\" , help = \"Turns off default behavior that removes direct imports when as imports exist.\" , ) parser . add_argument ( \"-l\" , \"--lines\" , help = \"[Deprecated] The max length of an import line (used for wrapping \" \"long imports).\" , dest = \"line_length\" , type = int , ) parser . add_argument ( \"-lai\" , \"--lines-after-imports\" , dest = \"lines_after_imports\" , type = int ) parser . add_argument ( \"-lbt\" , \"--lines-between-types\" , dest = \"lines_between_types\" , type = int ) parser . add_argument ( \"-le\" , \"--line-ending\" , dest = \"line_ending\" , help = \"Forces line endings to the specified value. If not set, values will be guessed per-file.\" , ) parser . add_argument ( \"-ls\" , \"--length-sort\" , help = \"Sort imports by their string length.\" , dest = \"length_sort\" , action = \"store_true\" , ) parser . add_argument ( \"-m\" , \"--multi-line\" , dest = \"multi_line_output\" , type = WrapModes . from_string , help = \"Multi line output (0-grid, 1-vertical, 2-hanging, 3-vert-hanging, 4-vert-grid, \" \"5-vert-grid-grouped, 6-vert-grid-grouped-no-comma).\" , ) inline_args_group . add_argument ( \"-nis\" , \"--no-inline-sort\" , dest = \"no_inline_sort\" , action = \"store_true\" , help = \"Leaves `from` imports with multiple imports 'as-is' (e.g. `from foo import a, c ,b`).\" , ) parser . add_argument ( \"-nlb\" , \"--no-lines-before\" , help = \"Sections which should not be split with previous by empty lines\" , dest = \"no_lines_before\" , action = \"append\" , ) parser . add_argument ( \"-ns\" , \"--dont-skip\" , help = \"Files that sort imports should never skip over.\" , dest = \"not_skip\" , action = \"append\" , ) parser . add_argument ( \"-o\" , \"--thirdparty\" , dest = \"known_third_party\" , action = \"append\" , help = \"Force sortImports to recognize a module as being part of a third party library.\" , ) parser . add_argument ( \"-ot\" , \"--order-by-type\" , dest = \"order_by_type\" , action = \"store_true\" , help = \"Order imports by type in addition to alphabetically\" , ) parser . add_argument ( \"-p\" , \"--project\" , dest = \"known_first_party\" , action = \"append\" , help = \"Force sortImports to recognize a module as being part of the current python project.\" , ) parser . add_argument ( \"-q\" , \"--quiet\" , action = \"store_true\" , dest = \"quiet\" , help = \"Shows extra quiet output, only errors are outputted.\" , ) parser . add_argument ( \"-r\" , dest = \"ambiguous_r_flag\" , action = \"store_true\" ) parser . add_argument ( \"-rm\" , \"--remove-import\" , dest = \"remove_imports\" , action = \"append\" , help = \"Removes the specified import from all files.\" , ) parser . add_argument ( \"-rr\" , \"--reverse-relative\" , dest = \"reverse_relative\" , action = \"store_true\" , help = \"Reverse order of relative imports.\" , ) parser . add_argument ( \"-rc\" , \"--recursive\" , dest = \"recursive\" , action = \"store_true\" , help = \"Recursively look for Python files of which to sort imports\" , ) parser . add_argument ( \"-s\" , \"--skip\" , help = \"Files that sort imports should skip over. If you want to skip multiple \" \"files you should specify twice: --skip file1 --skip file2.\" , dest = \"skip\" , action = \"append\" , ) parser . add_argument ( \"-sd\" , \"--section-default\" , dest = \"default_section\" , help = \"Sets the default section for imports (by default FIRSTPARTY) options: \" + str ( DEFAULT_SECTIONS ), ) parser . add_argument ( \"-sg\" , \"--skip-glob\" , help = \"Files that sort imports should skip over.\" , dest = \"skip_glob\" , action = \"append\" , ) inline_args_group . add_argument ( \"-sl\" , \"--force-single-line-imports\" , dest = \"force_single_line\" , action = \"store_true\" , help = \"Forces all from imports to appear on their own line\" , ) parser . add_argument ( \"-sp\" , \"--settings-path\" , dest = \"settings_path\" , help = \"Explicitly set the settings path instead of auto determining based on file location.\" , ) parser . add_argument ( \"-t\" , \"--top\" , help = \"Force specific imports to the top of their appropriate section.\" , dest = \"force_to_top\" , action = \"append\" , ) parser . add_argument ( \"-tc\" , \"--trailing-comma\" , dest = \"include_trailing_comma\" , action = \"store_true\" , help = \"Includes a trailing comma on multi line imports that include parentheses.\" , ) parser . add_argument ( \"-up\" , \"--use-parentheses\" , dest = \"use_parentheses\" , action = \"store_true\" , help = \"Use parenthesis for line continuation on length limit instead of slashes.\" , ) parser . add_argument ( \"-v\" , \"--version\" , action = \"store_true\" , dest = \"show_version\" ) parser . add_argument ( \"-vb\" , \"--verbose\" , action = \"store_true\" , dest = \"verbose\" , help = \"Shows verbose output, such as when files are skipped or when a check is successful.\" , ) parser . add_argument ( \"--virtual-env\" , dest = \"virtual_env\" , help = \"Virtual environment to use for determining whether a package is third-party\" , ) parser . add_argument ( \"--conda-env\" , dest = \"conda_env\" , help = \"Conda environment to use for determining whether a package is third-party\" , ) parser . add_argument ( \"-vn\" , \"--version-number\" , action = \"version\" , version = __version__ , help = \"Returns just the current version number without the logo\" , ) parser . add_argument ( \"-w\" , \"--line-width\" , help = \"The max length of an import line (used for wrapping long imports).\" , dest = \"line_length\" , type = int , ) parser . add_argument ( \"-wl\" , \"--wrap-length\" , dest = \"wrap_length\" , type = int , help = \"Specifies how long lines that are wrapped should be, if not set line_length is used.\" , ) parser . add_argument ( \"-ws\" , \"--ignore-whitespace\" , action = \"store_true\" , dest = \"ignore_whitespace\" , help = \"Tells isort to ignore whitespace differences when --check-only is being used.\" , ) parser . add_argument ( \"-y\" , \"--apply\" , dest = \"apply\" , action = \"store_true\" , help = \"Tells isort to apply changes recursively without asking\" , ) parser . add_argument ( \"--unsafe\" , dest = \"unsafe\" , action = \"store_true\" , help = \"Tells isort to look for files in standard library directories, etc. \" \"where it may not be safe to operate in\" , ) parser . add_argument ( \"--case-sensitive\" , dest = \"case_sensitive\" , action = \"store_true\" , help = \"Tells isort to include casing when sorting module names\" , ) parser . add_argument ( \"--filter-files\" , dest = \"filter_files\" , action = \"store_true\" , help = \"Tells isort to filter files even when they are explicitly passed in as part of the command\" , ) parser . add_argument ( \"files\" , nargs = \"*\" , help = \"One or more Python source files that need their imports sorted.\" , ) parser . add_argument ( \"-py\" , \"--python-version\" , action = \"store\" , dest = \"py_version\" , help = \"Tells isort to sort the standard library based on the python version. \" \"Default is the version of the running interpreter, for instance: -py 3, -py 2.7\" , ) arguments = { key : value for key , value in vars ( parser . parse_args ( argv )) . items () if value } if \"dont_order_by_type\" in arguments : arguments [ \"order_by_type\" ] = False if arguments . pop ( \"unsafe\" , False ): arguments [ \"safety_excludes\" ] = False return arguments sort_imports def sort_imports ( file_name : str , ** arguments : Any ) -> Union [ isort . main . SortAttempt , NoneType ] View Source def sort_imports ( file_name : str , ** arguments : Any ) -> Optional [ SortAttempt ]: try : result = SortImports ( file_name , ** arguments ) return SortAttempt ( result . incorrectly_sorted , result . skipped ) except OSError as e : print ( \" WARNING: Unable to parse file {} due to {} \" . format ( file_name , e )) return None Classes ISortCommand class ISortCommand ( dist , ** kw ) The :class: ISortCommand class is used by setuptools to perform imports checks on registered modules. View Source class ISortCommand ( setuptools . Command ) : \"\"\" The :class:`ISortCommand` class is used by setuptools to perform imports checks on registered modules . \"\"\" description = \" Run isort on modules registered in setuptools \" user_options = [] # type : List [ Any ] def initialize_options ( self ) -> None : default_settings = default . copy () for key , value in default_settings . items () : setattr ( self , key , value ) def finalize_options ( self ) -> None : \" Get options from config files. \" self . arguments = {} # type : Dict [ str , Any ] computed_settings = from_path ( os . getcwd ()) for key , value in computed_settings . items () : self . arguments [ key ] = value def distribution_files ( self ) -> Iterator [ str ]: \"\"\" Find distribution packages. \"\"\" # This is verbatim from flake8 if self . distribution . packages : package_dirs = self . distribution . package_dir or {} for package in self . distribution . packages : pkg_dir = package if package in package_dirs : pkg_dir = package_dirs [ package ] elif \"\" in package_dirs : pkg_dir = package_dirs [ \"\" ] + os . path . sep + pkg_dir yield pkg_dir . replace ( \" . \" , os . path . sep ) if self . distribution . py_modules : for filename in self . distribution . py_modules : yield \" %s.py \" % filename # Don ' t miss the setup.py file itself yield \" setup.py \" def run ( self ) -> None : arguments = self . arguments wrong_sorted_files = False arguments [ \" check \" ] = True for path in self . distribution_files () : for python_file in glob . iglob ( os . path . join ( path , \" *.py \" )) : try : incorrectly_sorted = SortImports ( python_file , ** arguments ) . incorrectly_sorted if incorrectly_sorted : wrong_sorted_files = True except OSError as e : print ( \" WARNING: Unable to parse file {} due to {} \" . format ( python_file , e ) ) if wrong_sorted_files : sys . exit ( 1 ) Ancestors (in MRO) setuptools.Command distutils.cmd.Command Class variables command_consumes_arguments description sub_commands user_options Methods announce def announce ( self , msg , level = 1 ) If the current verbosity level is of greater than or equal to 'level' print 'msg' to stdout. View Source def announce ( self , msg , level = 1 ) : \"\"\" If the current verbosity level is of greater than or equal to ' level ' print ' msg ' to stdout . \"\"\" log . log ( level , msg ) copy_file def copy_file ( self , infile , outfile , preserve_mode = 1 , preserve_times = 1 , link = None , level = 1 ) Copy a file respecting verbose, dry-run and force flags. (The former two default to whatever is in the Distribution object, and the latter defaults to false for commands that don't define it.) View Source def copy_file ( self , infile , outfile , preserve_mode = 1 , preserve_times = 1 , link = None , level = 1 ) : \"\"\" Copy a file respecting verbose, dry-run and force flags. (The former two default to whatever is in the Distribution object , and the latter defaults to false for commands that don ' t define it.)\"\"\" return file_util . copy_file ( infile , outfile , preserve_mode , preserve_times , not self . force , link , dry_run = self . dry_run ) copy_tree def copy_tree ( self , infile , outfile , preserve_mode = 1 , preserve_times = 1 , preserve_symlinks = 0 , level = 1 ) Copy an entire directory tree respecting verbose, dry-run, and force flags. View Source def copy_tree ( self , infile , outfile , preserve_mode = 1 , preserve_times = 1 , preserve_symlinks = 0 , level = 1 ) : \"\"\" Copy an entire directory tree respecting verbose, dry-run, and force flags . \"\"\" return dir_util . copy_tree ( infile , outfile , preserve_mode , preserve_times , preserve_symlinks , not self . force , dry_run = self . dry_run ) debug_print def debug_print ( self , msg ) Print 'msg' to stdout if the global DEBUG (taken from the DISTUTILS_DEBUG environment variable) flag is true. View Source def debug_print ( self , msg ): \"\"\"Print 'msg' to stdout if the global DEBUG (taken from the DISTUTILS_DEBUG environment variable) flag is true. \"\"\" from distutils.debug import DEBUG if DEBUG : print ( msg ) sys . stdout . flush () distribution_files def distribution_files ( self ) -> Iterator [ str ] Find distribution packages. View Source def distribution_files ( self ) -> Iterator [ str ]: \"\"\" Find distribution packages. \"\"\" # This is verbatim from flake8 if self . distribution . packages : package_dirs = self . distribution . package_dir or {} for package in self . distribution . packages : pkg_dir = package if package in package_dirs : pkg_dir = package_dirs [ package ] elif \"\" in package_dirs : pkg_dir = package_dirs [ \"\" ] + os . path . sep + pkg_dir yield pkg_dir . replace ( \" . \" , os . path . sep ) if self . distribution . py_modules : for filename in self . distribution . py_modules : yield \" %s.py \" % filename # Don ' t miss the setup.py file itself yield \" setup.py \" dump_options def dump_options ( self , header = None , indent = '' ) View Source def dump_options ( self , header = None , indent= \"\" ) : from distutils . fancy_getopt import longopt_xlate if header is None : header = \"command options for '%s':\" % self.get_command_name() self . announce ( indent + header , level = log . INFO ) indent = indent + \" \" for ( option , _ , _ ) in self . user_options: option = option . translate ( longopt_xlate ) if option [ - 1 ] == \"=\" : option = option [:- 1 ] value = getattr ( self , option ) self . announce ( indent + \"%s = %s\" % (option, value), level = log . INFO ) ensure_dirname def ensure_dirname ( self , option ) View Source def ensure_dirname ( self , option ): self . _ensure_tested_string ( option , os . path . isdir , \"directory name\" , \"'%s' does not exist or is not a directory\" ) ensure_filename def ensure_filename ( self , option ) Ensure that 'option' is the name of an existing file. View Source def ensure_filename ( self , option ): \"\"\"Ensure that 'option' is the name of an existing file.\"\"\" self . _ensure_tested_string ( option , os . path . isfile , \"filename\" , \"'%s' does not exist or is not a file\" ) ensure_finalized def ensure_finalized ( self ) View Source def ensure_finalized ( self ) : if not self . finalized : self . finalize_options () self . finalized = 1 ensure_string def ensure_string ( self , option , default = None ) Ensure that 'option' is a string; if not defined, set it to 'default'. View Source def ensure_string ( self , option , default = None ) : \"\"\" Ensure that 'option' is a string; if not defined, set it to ' default ' . \"\"\" self . _ensure_stringlike ( option , \" string \" , default ) ensure_string_list def ensure_string_list ( self , option ) Ensure that 'option' is a list of strings. If 'option' is currently a string, we split it either on /,\\s*/ or /\\s+/, so \"foo bar baz\", \"foo,bar,baz\", and \"foo, bar baz\" all become [\"foo\", \"bar\", \"baz\"]. View Source def ensure_string_list ( self , option ) : r \"\"\" Ensure that 'option' is a list of strings. If 'option' is currently a string , we split it either on / ,\\ s */ or / \\ s +/ , so \" foo bar baz \" , \" foo,bar,baz \" , and \" foo, bar baz \" all become [ \" foo \" , \" bar \" , \" baz \" ]. \"\"\" val = getattr ( self , option ) if val is None : return elif isinstance ( val , string_types ) : setattr ( self , option , re . split ( r ' ,\\s*|\\s+ ' , val )) else : if isinstance ( val , list ) : ok = all ( isinstance ( v , string_types ) for v in val ) else : ok = False if not ok : raise DistutilsOptionError ( \" '%s' must be a list of strings (got %r) \" % ( option , val )) execute def execute ( self , func , args , msg = None , level = 1 ) View Source def execute ( self , func , args , msg = None , level = 1 ): util . execute ( func , args , msg , dry_run = self . dry_run ) finalize_options def finalize_options ( self ) -> None Get options from config files. View Source def finalize_options ( self ) -> None : \" Get options from config files. \" self . arguments = {} # type : Dict [ str , Any ] computed_settings = from_path ( os . getcwd ()) for key , value in computed_settings . items () : self . arguments [ key ] = value get_command_name def get_command_name ( self ) View Source def get_command_name ( self ) : if hasattr ( self , ' command_name ' ) : return self . command_name else : return self . __class__ . __name__ get_finalized_command def get_finalized_command ( self , command , create = 1 ) Wrapper around Distribution's 'get_command_obj()' method: find (create if necessary and 'create' is true) the command object for 'command', call its 'ensure_finalized()' method, and return the finalized command object. View Source def get_finalized_command ( self , command , create = 1 ) : \"\"\" Wrapper around Distribution's 'get_command_obj()' method: find ( create if necessary and ' create ' is true ) the command object for ' command ' , call its ' ensure_finalized() ' method , and return the finalized command object . \"\"\" cmd_obj = self . distribution . get_command_obj ( command , create ) cmd_obj . ensure_finalized () return cmd_obj get_sub_commands def get_sub_commands ( self ) Determine the sub-commands that are relevant in the current distribution (ie., that need to be run). This is based on the 'sub_commands' class attribute: each tuple in that list may include a method that we call to determine if the subcommand needs to be run for the current distribution. Return a list of command names. View Source def get_sub_commands ( self ) : \"\"\" Determine the sub-commands that are relevant in the current distribution ( ie ., that need to be run ) . This is based on the ' sub_commands ' class attribute : each tuple in that list may include a method that we call to determine if the subcommand needs to be run for the current distribution . Return a list of command names . \"\"\" commands = [] for ( cmd_name , method ) in self . sub_commands : if method is None or method ( self ) : commands . append ( cmd_name ) return commands initialize_options def initialize_options ( self ) -> None Set default values for all the options that this command supports. Note that these defaults may be overridden by other commands, by the setup script, by config files, or by the command-line. Thus, this is not the place to code dependencies between options; generally, 'initialize_options()' implementations are just a bunch of \"self.foo = None\" assignments. This method must be implemented by all command classes. View Source def initialize_options ( self ) -> None : default_settings = default . copy () for key , value in default_settings . items () : setattr ( self , key , value ) make_archive def make_archive ( self , base_name , format , root_dir = None , base_dir = None , owner = None , group = None ) View Source def make_archive ( self , base_name , format , root_dir = None , base_dir = None , owner = None , group = None ) : return archive_util . make_archive ( base_name , format , root_dir , base_dir , dry_run = self . dry_run , owner = owner , group = group ) make_file def make_file ( self , infiles , outfile , func , args , exec_msg = None , skip_msg = None , level = 1 ) Special case of 'execute()' for operations that process one or more input files and generate one output file. Works just like 'execute()', except the operation is skipped and a different message printed if 'outfile' already exists and is newer than all files listed in 'infiles'. If the command defined 'self.force', and it is true, then the command is unconditionally run -- does no timestamp checks. View Source def make_file ( self , infiles , outfile , func , args , exec_msg = None , skip_msg = None , level = 1 ) : \"\"\" Special case of 'execute()' for operations that process one or more input files and generate one output file . Works just like ' execute() ' , except the operation is skipped and a different message printed if ' outfile ' already exists and is newer than all files listed in ' infiles ' . If the command defined ' self.force ' , and it is true , then the command is unconditionally run -- does no timestamp checks . \"\"\" if skip_msg is None : skip_msg = \" skipping %s (inputs unchanged) \" % outfile # Allow ' infiles ' to be a single string if isinstance ( infiles , str ) : infiles = ( infiles , ) elif not isinstance ( infiles , ( list , tuple )) : raise TypeError ( \" 'infiles' must be a string, or a list or tuple of strings \" ) if exec_msg is None : exec_msg = \" generating %s from %s \" % ( outfile , ' , ' . join ( infiles )) # If ' outfile ' must be regenerated ( either because it doesn ' t # exist , is out - of - date , or the ' force ' flag is true ) then # perform the action that presumably regenerates it if self . force or dep_util . newer_group ( infiles , outfile ) : self . execute ( func , args , exec_msg , level ) # Otherwise , print the \" skip \" message else : log . debug ( skip_msg ) mkpath def mkpath ( self , name , mode = 511 ) View Source def mkpath ( self , name , mode = 0 o777 ): dir_util . mkpath ( name , mode , dry_run = self . dry_run ) move_file def move_file ( self , src , dst , level = 1 ) Move a file respecting dry-run flag. View Source def move_file ( self , src , dst , level = 1 ) : \"\"\" Move a file respecting dry-run flag. \"\"\" return file_util . move_file ( src , dst , dry_run = self . dry_run ) reinitialize_command def reinitialize_command ( self , command , reinit_subcommands = 0 , ** kw ) View Source def reinitialize_command ( self , command , reinit_subcommands = 0 , ** kw ) : cmd = _Command . reinitialize_command ( self , command , reinit_subcommands ) vars ( cmd ) . update ( kw ) return cmd run def run ( self ) -> None A command's raison d'etre: carry out the action it exists to perform, controlled by the options initialized in 'initialize_options()', customized by other commands, the setup script, the command-line, and config files, and finalized in 'finalize_options()'. All terminal output and filesystem interaction should be done by 'run()'. This method must be implemented by all command classes. View Source def run ( self ) -> None : arguments = self . arguments wrong_sorted_files = False arguments [ \" check \" ] = True for path in self . distribution_files () : for python_file in glob . iglob ( os . path . join ( path , \" *.py \" )) : try : incorrectly_sorted = SortImports ( python_file , ** arguments ) . incorrectly_sorted if incorrectly_sorted : wrong_sorted_files = True except OSError as e : print ( \" WARNING: Unable to parse file {} due to {} \" . format ( python_file , e ) ) if wrong_sorted_files : sys . exit ( 1 ) run_command def run_command ( self , command ) Run some other command: uses the 'run_command()' method of Distribution, which creates and finalizes the command object if necessary and then invokes its 'run()' method. View Source def run_command ( self , command ) : \"\"\" Run some other command: uses the 'run_command()' method of Distribution , which creates and finalizes the command object if necessary and then invokes its ' run() ' method . \"\"\" self . distribution . run_command ( command ) set_undefined_options def set_undefined_options ( self , src_cmd , * option_pairs ) Set the values of any \"undefined\" options from corresponding option values in some other command object. \"Undefined\" here means \"is None\", which is the convention used to indicate that an option has not been changed between 'initialize_options()' and 'finalize_options()'. Usually called from 'finalize_options()' for options that depend on some other command rather than another option of the same command. 'src_cmd' is the other command from which option values will be taken (a command object will be created for it if necessary); the remaining arguments are '(src_option,dst_option)' tuples which mean \"take the value of 'src_option' in the 'src_cmd' command object, and copy it to 'dst_option' in the current command object\". View Source def set_undefined_options ( self , src_cmd , * option_pairs ) : \"\"\" Set the values of any \" undefined \" options from corresponding option values in some other command object . \" Undefined \" here means \" is None \" , which is the convention used to indicate that an option has not been changed between ' initialize_options() ' and ' finalize_options() ' . Usually called from ' finalize_options() ' for options that depend on some other command rather than another option of the same command . ' src_cmd ' is the other command from which option values will be taken ( a command object will be created for it if necessary ) ; the remaining arguments are ' (src_option,dst_option) ' tuples which mean \" take the value of ' src_option ' in the ' src_cmd ' command object , and copy it to ' dst_option ' in the current command object \" . \"\"\" # Option_pairs : list of ( src_option , dst_option ) tuples src_cmd_obj = self . distribution . get_command_obj ( src_cmd ) src_cmd_obj . ensure_finalized () for ( src_option , dst_option ) in option_pairs : if getattr ( self , dst_option ) is None : setattr ( self , dst_option , getattr ( src_cmd_obj , src_option )) spawn def spawn ( self , cmd , search_path = 1 , level = 1 ) Spawn an external command respecting dry-run flag. View Source def spawn ( self , cmd , search_path = 1 , level = 1 ): \"\"\"Spawn an external command respecting dry-run flag.\"\"\" from distutils.spawn import spawn spawn ( cmd , search_path , dry_run = self . dry_run ) warn def warn ( self , msg ) View Source def warn ( self , msg ): log . warn ( \"warning: %s: %s\\n\" , self . get_command_name (), msg ) SortAttempt class SortAttempt ( incorrectly_sorted : bool , skipped : bool ) View Source class SortAttempt: def __init__ ( self , incorrectly_sorted: bool , skipped: bool ) -> None: self . incorrectly_sorted = incorrectly_sorted self . skipped = skipped","title":"Main"},{"location":"reference/isort/main/#module-isortmain","text":"Tool for sorting imports alphabetically, and automatically separated into sections. Copyright (C) 2013 Timothy Edmund Crosley Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. View Source \"\"\" Tool for sorting imports alphabetically, and automatically separated into sections. Copyright (C) 2013 Timothy Edmund Crosley Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \" Software \"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \" AS IS \", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. \"\"\" import argparse import functools import glob import os import re import sys from typing import ( Any , Dict , Iterable , Iterator , List , MutableMapping , Optional , Sequence , ) import setuptools from isort import SortImports , __ version__ from isort . settings import ( DEFAULT_SECTIONS , WrapModes , default , file_should_be_skipped , from_path , ) INTRO = r \"\" \" /#######################################################################\\ ` sMMy ` . yyyy - ` ##soos## . / o . ` `` .. -.. ` `` ... ` . `` ` ```` `` - ssso ``` . s : - y - . + osssssso/. . / ossss+:so+: ` :+o- ` / osso : + sssssssso / . s : :y - osss+. `` . `` - ssss+-. ` - ossso ` ssssso/::..::+ ssss : ::. . s : :y - / ssss+//:-. ` ` ssss + ` ssss + sssso ` :ssss ` . s : :y - ` -/+oossssso / ` ssss / sssso ssss / :ssss ` . y-/y - ```` :ssss ` ossso . : ssss : ssss / :ssss . ` / so : ` ` -//::/osss + ` + ssss+-/ ossso : / sso - ` osssso/. \\/ ` -/oooo++/- . :/++:/++/- ` .. ` ://++/. isort your Python imports for you so you don't have to VERSION {} \\########################################################################/ \"\"\".format( __version__ ) shebang_re = re.compile(br\"^#!.*\\bpython[23w]?\\b\") def is_python_file(path: str) -> bool: _root, ext = os.path.splitext(path) if ext in (\".py\", \".pyi\"): return True if ext in (\".pex\",): return False # Skip editor backup files. if path.endswith(\"~\"): return False try: with open(path, \"rb\") as fp: line = fp.readline(100) except OSError: return False else: return bool(shebang_re.match(line)) class SortAttempt: def __init__(self, incorrectly_sorted: bool, skipped: bool) -> None: self.incorrectly_sorted = incorrectly_sorted self.skipped = skipped def sort_imports(file_name: str, **arguments: Any) -> Optional[SortAttempt]: try: result = SortImports(file_name, **arguments) return SortAttempt(result.incorrectly_sorted, result.skipped) except OSError as e: print(\"WARNING: Unable to parse file {} due to {}\".format(file_name, e)) return None def iter_source_code( paths: Iterable[str], config: MutableMapping[str, Any], skipped: List[str] ) -> Iterator[str]: \"\"\"Iterate over all Python source files defined in paths.\"\"\" if \"not_skip\" in config: config[\"skip\"] = list(set(config[\"skip\"]).difference(config[\"not_skip\"])) for path in paths: if os.path.isdir(path): for dirpath, dirnames, filenames in os.walk( path, topdown=True, followlinks=True ): for dirname in list(dirnames): if file_should_be_skipped(dirname, config, dirpath): skipped.append(dirname) dirnames.remove(dirname) for filename in filenames: filepath = os.path.join(dirpath, filename) if is_python_file(filepath): relative_file = os.path.relpath(filepath, path) if file_should_be_skipped(relative_file, config, path): skipped.append(filename) else: yield filepath else: yield path class ISortCommand(setuptools.Command): \"\"\"The :class:`ISortCommand` class is used by setuptools to perform imports checks on registered modules. \"\"\" description = \"Run isort on modules registered in setuptools\" user_options = [] # type: List[Any] def initialize_options(self) -> None: default_settings = default.copy() for key, value in default_settings.items(): setattr(self, key, value) def finalize_options(self) -> None: \"Get options from config files.\" self.arguments = {} # type: Dict[str, Any] computed_settings = from_path(os.getcwd()) for key, value in computed_settings.items(): self.arguments[key] = value def distribution_files(self) -> Iterator[str]: \"\"\"Find distribution packages.\"\"\" # This is verbatim from flake8 if self.distribution.packages: package_dirs = self.distribution.package_dir or {} for package in self.distribution.packages: pkg_dir = package if package in package_dirs: pkg_dir = package_dirs[package] elif \"\" in package_dirs: pkg_dir = package_dirs[\"\"] + os.path.sep + pkg_dir yield pkg_dir.replace(\".\", os.path.sep) if self.distribution.py_modules: for filename in self.distribution.py_modules: yield \"%s.py\" % filename # Don't miss the setup . py file itself yield \"setup.py\" def run ( self ) -> None : arguments = self . arguments wrong_sorted_files = False arguments [ \"check\" ] = True for path in self . distribution_files () : for python_file in glob . iglob ( os . path . join ( path , \"*.py\" )) : try : incorrectly_sorted = SortImports ( python_file , **arguments ). incorrectly_sorted if incorrectly_sorted: wrong_sorted_files = True except OSError as e : print ( \"WARNING: Unable to parse file {} due to {}\" . format ( python_file , e ) ) if wrong_sorted_files: sys . exit ( 1 ) def parse_args ( argv : Optional [ Sequence [ str ]] = None ) -> Dict [ str , Any ] : parser = argparse . ArgumentParser ( description= \"Sort Python import definitions alphabetically \" \"within logical sections. Run with no arguments to run \" \"interactively. Run with `-` as the first argument to read from \" \"stdin. Otherwise provide a list of files to sort.\" ) inline_args_group = parser . add_mutually_exclusive_group () parser . add_argument ( \"-a\" , \"--add-import\" , dest= \"add_imports\" , action= \"append\" , help= \"Adds the specified import line to all files, \" \"automatically determining correct placement.\" , ) parser . add_argument ( \"-ac\" , \"--atomic\" , dest= \"atomic\" , action= \"store_true\" , help= \"Ensures the output doesn't save if the resulting file contains syntax errors.\" , ) parser . add_argument ( \"-af\" , \"--force-adds\" , dest= \"force_adds\" , action= \"store_true\" , help= \"Forces import adds even if the original file is empty.\" , ) parser . add_argument ( \"-b\" , \"--builtin\" , dest= \"known_standard_library\" , action= \"append\" , help= \"Force sortImports to recognize a module as part of the python standard library.\" , ) parser . add_argument ( \"-c\" , \"--check-only\" , action= \"store_true\" , dest= \"check\" , help= \"Checks the file for unsorted / unformatted imports and prints them to the \" \"command line without modifying the file.\" , ) parser . add_argument ( \"-ca\" , \"--combine-as\" , dest= \"combine_as_imports\" , action= \"store_true\" , help= \"Combines as imports on the same line.\" , ) parser . add_argument ( \"-cs\" , \"--combine-star\" , dest= \"combine_star\" , action= \"store_true\" , help= \"Ensures that if a star import is present, nothing else is imported from that namespace.\" , ) parser . add_argument ( \"-d\" , \"--stdout\" , help= \"Force resulting output to stdout, instead of in-place.\" , dest= \"write_to_stdout\" , action= \"store_true\" , ) parser . add_argument ( \"-df\" , \"--diff\" , dest= \"show_diff\" , action= \"store_true\" , help= \"Prints a diff of all the changes isort would make to a file, instead of \" \"changing it in place\" , ) parser . add_argument ( \"-ds\" , \"--no-sections\" , help= \"Put all imports into the same section bucket\" , dest= \"no_sections\" , action= \"store_true\" , ) parser . add_argument ( \"-dt\" , \"--dont-order-by-type\" , dest= \"dont_order_by_type\" , action= \"store_true\" , help= \"Only order imports alphabetically, do not attempt type ordering\" , ) parser . add_argument ( \"-e\" , \"--balanced\" , dest= \"balanced_wrapping\" , action= \"store_true\" , help= \"Balances wrapping to produce the most consistent line length possible\" , ) parser . add_argument ( \"-f\" , \"--future\" , dest= \"known_future_library\" , action= \"append\" , help= \"Force sortImports to recognize a module as part of the future compatibility libraries.\" , ) parser . add_argument ( \"-fas\" , \"--force-alphabetical-sort\" , action= \"store_true\" , dest= \"force_alphabetical_sort\" , help= \"Force all imports to be sorted as a single section\" , ) parser . add_argument ( \"-fass\" , \"--force-alphabetical-sort-within-sections\" , action= \"store_true\" , dest= \"force_alphabetical_sort\" , help= \"Force all imports to be sorted alphabetically within a section\" , ) parser . add_argument ( \"-ff\" , \"--from-first\" , dest= \"from_first\" , help= \"Switches the typical ordering preference, showing from imports first then straight ones.\" , ) parser . add_argument ( \"-fgw\" , \"--force-grid-wrap\" , nargs= \"?\" , const = 2 , type = int , dest= \"force_grid_wrap\" , help= \"Force number of from imports (defaults to 2) to be grid wrapped regardless of line \" \"length\" , ) parser . add_argument ( \"-fss\" , \"--force-sort-within-sections\" , action= \"store_true\" , dest= \"force_sort_within_sections\" , help= \"Force imports to be sorted by module, independent of import_type\" , ) parser . add_argument ( \"-i\" , \"--indent\" , help='String to place for indents defaults to \" \" (4 spaces).' , dest= \"indent\" , type = str , ) parser . add_argument ( \"-j\" , \"--jobs\" , help= \"Number of files to process in parallel.\" , dest= \"jobs\" , type = int , ) parser . add_argument ( \"-k\" , \"--keep-direct-and-as\" , dest= \"keep_direct_and_as_imports\" , action= \"store_true\" , help= \"Turns off default behavior that removes direct imports when as imports exist.\" , ) parser . add_argument ( \"-l\" , \"--lines\" , help= \"[Deprecated] The max length of an import line (used for wrapping \" \"long imports).\" , dest= \"line_length\" , type = int , ) parser . add_argument ( \"-lai\" , \"--lines-after-imports\" , dest= \"lines_after_imports\" , type = int ) parser . add_argument ( \"-lbt\" , \"--lines-between-types\" , dest= \"lines_between_types\" , type = int ) parser . add_argument ( \"-le\" , \"--line-ending\" , dest= \"line_ending\" , help= \"Forces line endings to the specified value. If not set, values will be guessed per-file.\" , ) parser . add_argument ( \"-ls\" , \"--length-sort\" , help= \"Sort imports by their string length.\" , dest= \"length_sort\" , action= \"store_true\" , ) parser . add_argument ( \"-m\" , \"--multi-line\" , dest= \"multi_line_output\" , type = WrapModes . from_string , help= \"Multi line output (0-grid, 1-vertical, 2-hanging, 3-vert-hanging, 4-vert-grid, \" \"5-vert-grid-grouped, 6-vert-grid-grouped-no-comma).\" , ) inline_args_group . add_argument ( \"-nis\" , \"--no-inline-sort\" , dest= \"no_inline_sort\" , action= \"store_true\" , help= \"Leaves `from` imports with multiple imports 'as-is' (e.g. `from foo import a, c ,b`).\" , ) parser . add_argument ( \"-nlb\" , \"--no-lines-before\" , help= \"Sections which should not be split with previous by empty lines\" , dest= \"no_lines_before\" , action= \"append\" , ) parser . add_argument ( \"-ns\" , \"--dont-skip\" , help= \"Files that sort imports should never skip over.\" , dest= \"not_skip\" , action= \"append\" , ) parser . add_argument ( \"-o\" , \"--thirdparty\" , dest= \"known_third_party\" , action= \"append\" , help= \"Force sortImports to recognize a module as being part of a third party library.\" , ) parser . add_argument ( \"-ot\" , \"--order-by-type\" , dest= \"order_by_type\" , action= \"store_true\" , help= \"Order imports by type in addition to alphabetically\" , ) parser . add_argument ( \"-p\" , \"--project\" , dest= \"known_first_party\" , action= \"append\" , help= \"Force sortImports to recognize a module as being part of the current python project.\" , ) parser . add_argument ( \"-q\" , \"--quiet\" , action= \"store_true\" , dest= \"quiet\" , help= \"Shows extra quiet output, only errors are outputted.\" , ) parser . add_argument ( \"-r\" , dest= \"ambiguous_r_flag\" , action= \"store_true\" ) parser . add_argument ( \"-rm\" , \"--remove-import\" , dest= \"remove_imports\" , action= \"append\" , help= \"Removes the specified import from all files.\" , ) parser . add_argument ( \"-rr\" , \"--reverse-relative\" , dest= \"reverse_relative\" , action= \"store_true\" , help= \"Reverse order of relative imports.\" , ) parser . add_argument ( \"-rc\" , \"--recursive\" , dest= \"recursive\" , action= \"store_true\" , help= \"Recursively look for Python files of which to sort imports\" , ) parser . add_argument ( \"-s\" , \"--skip\" , help= \"Files that sort imports should skip over. If you want to skip multiple \" \"files you should specify twice: --skip file1 --skip file2.\" , dest= \"skip\" , action= \"append\" , ) parser . add_argument ( \"-sd\" , \"--section-default\" , dest= \"default_section\" , help= \"Sets the default section for imports (by default FIRSTPARTY) options: \" + str ( DEFAULT_SECTIONS ), ) parser . add_argument ( \"-sg\" , \"--skip-glob\" , help= \"Files that sort imports should skip over.\" , dest= \"skip_glob\" , action= \"append\" , ) inline_args_group . add_argument ( \"-sl\" , \"--force-single-line-imports\" , dest= \"force_single_line\" , action= \"store_true\" , help= \"Forces all from imports to appear on their own line\" , ) parser . add_argument ( \"-sp\" , \"--settings-path\" , dest= \"settings_path\" , help= \"Explicitly set the settings path instead of auto determining based on file location.\" , ) parser . add_argument ( \"-t\" , \"--top\" , help= \"Force specific imports to the top of their appropriate section.\" , dest= \"force_to_top\" , action= \"append\" , ) parser . add_argument ( \"-tc\" , \"--trailing-comma\" , dest= \"include_trailing_comma\" , action= \"store_true\" , help= \"Includes a trailing comma on multi line imports that include parentheses.\" , ) parser . add_argument ( \"-up\" , \"--use-parentheses\" , dest= \"use_parentheses\" , action= \"store_true\" , help= \"Use parenthesis for line continuation on length limit instead of slashes.\" , ) parser . add_argument ( \"-v\" , \"--version\" , action= \"store_true\" , dest= \"show_version\" ) parser . add_argument ( \"-vb\" , \"--verbose\" , action= \"store_true\" , dest= \"verbose\" , help= \"Shows verbose output, such as when files are skipped or when a check is successful.\" , ) parser . add_argument ( \"--virtual-env\" , dest= \"virtual_env\" , help= \"Virtual environment to use for determining whether a package is third-party\" , ) parser . add_argument ( \"--conda-env\" , dest= \"conda_env\" , help= \"Conda environment to use for determining whether a package is third-party\" , ) parser . add_argument ( \"-vn\" , \"--version-number\" , action= \"version\" , version= __ version__ , help= \"Returns just the current version number without the logo\" , ) parser . add_argument ( \"-w\" , \"--line-width\" , help= \"The max length of an import line (used for wrapping long imports).\" , dest= \"line_length\" , type = int , ) parser . add_argument ( \"-wl\" , \"--wrap-length\" , dest= \"wrap_length\" , type = int , help= \"Specifies how long lines that are wrapped should be, if not set line_length is used.\" , ) parser . add_argument ( \"-ws\" , \"--ignore-whitespace\" , action= \"store_true\" , dest= \"ignore_whitespace\" , help= \"Tells isort to ignore whitespace differences when --check-only is being used.\" , ) parser . add_argument ( \"-y\" , \"--apply\" , dest= \"apply\" , action= \"store_true\" , help= \"Tells isort to apply changes recursively without asking\" , ) parser . add_argument ( \"--unsafe\" , dest= \"unsafe\" , action= \"store_true\" , help= \"Tells isort to look for files in standard library directories, etc. \" \"where it may not be safe to operate in\" , ) parser . add_argument ( \"--case-sensitive\" , dest= \"case_sensitive\" , action= \"store_true\" , help= \"Tells isort to include casing when sorting module names\" , ) parser . add_argument ( \"--filter-files\" , dest= \"filter_files\" , action= \"store_true\" , help= \"Tells isort to filter files even when they are explicitly passed in as part of the command\" , ) parser . add_argument ( \"files\" , nargs= \"*\" , help= \"One or more Python source files that need their imports sorted.\" , ) parser . add_argument ( \"-py\" , \"--python-version\" , action= \"store\" , dest= \"py_version\" , help= \"Tells isort to sort the standard library based on the python version. \" \"Default is the version of the running interpreter, for instance: -py 3, -py 2.7\" , ) arguments = { key : value for key , value in vars ( parser . parse_args ( argv )). items () if value } if \"dont_order_by_type\" in arguments : arguments [ \"order_by_type\" ] = False if arguments . pop ( \"unsafe\" , False ) : arguments [ \"safety_excludes\" ] = False return arguments def main ( argv : Optional [ Sequence [ str ]] = None ) -> None : arguments = parse_args ( argv ) if arguments . get ( \"show_version\" ) : print ( INTRO ) return if arguments . get ( \"ambiguous_r_flag\" ) : print ( \"ERROR: Deprecated -r flag set. This flag has been replaced with -rm to remove ambiguity between it and \" \"-rc for recursive\" ) sys . exit ( 1 ) arguments [ \"check_skip\" ] = False if \"settings_path\" in arguments : sp = arguments [ \"settings_path\" ] arguments [ \"settings_path\" ] = ( os . path . abspath ( sp ) if os . path . isdir ( sp ) else os . path . dirname ( os . path . abspath ( sp )) ) if not os . path . isdir ( arguments [ \"settings_path\" ]) : print ( \"WARNING: settings_path dir does not exist: {}\" . format ( arguments [ \"settings_path\" ] ) ) if \"virtual_env\" in arguments : venv = arguments [ \"virtual_env\" ] arguments [ \"virtual_env\" ] = os . path . abspath ( venv ) if not os . path . isdir ( arguments [ \"virtual_env\" ]) : print ( \"WARNING: virtual_env dir does not exist: {}\" . format ( arguments [ \"virtual_env\" ] ) ) file_names = arguments . pop ( \"files\" , []) if file_names == [ \"-\" ] : SortImports ( file_contents = sys . stdin . read (), write_to_stdout = True , **arguments ) else : if not file_names: file_names = [ \".\" ] arguments [ \"recursive\" ] = True if not arguments . get ( \"apply\" , False ) : arguments [ \"ask_to_apply\" ] = True config = from_path ( arguments . get ( \"settings_path\" , \"\" ) or os . path . abspath ( file_names [ 0 ]) or os . getcwd () ). copy () config . update ( arguments ) wrong_sorted_files = False skipped = [] # type : List [ str ] if config . get ( \"filter_files\" ) : filtered_files = [] for file_name in file_names: if file_should_be_skipped ( file_name , config ) : skipped . append ( file_name ) else : filtered_files . append ( file_name ) file_names = filtered_files if arguments . get ( \"recursive\" , False ) : file_names = iter_source_code ( file_names , config , skipped ) num_skipped = 0 if config [ \"verbose\" ] or config . get ( \"show_logo\" , False ) : print ( INTRO ) jobs = arguments . get ( \"jobs\" ) if jobs : import multiprocessing executor = multiprocessing . Pool ( jobs ) attempt_iterator = executor . imap ( functools . partial ( sort_imports , **arguments ), file_names ) else : # https : // github . com / python / typeshed / pull / 2814 attempt_iterator = ( # type : ignore sort_imports ( file_name , **arguments ) for file_name in file_names ) for sort_attempt in attempt_iterator: if not sort_attempt: continue incorrectly_sorted = sort_attempt . incorrectly_sorted if arguments . get ( \"check\" , False ) and incorrectly_sorted: wrong_sorted_files = True if sort_attempt . skipped : num_skipped += 1 if wrong_sorted_files: sys . exit ( 1 ) num_skipped += len ( skipped ) if num_skipped and not arguments . get ( \"quiet\" , False ) : if config [ \"verbose\" ] : for was_skipped in skipped : print ( \"WARNING: {} was skipped as it's listed in 'skip' setting\" \" or matches a glob in 'skip_glob' setting\" . format ( was_skipped ) ) print ( \"Skipped {} files\" . format ( num_skipped )) if __ name__ == \"__main__\" : main ()","title":"Module isort.main"},{"location":"reference/isort/main/#variables","text":"DEFAULT_SECTIONS INTRO default shebang_re","title":"Variables"},{"location":"reference/isort/main/#functions","text":"","title":"Functions"},{"location":"reference/isort/main/#is_python_file","text":"def is_python_file ( path : str ) -> bool View Source def is_python_file ( path : str ) -> bool : _root , ext = os . path . splitext ( path ) if ext in ( \" .py \" , \" .pyi \" ) : return True if ext in ( \" .pex \" , ) : return False # Skip editor backup files . if path . endswith ( \" ~ \" ) : return False try : with open ( path , \" rb \" ) as fp : line = fp . readline ( 100 ) except OSError : return False else : return bool ( shebang_re . match ( line ))","title":"is_python_file"},{"location":"reference/isort/main/#iter_source_code","text":"def iter_source_code ( paths : Iterable [ str ], config : MutableMapping [ str , Any ], skipped : List [ str ] ) -> Iterator [ str ] Iterate over all Python source files defined in paths. View Source def iter_source_code ( paths : Iterable [ str ], config : MutableMapping [ str , Any ], skipped : List [ str ] ) -> Iterator [ str ]: \"\"\" Iterate over all Python source files defined in paths. \"\"\" if \" not_skip \" in config : config [ \" skip \" ] = list ( set ( config [ \" skip \" ] ) . difference ( config [ \" not_skip \" ] )) for path in paths : if os . path . isdir ( path ) : for dirpath , dirnames , filenames in os . walk ( path , topdown = True , followlinks = True ) : for dirname in list ( dirnames ) : if file_should_be_skipped ( dirname , config , dirpath ) : skipped . append ( dirname ) dirnames . remove ( dirname ) for filename in filenames : filepath = os . path . join ( dirpath , filename ) if is_python_file ( filepath ) : relative_file = os . path . relpath ( filepath , path ) if file_should_be_skipped ( relative_file , config , path ) : skipped . append ( filename ) else : yield filepath else : yield path","title":"iter_source_code"},{"location":"reference/isort/main/#main","text":"def main ( argv : Union [ Sequence [ str ], NoneType ] = None ) -> None View Source def main ( argv : Optional [ Sequence [ str ]] = None ) -> None : arguments = parse_args ( argv ) if arguments . get ( \" show_version \" ) : print ( INTRO ) return if arguments . get ( \" ambiguous_r_flag \" ) : print ( \" ERROR: Deprecated -r flag set. This flag has been replaced with -rm to remove ambiguity between it and \" \" -rc for recursive \" ) sys . exit ( 1 ) arguments [ \" check_skip \" ] = False if \" settings_path \" in arguments : sp = arguments [ \" settings_path \" ] arguments [ \" settings_path \" ] = ( os . path . abspath ( sp ) if os . path . isdir ( sp ) else os . path . dirname ( os . path . abspath ( sp )) ) if not os . path . isdir ( arguments [ \" settings_path \" ] ) : print ( \" WARNING: settings_path dir does not exist: {} \" . format ( arguments [ \" settings_path \" ] ) ) if \" virtual_env \" in arguments : venv = arguments [ \" virtual_env \" ] arguments [ \" virtual_env \" ] = os . path . abspath ( venv ) if not os . path . isdir ( arguments [ \" virtual_env \" ] ) : print ( \" WARNING: virtual_env dir does not exist: {} \" . format ( arguments [ \" virtual_env \" ] ) ) file_names = arguments . pop ( \" files \" , [] ) if file_names == [ \" - \" ]: SortImports ( file_contents = sys . stdin . read () , write_to_stdout = True , ** arguments ) else : if not file_names : file_names = [ \" . \" ] arguments [ \" recursive \" ] = True if not arguments . get ( \" apply \" , False ) : arguments [ \" ask_to_apply \" ] = True config = from_path ( arguments . get ( \" settings_path \" , \"\" ) or os . path . abspath ( file_names [ 0 ] ) or os . getcwd () ) . copy () config . update ( arguments ) wrong_sorted_files = False skipped = [] # type : List [ str ] if config . get ( \" filter_files \" ) : filtered_files = [] for file_name in file_names : if file_should_be_skipped ( file_name , config ) : skipped . append ( file_name ) else : filtered_files . append ( file_name ) file_names = filtered_files if arguments . get ( \" recursive \" , False ) : file_names = iter_source_code ( file_names , config , skipped ) num_skipped = 0 if config [ \" verbose \" ] or config . get ( \" show_logo \" , False ) : print ( INTRO ) jobs = arguments . get ( \" jobs \" ) if jobs : import multiprocessing executor = multiprocessing . Pool ( jobs ) attempt_iterator = executor . imap ( functools . partial ( sort_imports , ** arguments ) , file_names ) else : # https : // github . com / python / typeshed / pull / 2814 attempt_iterator = ( # type : ignore sort_imports ( file_name , ** arguments ) for file_name in file_names ) for sort_attempt in attempt_iterator : if not sort_attempt : continue incorrectly_sorted = sort_attempt . incorrectly_sorted if arguments . get ( \" check \" , False ) and incorrectly_sorted : wrong_sorted_files = True if sort_attempt . skipped : num_skipped += 1 if wrong_sorted_files : sys . exit ( 1 ) num_skipped += len ( skipped ) if num_skipped and not arguments . get ( \" quiet \" , False ) : if config [ \" verbose \" ]: for was_skipped in skipped : print ( \" WARNING: {} was skipped as it's listed in 'skip' setting \" \" or matches a glob in 'skip_glob' setting \" . format ( was_skipped ) ) print ( \" Skipped {} files \" . format ( num_skipped ))","title":"main"},{"location":"reference/isort/main/#parse_args","text":"def parse_args ( argv : Union [ Sequence [ str ], NoneType ] = None ) -> Dict [ str , Any ] View Source def parse_args ( argv : Optional [ Sequence [ str ]] = None ) -> Dict [ str , Any ]: parser = argparse . ArgumentParser ( description = \"Sort Python import definitions alphabetically \" \"within logical sections. Run with no arguments to run \" \"interactively. Run with `-` as the first argument to read from \" \"stdin. Otherwise provide a list of files to sort.\" ) inline_args_group = parser . add_mutually_exclusive_group () parser . add_argument ( \"-a\" , \"--add-import\" , dest = \"add_imports\" , action = \"append\" , help = \"Adds the specified import line to all files, \" \"automatically determining correct placement.\" , ) parser . add_argument ( \"-ac\" , \"--atomic\" , dest = \"atomic\" , action = \"store_true\" , help = \"Ensures the output doesn't save if the resulting file contains syntax errors.\" , ) parser . add_argument ( \"-af\" , \"--force-adds\" , dest = \"force_adds\" , action = \"store_true\" , help = \"Forces import adds even if the original file is empty.\" , ) parser . add_argument ( \"-b\" , \"--builtin\" , dest = \"known_standard_library\" , action = \"append\" , help = \"Force sortImports to recognize a module as part of the python standard library.\" , ) parser . add_argument ( \"-c\" , \"--check-only\" , action = \"store_true\" , dest = \"check\" , help = \"Checks the file for unsorted / unformatted imports and prints them to the \" \"command line without modifying the file.\" , ) parser . add_argument ( \"-ca\" , \"--combine-as\" , dest = \"combine_as_imports\" , action = \"store_true\" , help = \"Combines as imports on the same line.\" , ) parser . add_argument ( \"-cs\" , \"--combine-star\" , dest = \"combine_star\" , action = \"store_true\" , help = \"Ensures that if a star import is present, nothing else is imported from that namespace.\" , ) parser . add_argument ( \"-d\" , \"--stdout\" , help = \"Force resulting output to stdout, instead of in-place.\" , dest = \"write_to_stdout\" , action = \"store_true\" , ) parser . add_argument ( \"-df\" , \"--diff\" , dest = \"show_diff\" , action = \"store_true\" , help = \"Prints a diff of all the changes isort would make to a file, instead of \" \"changing it in place\" , ) parser . add_argument ( \"-ds\" , \"--no-sections\" , help = \"Put all imports into the same section bucket\" , dest = \"no_sections\" , action = \"store_true\" , ) parser . add_argument ( \"-dt\" , \"--dont-order-by-type\" , dest = \"dont_order_by_type\" , action = \"store_true\" , help = \"Only order imports alphabetically, do not attempt type ordering\" , ) parser . add_argument ( \"-e\" , \"--balanced\" , dest = \"balanced_wrapping\" , action = \"store_true\" , help = \"Balances wrapping to produce the most consistent line length possible\" , ) parser . add_argument ( \"-f\" , \"--future\" , dest = \"known_future_library\" , action = \"append\" , help = \"Force sortImports to recognize a module as part of the future compatibility libraries.\" , ) parser . add_argument ( \"-fas\" , \"--force-alphabetical-sort\" , action = \"store_true\" , dest = \"force_alphabetical_sort\" , help = \"Force all imports to be sorted as a single section\" , ) parser . add_argument ( \"-fass\" , \"--force-alphabetical-sort-within-sections\" , action = \"store_true\" , dest = \"force_alphabetical_sort\" , help = \"Force all imports to be sorted alphabetically within a section\" , ) parser . add_argument ( \"-ff\" , \"--from-first\" , dest = \"from_first\" , help = \"Switches the typical ordering preference, showing from imports first then straight ones.\" , ) parser . add_argument ( \"-fgw\" , \"--force-grid-wrap\" , nargs = \"?\" , const = 2 , type = int , dest = \"force_grid_wrap\" , help = \"Force number of from imports (defaults to 2) to be grid wrapped regardless of line \" \"length\" , ) parser . add_argument ( \"-fss\" , \"--force-sort-within-sections\" , action = \"store_true\" , dest = \"force_sort_within_sections\" , help = \"Force imports to be sorted by module, independent of import_type\" , ) parser . add_argument ( \"-i\" , \"--indent\" , help = 'String to place for indents defaults to \" \" (4 spaces).' , dest = \"indent\" , type = str , ) parser . add_argument ( \"-j\" , \"--jobs\" , help = \"Number of files to process in parallel.\" , dest = \"jobs\" , type = int , ) parser . add_argument ( \"-k\" , \"--keep-direct-and-as\" , dest = \"keep_direct_and_as_imports\" , action = \"store_true\" , help = \"Turns off default behavior that removes direct imports when as imports exist.\" , ) parser . add_argument ( \"-l\" , \"--lines\" , help = \"[Deprecated] The max length of an import line (used for wrapping \" \"long imports).\" , dest = \"line_length\" , type = int , ) parser . add_argument ( \"-lai\" , \"--lines-after-imports\" , dest = \"lines_after_imports\" , type = int ) parser . add_argument ( \"-lbt\" , \"--lines-between-types\" , dest = \"lines_between_types\" , type = int ) parser . add_argument ( \"-le\" , \"--line-ending\" , dest = \"line_ending\" , help = \"Forces line endings to the specified value. If not set, values will be guessed per-file.\" , ) parser . add_argument ( \"-ls\" , \"--length-sort\" , help = \"Sort imports by their string length.\" , dest = \"length_sort\" , action = \"store_true\" , ) parser . add_argument ( \"-m\" , \"--multi-line\" , dest = \"multi_line_output\" , type = WrapModes . from_string , help = \"Multi line output (0-grid, 1-vertical, 2-hanging, 3-vert-hanging, 4-vert-grid, \" \"5-vert-grid-grouped, 6-vert-grid-grouped-no-comma).\" , ) inline_args_group . add_argument ( \"-nis\" , \"--no-inline-sort\" , dest = \"no_inline_sort\" , action = \"store_true\" , help = \"Leaves `from` imports with multiple imports 'as-is' (e.g. `from foo import a, c ,b`).\" , ) parser . add_argument ( \"-nlb\" , \"--no-lines-before\" , help = \"Sections which should not be split with previous by empty lines\" , dest = \"no_lines_before\" , action = \"append\" , ) parser . add_argument ( \"-ns\" , \"--dont-skip\" , help = \"Files that sort imports should never skip over.\" , dest = \"not_skip\" , action = \"append\" , ) parser . add_argument ( \"-o\" , \"--thirdparty\" , dest = \"known_third_party\" , action = \"append\" , help = \"Force sortImports to recognize a module as being part of a third party library.\" , ) parser . add_argument ( \"-ot\" , \"--order-by-type\" , dest = \"order_by_type\" , action = \"store_true\" , help = \"Order imports by type in addition to alphabetically\" , ) parser . add_argument ( \"-p\" , \"--project\" , dest = \"known_first_party\" , action = \"append\" , help = \"Force sortImports to recognize a module as being part of the current python project.\" , ) parser . add_argument ( \"-q\" , \"--quiet\" , action = \"store_true\" , dest = \"quiet\" , help = \"Shows extra quiet output, only errors are outputted.\" , ) parser . add_argument ( \"-r\" , dest = \"ambiguous_r_flag\" , action = \"store_true\" ) parser . add_argument ( \"-rm\" , \"--remove-import\" , dest = \"remove_imports\" , action = \"append\" , help = \"Removes the specified import from all files.\" , ) parser . add_argument ( \"-rr\" , \"--reverse-relative\" , dest = \"reverse_relative\" , action = \"store_true\" , help = \"Reverse order of relative imports.\" , ) parser . add_argument ( \"-rc\" , \"--recursive\" , dest = \"recursive\" , action = \"store_true\" , help = \"Recursively look for Python files of which to sort imports\" , ) parser . add_argument ( \"-s\" , \"--skip\" , help = \"Files that sort imports should skip over. If you want to skip multiple \" \"files you should specify twice: --skip file1 --skip file2.\" , dest = \"skip\" , action = \"append\" , ) parser . add_argument ( \"-sd\" , \"--section-default\" , dest = \"default_section\" , help = \"Sets the default section for imports (by default FIRSTPARTY) options: \" + str ( DEFAULT_SECTIONS ), ) parser . add_argument ( \"-sg\" , \"--skip-glob\" , help = \"Files that sort imports should skip over.\" , dest = \"skip_glob\" , action = \"append\" , ) inline_args_group . add_argument ( \"-sl\" , \"--force-single-line-imports\" , dest = \"force_single_line\" , action = \"store_true\" , help = \"Forces all from imports to appear on their own line\" , ) parser . add_argument ( \"-sp\" , \"--settings-path\" , dest = \"settings_path\" , help = \"Explicitly set the settings path instead of auto determining based on file location.\" , ) parser . add_argument ( \"-t\" , \"--top\" , help = \"Force specific imports to the top of their appropriate section.\" , dest = \"force_to_top\" , action = \"append\" , ) parser . add_argument ( \"-tc\" , \"--trailing-comma\" , dest = \"include_trailing_comma\" , action = \"store_true\" , help = \"Includes a trailing comma on multi line imports that include parentheses.\" , ) parser . add_argument ( \"-up\" , \"--use-parentheses\" , dest = \"use_parentheses\" , action = \"store_true\" , help = \"Use parenthesis for line continuation on length limit instead of slashes.\" , ) parser . add_argument ( \"-v\" , \"--version\" , action = \"store_true\" , dest = \"show_version\" ) parser . add_argument ( \"-vb\" , \"--verbose\" , action = \"store_true\" , dest = \"verbose\" , help = \"Shows verbose output, such as when files are skipped or when a check is successful.\" , ) parser . add_argument ( \"--virtual-env\" , dest = \"virtual_env\" , help = \"Virtual environment to use for determining whether a package is third-party\" , ) parser . add_argument ( \"--conda-env\" , dest = \"conda_env\" , help = \"Conda environment to use for determining whether a package is third-party\" , ) parser . add_argument ( \"-vn\" , \"--version-number\" , action = \"version\" , version = __version__ , help = \"Returns just the current version number without the logo\" , ) parser . add_argument ( \"-w\" , \"--line-width\" , help = \"The max length of an import line (used for wrapping long imports).\" , dest = \"line_length\" , type = int , ) parser . add_argument ( \"-wl\" , \"--wrap-length\" , dest = \"wrap_length\" , type = int , help = \"Specifies how long lines that are wrapped should be, if not set line_length is used.\" , ) parser . add_argument ( \"-ws\" , \"--ignore-whitespace\" , action = \"store_true\" , dest = \"ignore_whitespace\" , help = \"Tells isort to ignore whitespace differences when --check-only is being used.\" , ) parser . add_argument ( \"-y\" , \"--apply\" , dest = \"apply\" , action = \"store_true\" , help = \"Tells isort to apply changes recursively without asking\" , ) parser . add_argument ( \"--unsafe\" , dest = \"unsafe\" , action = \"store_true\" , help = \"Tells isort to look for files in standard library directories, etc. \" \"where it may not be safe to operate in\" , ) parser . add_argument ( \"--case-sensitive\" , dest = \"case_sensitive\" , action = \"store_true\" , help = \"Tells isort to include casing when sorting module names\" , ) parser . add_argument ( \"--filter-files\" , dest = \"filter_files\" , action = \"store_true\" , help = \"Tells isort to filter files even when they are explicitly passed in as part of the command\" , ) parser . add_argument ( \"files\" , nargs = \"*\" , help = \"One or more Python source files that need their imports sorted.\" , ) parser . add_argument ( \"-py\" , \"--python-version\" , action = \"store\" , dest = \"py_version\" , help = \"Tells isort to sort the standard library based on the python version. \" \"Default is the version of the running interpreter, for instance: -py 3, -py 2.7\" , ) arguments = { key : value for key , value in vars ( parser . parse_args ( argv )) . items () if value } if \"dont_order_by_type\" in arguments : arguments [ \"order_by_type\" ] = False if arguments . pop ( \"unsafe\" , False ): arguments [ \"safety_excludes\" ] = False return arguments","title":"parse_args"},{"location":"reference/isort/main/#sort_imports","text":"def sort_imports ( file_name : str , ** arguments : Any ) -> Union [ isort . main . SortAttempt , NoneType ] View Source def sort_imports ( file_name : str , ** arguments : Any ) -> Optional [ SortAttempt ]: try : result = SortImports ( file_name , ** arguments ) return SortAttempt ( result . incorrectly_sorted , result . skipped ) except OSError as e : print ( \" WARNING: Unable to parse file {} due to {} \" . format ( file_name , e )) return None","title":"sort_imports"},{"location":"reference/isort/main/#classes","text":"","title":"Classes"},{"location":"reference/isort/main/#isortcommand","text":"class ISortCommand ( dist , ** kw ) The :class: ISortCommand class is used by setuptools to perform imports checks on registered modules. View Source class ISortCommand ( setuptools . Command ) : \"\"\" The :class:`ISortCommand` class is used by setuptools to perform imports checks on registered modules . \"\"\" description = \" Run isort on modules registered in setuptools \" user_options = [] # type : List [ Any ] def initialize_options ( self ) -> None : default_settings = default . copy () for key , value in default_settings . items () : setattr ( self , key , value ) def finalize_options ( self ) -> None : \" Get options from config files. \" self . arguments = {} # type : Dict [ str , Any ] computed_settings = from_path ( os . getcwd ()) for key , value in computed_settings . items () : self . arguments [ key ] = value def distribution_files ( self ) -> Iterator [ str ]: \"\"\" Find distribution packages. \"\"\" # This is verbatim from flake8 if self . distribution . packages : package_dirs = self . distribution . package_dir or {} for package in self . distribution . packages : pkg_dir = package if package in package_dirs : pkg_dir = package_dirs [ package ] elif \"\" in package_dirs : pkg_dir = package_dirs [ \"\" ] + os . path . sep + pkg_dir yield pkg_dir . replace ( \" . \" , os . path . sep ) if self . distribution . py_modules : for filename in self . distribution . py_modules : yield \" %s.py \" % filename # Don ' t miss the setup.py file itself yield \" setup.py \" def run ( self ) -> None : arguments = self . arguments wrong_sorted_files = False arguments [ \" check \" ] = True for path in self . distribution_files () : for python_file in glob . iglob ( os . path . join ( path , \" *.py \" )) : try : incorrectly_sorted = SortImports ( python_file , ** arguments ) . incorrectly_sorted if incorrectly_sorted : wrong_sorted_files = True except OSError as e : print ( \" WARNING: Unable to parse file {} due to {} \" . format ( python_file , e ) ) if wrong_sorted_files : sys . exit ( 1 )","title":"ISortCommand"},{"location":"reference/isort/main/#ancestors-in-mro","text":"setuptools.Command distutils.cmd.Command","title":"Ancestors (in MRO)"},{"location":"reference/isort/main/#class-variables","text":"command_consumes_arguments description sub_commands user_options","title":"Class variables"},{"location":"reference/isort/main/#methods","text":"","title":"Methods"},{"location":"reference/isort/main/#announce","text":"def announce ( self , msg , level = 1 ) If the current verbosity level is of greater than or equal to 'level' print 'msg' to stdout. View Source def announce ( self , msg , level = 1 ) : \"\"\" If the current verbosity level is of greater than or equal to ' level ' print ' msg ' to stdout . \"\"\" log . log ( level , msg )","title":"announce"},{"location":"reference/isort/main/#copy_file","text":"def copy_file ( self , infile , outfile , preserve_mode = 1 , preserve_times = 1 , link = None , level = 1 ) Copy a file respecting verbose, dry-run and force flags. (The former two default to whatever is in the Distribution object, and the latter defaults to false for commands that don't define it.) View Source def copy_file ( self , infile , outfile , preserve_mode = 1 , preserve_times = 1 , link = None , level = 1 ) : \"\"\" Copy a file respecting verbose, dry-run and force flags. (The former two default to whatever is in the Distribution object , and the latter defaults to false for commands that don ' t define it.)\"\"\" return file_util . copy_file ( infile , outfile , preserve_mode , preserve_times , not self . force , link , dry_run = self . dry_run )","title":"copy_file"},{"location":"reference/isort/main/#copy_tree","text":"def copy_tree ( self , infile , outfile , preserve_mode = 1 , preserve_times = 1 , preserve_symlinks = 0 , level = 1 ) Copy an entire directory tree respecting verbose, dry-run, and force flags. View Source def copy_tree ( self , infile , outfile , preserve_mode = 1 , preserve_times = 1 , preserve_symlinks = 0 , level = 1 ) : \"\"\" Copy an entire directory tree respecting verbose, dry-run, and force flags . \"\"\" return dir_util . copy_tree ( infile , outfile , preserve_mode , preserve_times , preserve_symlinks , not self . force , dry_run = self . dry_run )","title":"copy_tree"},{"location":"reference/isort/main/#debug_print","text":"def debug_print ( self , msg ) Print 'msg' to stdout if the global DEBUG (taken from the DISTUTILS_DEBUG environment variable) flag is true. View Source def debug_print ( self , msg ): \"\"\"Print 'msg' to stdout if the global DEBUG (taken from the DISTUTILS_DEBUG environment variable) flag is true. \"\"\" from distutils.debug import DEBUG if DEBUG : print ( msg ) sys . stdout . flush ()","title":"debug_print"},{"location":"reference/isort/main/#distribution_files","text":"def distribution_files ( self ) -> Iterator [ str ] Find distribution packages. View Source def distribution_files ( self ) -> Iterator [ str ]: \"\"\" Find distribution packages. \"\"\" # This is verbatim from flake8 if self . distribution . packages : package_dirs = self . distribution . package_dir or {} for package in self . distribution . packages : pkg_dir = package if package in package_dirs : pkg_dir = package_dirs [ package ] elif \"\" in package_dirs : pkg_dir = package_dirs [ \"\" ] + os . path . sep + pkg_dir yield pkg_dir . replace ( \" . \" , os . path . sep ) if self . distribution . py_modules : for filename in self . distribution . py_modules : yield \" %s.py \" % filename # Don ' t miss the setup.py file itself yield \" setup.py \"","title":"distribution_files"},{"location":"reference/isort/main/#dump_options","text":"def dump_options ( self , header = None , indent = '' ) View Source def dump_options ( self , header = None , indent= \"\" ) : from distutils . fancy_getopt import longopt_xlate if header is None : header = \"command options for '%s':\" % self.get_command_name() self . announce ( indent + header , level = log . INFO ) indent = indent + \" \" for ( option , _ , _ ) in self . user_options: option = option . translate ( longopt_xlate ) if option [ - 1 ] == \"=\" : option = option [:- 1 ] value = getattr ( self , option ) self . announce ( indent + \"%s = %s\" % (option, value), level = log . INFO )","title":"dump_options"},{"location":"reference/isort/main/#ensure_dirname","text":"def ensure_dirname ( self , option ) View Source def ensure_dirname ( self , option ): self . _ensure_tested_string ( option , os . path . isdir , \"directory name\" , \"'%s' does not exist or is not a directory\" )","title":"ensure_dirname"},{"location":"reference/isort/main/#ensure_filename","text":"def ensure_filename ( self , option ) Ensure that 'option' is the name of an existing file. View Source def ensure_filename ( self , option ): \"\"\"Ensure that 'option' is the name of an existing file.\"\"\" self . _ensure_tested_string ( option , os . path . isfile , \"filename\" , \"'%s' does not exist or is not a file\" )","title":"ensure_filename"},{"location":"reference/isort/main/#ensure_finalized","text":"def ensure_finalized ( self ) View Source def ensure_finalized ( self ) : if not self . finalized : self . finalize_options () self . finalized = 1","title":"ensure_finalized"},{"location":"reference/isort/main/#ensure_string","text":"def ensure_string ( self , option , default = None ) Ensure that 'option' is a string; if not defined, set it to 'default'. View Source def ensure_string ( self , option , default = None ) : \"\"\" Ensure that 'option' is a string; if not defined, set it to ' default ' . \"\"\" self . _ensure_stringlike ( option , \" string \" , default )","title":"ensure_string"},{"location":"reference/isort/main/#ensure_string_list","text":"def ensure_string_list ( self , option ) Ensure that 'option' is a list of strings. If 'option' is currently a string, we split it either on /,\\s*/ or /\\s+/, so \"foo bar baz\", \"foo,bar,baz\", and \"foo, bar baz\" all become [\"foo\", \"bar\", \"baz\"]. View Source def ensure_string_list ( self , option ) : r \"\"\" Ensure that 'option' is a list of strings. If 'option' is currently a string , we split it either on / ,\\ s */ or / \\ s +/ , so \" foo bar baz \" , \" foo,bar,baz \" , and \" foo, bar baz \" all become [ \" foo \" , \" bar \" , \" baz \" ]. \"\"\" val = getattr ( self , option ) if val is None : return elif isinstance ( val , string_types ) : setattr ( self , option , re . split ( r ' ,\\s*|\\s+ ' , val )) else : if isinstance ( val , list ) : ok = all ( isinstance ( v , string_types ) for v in val ) else : ok = False if not ok : raise DistutilsOptionError ( \" '%s' must be a list of strings (got %r) \" % ( option , val ))","title":"ensure_string_list"},{"location":"reference/isort/main/#execute","text":"def execute ( self , func , args , msg = None , level = 1 ) View Source def execute ( self , func , args , msg = None , level = 1 ): util . execute ( func , args , msg , dry_run = self . dry_run )","title":"execute"},{"location":"reference/isort/main/#finalize_options","text":"def finalize_options ( self ) -> None Get options from config files. View Source def finalize_options ( self ) -> None : \" Get options from config files. \" self . arguments = {} # type : Dict [ str , Any ] computed_settings = from_path ( os . getcwd ()) for key , value in computed_settings . items () : self . arguments [ key ] = value","title":"finalize_options"},{"location":"reference/isort/main/#get_command_name","text":"def get_command_name ( self ) View Source def get_command_name ( self ) : if hasattr ( self , ' command_name ' ) : return self . command_name else : return self . __class__ . __name__","title":"get_command_name"},{"location":"reference/isort/main/#get_finalized_command","text":"def get_finalized_command ( self , command , create = 1 ) Wrapper around Distribution's 'get_command_obj()' method: find (create if necessary and 'create' is true) the command object for 'command', call its 'ensure_finalized()' method, and return the finalized command object. View Source def get_finalized_command ( self , command , create = 1 ) : \"\"\" Wrapper around Distribution's 'get_command_obj()' method: find ( create if necessary and ' create ' is true ) the command object for ' command ' , call its ' ensure_finalized() ' method , and return the finalized command object . \"\"\" cmd_obj = self . distribution . get_command_obj ( command , create ) cmd_obj . ensure_finalized () return cmd_obj","title":"get_finalized_command"},{"location":"reference/isort/main/#get_sub_commands","text":"def get_sub_commands ( self ) Determine the sub-commands that are relevant in the current distribution (ie., that need to be run). This is based on the 'sub_commands' class attribute: each tuple in that list may include a method that we call to determine if the subcommand needs to be run for the current distribution. Return a list of command names. View Source def get_sub_commands ( self ) : \"\"\" Determine the sub-commands that are relevant in the current distribution ( ie ., that need to be run ) . This is based on the ' sub_commands ' class attribute : each tuple in that list may include a method that we call to determine if the subcommand needs to be run for the current distribution . Return a list of command names . \"\"\" commands = [] for ( cmd_name , method ) in self . sub_commands : if method is None or method ( self ) : commands . append ( cmd_name ) return commands","title":"get_sub_commands"},{"location":"reference/isort/main/#initialize_options","text":"def initialize_options ( self ) -> None Set default values for all the options that this command supports. Note that these defaults may be overridden by other commands, by the setup script, by config files, or by the command-line. Thus, this is not the place to code dependencies between options; generally, 'initialize_options()' implementations are just a bunch of \"self.foo = None\" assignments. This method must be implemented by all command classes. View Source def initialize_options ( self ) -> None : default_settings = default . copy () for key , value in default_settings . items () : setattr ( self , key , value )","title":"initialize_options"},{"location":"reference/isort/main/#make_archive","text":"def make_archive ( self , base_name , format , root_dir = None , base_dir = None , owner = None , group = None ) View Source def make_archive ( self , base_name , format , root_dir = None , base_dir = None , owner = None , group = None ) : return archive_util . make_archive ( base_name , format , root_dir , base_dir , dry_run = self . dry_run , owner = owner , group = group )","title":"make_archive"},{"location":"reference/isort/main/#make_file","text":"def make_file ( self , infiles , outfile , func , args , exec_msg = None , skip_msg = None , level = 1 ) Special case of 'execute()' for operations that process one or more input files and generate one output file. Works just like 'execute()', except the operation is skipped and a different message printed if 'outfile' already exists and is newer than all files listed in 'infiles'. If the command defined 'self.force', and it is true, then the command is unconditionally run -- does no timestamp checks. View Source def make_file ( self , infiles , outfile , func , args , exec_msg = None , skip_msg = None , level = 1 ) : \"\"\" Special case of 'execute()' for operations that process one or more input files and generate one output file . Works just like ' execute() ' , except the operation is skipped and a different message printed if ' outfile ' already exists and is newer than all files listed in ' infiles ' . If the command defined ' self.force ' , and it is true , then the command is unconditionally run -- does no timestamp checks . \"\"\" if skip_msg is None : skip_msg = \" skipping %s (inputs unchanged) \" % outfile # Allow ' infiles ' to be a single string if isinstance ( infiles , str ) : infiles = ( infiles , ) elif not isinstance ( infiles , ( list , tuple )) : raise TypeError ( \" 'infiles' must be a string, or a list or tuple of strings \" ) if exec_msg is None : exec_msg = \" generating %s from %s \" % ( outfile , ' , ' . join ( infiles )) # If ' outfile ' must be regenerated ( either because it doesn ' t # exist , is out - of - date , or the ' force ' flag is true ) then # perform the action that presumably regenerates it if self . force or dep_util . newer_group ( infiles , outfile ) : self . execute ( func , args , exec_msg , level ) # Otherwise , print the \" skip \" message else : log . debug ( skip_msg )","title":"make_file"},{"location":"reference/isort/main/#mkpath","text":"def mkpath ( self , name , mode = 511 ) View Source def mkpath ( self , name , mode = 0 o777 ): dir_util . mkpath ( name , mode , dry_run = self . dry_run )","title":"mkpath"},{"location":"reference/isort/main/#move_file","text":"def move_file ( self , src , dst , level = 1 ) Move a file respecting dry-run flag. View Source def move_file ( self , src , dst , level = 1 ) : \"\"\" Move a file respecting dry-run flag. \"\"\" return file_util . move_file ( src , dst , dry_run = self . dry_run )","title":"move_file"},{"location":"reference/isort/main/#reinitialize_command","text":"def reinitialize_command ( self , command , reinit_subcommands = 0 , ** kw ) View Source def reinitialize_command ( self , command , reinit_subcommands = 0 , ** kw ) : cmd = _Command . reinitialize_command ( self , command , reinit_subcommands ) vars ( cmd ) . update ( kw ) return cmd","title":"reinitialize_command"},{"location":"reference/isort/main/#run","text":"def run ( self ) -> None A command's raison d'etre: carry out the action it exists to perform, controlled by the options initialized in 'initialize_options()', customized by other commands, the setup script, the command-line, and config files, and finalized in 'finalize_options()'. All terminal output and filesystem interaction should be done by 'run()'. This method must be implemented by all command classes. View Source def run ( self ) -> None : arguments = self . arguments wrong_sorted_files = False arguments [ \" check \" ] = True for path in self . distribution_files () : for python_file in glob . iglob ( os . path . join ( path , \" *.py \" )) : try : incorrectly_sorted = SortImports ( python_file , ** arguments ) . incorrectly_sorted if incorrectly_sorted : wrong_sorted_files = True except OSError as e : print ( \" WARNING: Unable to parse file {} due to {} \" . format ( python_file , e ) ) if wrong_sorted_files : sys . exit ( 1 )","title":"run"},{"location":"reference/isort/main/#run_command","text":"def run_command ( self , command ) Run some other command: uses the 'run_command()' method of Distribution, which creates and finalizes the command object if necessary and then invokes its 'run()' method. View Source def run_command ( self , command ) : \"\"\" Run some other command: uses the 'run_command()' method of Distribution , which creates and finalizes the command object if necessary and then invokes its ' run() ' method . \"\"\" self . distribution . run_command ( command )","title":"run_command"},{"location":"reference/isort/main/#set_undefined_options","text":"def set_undefined_options ( self , src_cmd , * option_pairs ) Set the values of any \"undefined\" options from corresponding option values in some other command object. \"Undefined\" here means \"is None\", which is the convention used to indicate that an option has not been changed between 'initialize_options()' and 'finalize_options()'. Usually called from 'finalize_options()' for options that depend on some other command rather than another option of the same command. 'src_cmd' is the other command from which option values will be taken (a command object will be created for it if necessary); the remaining arguments are '(src_option,dst_option)' tuples which mean \"take the value of 'src_option' in the 'src_cmd' command object, and copy it to 'dst_option' in the current command object\". View Source def set_undefined_options ( self , src_cmd , * option_pairs ) : \"\"\" Set the values of any \" undefined \" options from corresponding option values in some other command object . \" Undefined \" here means \" is None \" , which is the convention used to indicate that an option has not been changed between ' initialize_options() ' and ' finalize_options() ' . Usually called from ' finalize_options() ' for options that depend on some other command rather than another option of the same command . ' src_cmd ' is the other command from which option values will be taken ( a command object will be created for it if necessary ) ; the remaining arguments are ' (src_option,dst_option) ' tuples which mean \" take the value of ' src_option ' in the ' src_cmd ' command object , and copy it to ' dst_option ' in the current command object \" . \"\"\" # Option_pairs : list of ( src_option , dst_option ) tuples src_cmd_obj = self . distribution . get_command_obj ( src_cmd ) src_cmd_obj . ensure_finalized () for ( src_option , dst_option ) in option_pairs : if getattr ( self , dst_option ) is None : setattr ( self , dst_option , getattr ( src_cmd_obj , src_option ))","title":"set_undefined_options"},{"location":"reference/isort/main/#spawn","text":"def spawn ( self , cmd , search_path = 1 , level = 1 ) Spawn an external command respecting dry-run flag. View Source def spawn ( self , cmd , search_path = 1 , level = 1 ): \"\"\"Spawn an external command respecting dry-run flag.\"\"\" from distutils.spawn import spawn spawn ( cmd , search_path , dry_run = self . dry_run )","title":"spawn"},{"location":"reference/isort/main/#warn","text":"def warn ( self , msg ) View Source def warn ( self , msg ): log . warn ( \"warning: %s: %s\\n\" , self . get_command_name (), msg )","title":"warn"},{"location":"reference/isort/main/#sortattempt","text":"class SortAttempt ( incorrectly_sorted : bool , skipped : bool ) View Source class SortAttempt: def __init__ ( self , incorrectly_sorted: bool , skipped: bool ) -> None: self . incorrectly_sorted = incorrectly_sorted self . skipped = skipped","title":"SortAttempt"},{"location":"reference/isort/natural/","text":"Module isort.natural isort/natural.py. Enables sorting strings that contain numbers naturally usage: natural.nsorted(list) Copyright (C) 2013 Timothy Edmund Crosley Implementation originally from @HappyLeapSecond stack overflow user in response to: https://stackoverflow.com/questions/5967500/how-to-correctly-sort-a-string-with-a-number-inside Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. View Source \"\"\" isort/natural.py. Enables sorting strings that contain numbers naturally usage : natural . nsorted ( list ) Copyright ( C ) 2013 Timothy Edmund Crosley Implementation originally from @ HappyLeapSecond stack overflow user in response to : https : // stackoverflow . com / questions / 5967500 / how - to - correctly - sort - a - string - with - a - number - inside Permission is hereby granted , free of charge , to any person obtaining a copy of this software and associated documentation files ( the \" Software \" ) , to deal in the Software without restriction , including without limitation the rights to use , copy , modify , merge , publish , distribute , sublicense , and / or sell copies of the Software , and to permit persons to whom the Software is furnished to do so , subject to the following conditions : The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software . THE SOFTWARE IS PROVIDED \" AS IS \" , WITHOUT WARRANTY OF ANY KIND , EXPRESS OR IMPLIED , INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY , FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT . IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM , DAMAGES OR OTHER LIABILITY , WHETHER IN AN ACTION OF CONTRACT , TORT OR OTHERWISE , ARISING FROM , OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE . \"\"\" import re from typing import Any , Callable , Iterable , List , Optional def _atoi ( text : str ) -> Any : return int ( text ) if text . isdigit () else text def _natural_keys ( text : str ) -> List [ Any ]: return [ _atoi ( c ) for c in re . split ( r \" (\\d+) \" , text ) ] def nsorted ( to_sort : Iterable [ str ], key : Optional [ Callable [[ str ], Any ]] = None ) -> List [ str ]: \"\"\" Returns a naturally sorted list \"\"\" if key is None : key_callback = _natural_keys else : def key_callback ( text : str ) -> List [ Any ]: return _natural_keys ( key ( text )) # type : ignore return sorted ( to_sort , key = key_callback ) Functions nsorted def nsorted ( to_sort : Iterable [ str ], key : Union [ Callable [[ str ], Any ], NoneType ] = None ) -> List [ str ] Returns a naturally sorted list View Source def nsorted ( to_sort : Iterable [ str ], key : Optional [ Callable [[ str ], Any ]] = None ) -> List [ str ]: \"\"\" Returns a naturally sorted list \"\"\" if key is None : key_callback = _natural_keys else : def key_callback ( text : str ) -> List [ Any ]: return _natural_keys ( key ( text )) # type : ignore return sorted ( to_sort , key = key_callback )","title":"Natural"},{"location":"reference/isort/natural/#module-isortnatural","text":"isort/natural.py. Enables sorting strings that contain numbers naturally usage: natural.nsorted(list) Copyright (C) 2013 Timothy Edmund Crosley Implementation originally from @HappyLeapSecond stack overflow user in response to: https://stackoverflow.com/questions/5967500/how-to-correctly-sort-a-string-with-a-number-inside Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. View Source \"\"\" isort/natural.py. Enables sorting strings that contain numbers naturally usage : natural . nsorted ( list ) Copyright ( C ) 2013 Timothy Edmund Crosley Implementation originally from @ HappyLeapSecond stack overflow user in response to : https : // stackoverflow . com / questions / 5967500 / how - to - correctly - sort - a - string - with - a - number - inside Permission is hereby granted , free of charge , to any person obtaining a copy of this software and associated documentation files ( the \" Software \" ) , to deal in the Software without restriction , including without limitation the rights to use , copy , modify , merge , publish , distribute , sublicense , and / or sell copies of the Software , and to permit persons to whom the Software is furnished to do so , subject to the following conditions : The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software . THE SOFTWARE IS PROVIDED \" AS IS \" , WITHOUT WARRANTY OF ANY KIND , EXPRESS OR IMPLIED , INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY , FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT . IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM , DAMAGES OR OTHER LIABILITY , WHETHER IN AN ACTION OF CONTRACT , TORT OR OTHERWISE , ARISING FROM , OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE . \"\"\" import re from typing import Any , Callable , Iterable , List , Optional def _atoi ( text : str ) -> Any : return int ( text ) if text . isdigit () else text def _natural_keys ( text : str ) -> List [ Any ]: return [ _atoi ( c ) for c in re . split ( r \" (\\d+) \" , text ) ] def nsorted ( to_sort : Iterable [ str ], key : Optional [ Callable [[ str ], Any ]] = None ) -> List [ str ]: \"\"\" Returns a naturally sorted list \"\"\" if key is None : key_callback = _natural_keys else : def key_callback ( text : str ) -> List [ Any ]: return _natural_keys ( key ( text )) # type : ignore return sorted ( to_sort , key = key_callback )","title":"Module isort.natural"},{"location":"reference/isort/natural/#functions","text":"","title":"Functions"},{"location":"reference/isort/natural/#nsorted","text":"def nsorted ( to_sort : Iterable [ str ], key : Union [ Callable [[ str ], Any ], NoneType ] = None ) -> List [ str ] Returns a naturally sorted list View Source def nsorted ( to_sort : Iterable [ str ], key : Optional [ Callable [[ str ], Any ]] = None ) -> List [ str ]: \"\"\" Returns a naturally sorted list \"\"\" if key is None : key_callback = _natural_keys else : def key_callback ( text : str ) -> List [ Any ]: return _natural_keys ( key ( text )) # type : ignore return sorted ( to_sort , key = key_callback )","title":"nsorted"},{"location":"reference/isort/pylama_isort/","text":"Module isort.pylama_isort View Source import os import sys from typing import Any , Dict , List from pylama.lint import Linter as BaseLinter from . import SortImports class Linter ( BaseLinter ): def allow ( self , path : str ) -> bool : \"\"\"Determine if this path should be linted.\"\"\" return path . endswith ( \".py\" ) def run ( self , path : str , ** meta : Any ) -> List [ Dict [ str , Any ]]: \"\"\"Lint the file. Return an array of error dicts if appropriate.\"\"\" with open ( os . devnull , \"w\" ) as devnull : # Suppress isort messages sys . stdout = devnull if SortImports ( path , check = True ) . incorrectly_sorted : return [ { \"lnum\" : 0 , \"col\" : 0 , \"text\" : \"Incorrectly sorted imports.\" , \"type\" : \"ISORT\" , } ] else : return [] Classes Linter class Linter ( / , * args , ** kwargs ) Abstract class for linter plugin. View Source class Linter ( BaseLinter ) : def allow ( self , path : str ) -> bool : \"\"\" Determine if this path should be linted. \"\"\" return path . endswith ( \" .py \" ) def run ( self , path : str , ** meta : Any ) -> List [ Dict [ str , Any ]]: \"\"\" Lint the file. Return an array of error dicts if appropriate. \"\"\" with open ( os . devnull , \" w \" ) as devnull : # Suppress isort messages sys . stdout = devnull if SortImports ( path , check = True ) . incorrectly_sorted : return [ { \" lnum \" : 0 , \" col \" : 0 , \" text \" : \" Incorrectly sorted imports. \" , \" type \" : \" ISORT \" , } ] else : return [] Ancestors (in MRO) pylama.lint.Linter Methods allow def allow ( self , path : str ) -> bool Determine if this path should be linted. View Source def allow ( self , path : str ) -> bool : \"\"\" Determine if this path should be linted. \"\"\" return path . endswith ( \" .py \" ) run def run ( self , path : str , ** meta : Any ) -> List [ Dict [ str , Any ]] Lint the file. Return an array of error dicts if appropriate. View Source def run ( self , path : str , ** meta : Any ) -> List [ Dict [ str , Any ]]: \"\"\" Lint the file. Return an array of error dicts if appropriate. \"\"\" with open ( os . devnull , \" w \" ) as devnull : # Suppress isort messages sys . stdout = devnull if SortImports ( path , check = True ) . incorrectly_sorted : return [ { \" lnum \" : 0 , \" col \" : 0 , \" text \" : \" Incorrectly sorted imports. \" , \" type \" : \" ISORT \" , } ] else : return []","title":"Pylama Isort"},{"location":"reference/isort/pylama_isort/#module-isortpylama_isort","text":"View Source import os import sys from typing import Any , Dict , List from pylama.lint import Linter as BaseLinter from . import SortImports class Linter ( BaseLinter ): def allow ( self , path : str ) -> bool : \"\"\"Determine if this path should be linted.\"\"\" return path . endswith ( \".py\" ) def run ( self , path : str , ** meta : Any ) -> List [ Dict [ str , Any ]]: \"\"\"Lint the file. Return an array of error dicts if appropriate.\"\"\" with open ( os . devnull , \"w\" ) as devnull : # Suppress isort messages sys . stdout = devnull if SortImports ( path , check = True ) . incorrectly_sorted : return [ { \"lnum\" : 0 , \"col\" : 0 , \"text\" : \"Incorrectly sorted imports.\" , \"type\" : \"ISORT\" , } ] else : return []","title":"Module isort.pylama_isort"},{"location":"reference/isort/pylama_isort/#classes","text":"","title":"Classes"},{"location":"reference/isort/pylama_isort/#linter","text":"class Linter ( / , * args , ** kwargs ) Abstract class for linter plugin. View Source class Linter ( BaseLinter ) : def allow ( self , path : str ) -> bool : \"\"\" Determine if this path should be linted. \"\"\" return path . endswith ( \" .py \" ) def run ( self , path : str , ** meta : Any ) -> List [ Dict [ str , Any ]]: \"\"\" Lint the file. Return an array of error dicts if appropriate. \"\"\" with open ( os . devnull , \" w \" ) as devnull : # Suppress isort messages sys . stdout = devnull if SortImports ( path , check = True ) . incorrectly_sorted : return [ { \" lnum \" : 0 , \" col \" : 0 , \" text \" : \" Incorrectly sorted imports. \" , \" type \" : \" ISORT \" , } ] else : return []","title":"Linter"},{"location":"reference/isort/pylama_isort/#ancestors-in-mro","text":"pylama.lint.Linter","title":"Ancestors (in MRO)"},{"location":"reference/isort/pylama_isort/#methods","text":"","title":"Methods"},{"location":"reference/isort/pylama_isort/#allow","text":"def allow ( self , path : str ) -> bool Determine if this path should be linted. View Source def allow ( self , path : str ) -> bool : \"\"\" Determine if this path should be linted. \"\"\" return path . endswith ( \" .py \" )","title":"allow"},{"location":"reference/isort/pylama_isort/#run","text":"def run ( self , path : str , ** meta : Any ) -> List [ Dict [ str , Any ]] Lint the file. Return an array of error dicts if appropriate. View Source def run ( self , path : str , ** meta : Any ) -> List [ Dict [ str , Any ]]: \"\"\" Lint the file. Return an array of error dicts if appropriate. \"\"\" with open ( os . devnull , \" w \" ) as devnull : # Suppress isort messages sys . stdout = devnull if SortImports ( path , check = True ) . incorrectly_sorted : return [ { \" lnum \" : 0 , \" col \" : 0 , \" text \" : \" Incorrectly sorted imports. \" , \" type \" : \" ISORT \" , } ] else : return []","title":"run"},{"location":"reference/isort/settings/","text":"Module isort.settings isort/settings.py. Defines how the default settings for isort should be loaded (First from the default setting dictionary at the top of the file, then overridden by any settings in ~/.isort.cfg or $XDG_CONFIG_HOME/isort.cfg if there are any) Copyright (C) 2013 Timothy Edmund Crosley Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. View Source \"\"\" isort/settings.py. Defines how the default settings for isort should be loaded ( First from the default setting dictionary at the top of the file , then overridden by any settings in ~/ . isort . cfg or $ XDG_CONFIG_HOME / isort . cfg if there are any ) Copyright ( C ) 2013 Timothy Edmund Crosley Permission is hereby granted , free of charge , to any person obtaining a copy of this software and associated documentation files ( the \" Software \" ) , to deal in the Software without restriction , including without limitation the rights to use , copy , modify , merge , publish , distribute , sublicense , and / or sell copies of the Software , and to permit persons to whom the Software is furnished to do so , subject to the following conditions : The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software . THE SOFTWARE IS PROVIDED \" AS IS \" , WITHOUT WARRANTY OF ANY KIND , EXPRESS OR IMPLIED , INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY , FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT . IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM , DAMAGES OR OTHER LIABILITY , WHETHER IN AN ACTION OF CONTRACT , TORT OR OTHERWISE , ARISING FROM , OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE . \"\"\" import configparser import enum import fnmatch import os import posixpath import re import sys import warnings from distutils . util import strtobool from functools import lru_cache from pathlib import Path from typing import ( Any , Callable , Dict , Iterable , List , Mapping , MutableMapping , Optional , Union , ) from . stdlibs import py3 , py27 from . utils import difference , union try : import toml except ImportError : toml = None # type : ignore try : import appdirs if appdirs . system == \" darwin \" : appdirs . system = \" linux2 \" except ImportError : appdirs = None MAX_CONFIG_SEARCH_DEPTH = ( 25 ) # The number of parent directories isort will look for a config file within DEFAULT_SECTIONS = ( \" FUTURE \" , \" STDLIB \" , \" THIRDPARTY \" , \" FIRSTPARTY \" , \" LOCALFOLDER \" ) safety_exclude_re = re . compile ( r \" /(\\.eggs|\\.git|\\.hg|\\.mypy_cache|\\.nox|\\.tox|\\.venv|_build|buck-out|build|dist|\\.pants\\.d \" r \" |lib/python[0-9].[0-9]+|node_modules)/ \" ) class WrapModes ( enum . Enum ) : GRID = 0 # 0 VERTICAL = 1 HANGING_INDENT = 2 VERTICAL_HANGING_INDENT = 3 VERTICAL_GRID = 4 VERTICAL_GRID_GROUPED = 5 VERTICAL_GRID_GROUPED_NO_COMMA = 6 NOQA = 7 @ staticmethod def from_string ( value : str ) -> \" WrapModes \" : return getattr ( WrapModes , str ( value ) , None ) or WrapModes ( int ( value )) def _get_default ( py_version : Optional [ str ] ) -> Dict [ str , Any ]: \"\"\" Returns the correct standard library based on either the passed py_version flag or the python interpreter Additionaly users have the option to pass all as value instead of an version . As an result code will be checked against both standard libraries - python2 & python3 See Issue 889 and 778 for more information \"\"\" if py_version is None : major , minor = sys . version_info [ 0 : 2 ] elif py_version != \" all \" : minor = 0 # we have a minor if \" . \" in py_version : # we do not care about patches just major and minor splits = py_version . split ( \" . \" ) [ 0 : 2 ] major = int ( splits [ 0 ] ) minor = int ( splits [ 1 ] ) else : major = int ( py_version ) _default = default . copy () if py_version == \" all \" : standard_library = list ( set ( py3 . stdlib + py27 . stdlib )) elif major == 3 : standard_library = py3 . stdlib elif major == 2 and minor == 7 : standard_library = py27 . stdlib else : raise ValueError ( \" The python version %s is not supported. \" \" You can set a python version with the -py or --python-version flag \" % py_version ) _default [ \" known_standard_library \" ] = standard_library return _default # Note that none of these lists must be complete as they are simply fallbacks for when included auto - detection fails . default = { \" force_to_top \" : [], \" skip \" : [], \" skip_glob \" : [], \" line_length \" : 79 , \" wrap_length \" : 0 , \" line_ending \" : None , \" sections \" : DEFAULT_SECTIONS , \" no_sections \" : False , \" known_future_library \" : [ \" __future__ \" ], \" known_third_party \" : [ \" google.appengine.api \" ], \" known_first_party \" : [], \" multi_line_output \" : WrapModes . GRID , \" forced_separate \" : [], \" indent \" : \" \" * 4 , \" comment_prefix \" : \" # \" , \" length_sort \" : False , \" add_imports \" : [], \" remove_imports \" : [], \" reverse_relative \" : False , \" force_single_line \" : False , \" default_section \" : \" FIRSTPARTY \" , \" import_heading_future \" : \"\" , \" import_heading_stdlib \" : \"\" , \" import_heading_thirdparty \" : \"\" , \" import_heading_firstparty \" : \"\" , \" import_heading_localfolder \" : \"\" , \" balanced_wrapping \" : False , \" use_parentheses \" : False , \" order_by_type \" : True , \" atomic \" : False , \" lines_after_imports \" : - 1 , \" lines_between_sections \" : 1 , \" lines_between_types \" : 0 , \" combine_as_imports \" : False , \" combine_star \" : False , \" keep_direct_and_as_imports \" : False , \" include_trailing_comma \" : False , \" from_first \" : False , \" verbose \" : False , \" quiet \" : False , \" force_adds \" : False , \" force_alphabetical_sort_within_sections \" : False , \" force_alphabetical_sort \" : False , \" force_grid_wrap \" : 0 , \" force_sort_within_sections \" : False , \" show_diff \" : False , \" ignore_whitespace \" : False , \" no_lines_before \" : [], \" no_inline_sort \" : False , \" ignore_comments \" : False , \" safety_excludes \" : True , \" case_sensitive \" : False , } @ lru_cache () def from_path ( path : Union [ str , Path ], py_version : Optional [ str ] = None ) -> Dict [ str , Any ]: computed_settings = _get_default ( py_version ) isort_defaults = [ \" ~/.isort.cfg \" ] if appdirs : isort_defaults = [ appdirs . user_config_dir ( \" isort.cfg \" ) ] + isort_defaults if isinstance ( path , Path ) : path = str ( path ) _update_settings_with_config ( path , \" .editorconfig \" , [ \" ~/.editorconfig \" ], ( \" * \" , \" *.py \" , \" **.py \" ) , computed_settings , ) _update_settings_with_config ( path , \" pyproject.toml \" , [], ( \" tool.isort \" , ) , computed_settings ) _update_settings_with_config ( path , \" .isort.cfg \" , isort_defaults , ( \" settings \" , \" isort \" ) , computed_settings ) _update_settings_with_config ( path , \" setup.cfg \" , [], ( \" isort \" , \" tool:isort \" ) , computed_settings ) _update_settings_with_config ( path , \" tox.ini \" , [], ( \" isort \" , \" tool:isort \" ) , computed_settings ) return computed_settings def prepare_config ( settings_path : Path , ** setting_overrides : Any ) -> Dict [ str , Any ]: py_version = setting_overrides . pop ( \" py_version \" , None ) config = from_path ( settings_path , py_version ) . copy () for key , value in setting_overrides . items () : access_key = key . replace ( \" not_ \" , \"\" ) . lower () # The sections config needs to retain order and can ' t be converted to a set. if access_key != \" sections \" and type ( config . get ( access_key )) in ( list , tuple ) : if key . startswith ( \" not_ \" ) : config [ access_key ] = list ( set ( config [ access_key ] ) . difference ( value )) else : config [ access_key ] = list ( set ( config [ access_key ] ) . union ( value )) else : config [ key ] = value if config [ \" force_alphabetical_sort \" ]: config . update ( { \" force_alphabetical_sort_within_sections \" : True , \" no_sections \" : True , \" lines_between_types \" : 1 , \" from_first \" : True , } ) indent = str ( config [ \" indent \" ] ) if indent . isdigit () : indent = \" \" * int ( indent ) else : indent = indent . strip ( \" ' \" ) . strip ( ' \" ' ) if indent . lower () == \" tab \" : indent = \" \\t \" config [ \" indent \" ] = indent config [ \" comment_prefix \" ] = config [ \" comment_prefix \" ]. strip ( \" ' \" ) . strip ( ' \" ' ) return config def _update_settings_with_config ( path : str , name : str , default : Iterable [ str ], sections : Iterable [ str ], computed_settings : MutableMapping [ str , Any ], ) -> None : editor_config_file = None for potential_settings_path in default : expanded = os . path . expanduser ( potential_settings_path ) if os . path . exists ( expanded ) : editor_config_file = expanded break tries = 0 current_directory = path while current_directory and tries < MAX_CONFIG_SEARCH_DEPTH : potential_path = os . path . join ( current_directory , name ) if os . path . exists ( potential_path ) : editor_config_file = potential_path break new_directory = os . path . split ( current_directory ) [ 0 ] if current_directory == new_directory : break current_directory = new_directory tries += 1 if editor_config_file and os . path . exists ( editor_config_file ) : _update_with_config_file ( editor_config_file , sections , computed_settings ) def _get_str_to_type_converter ( setting_name : str ) -> Callable [[ str ], Any ]: type_converter = type ( default . get ( setting_name , \"\" )) # type : Callable [[ str ], Any ] if type_converter == WrapModes : type_converter = WrapModes . from_string return type_converter def _update_with_config_file ( file_path : str , sections : Iterable [ str ], computed_settings : MutableMapping [ str , Any ] ) -> None : cwd = os . path . dirname ( file_path ) settings = _get_config_data ( file_path , sections ) . copy () if not settings : return if file_path . endswith ( \" .editorconfig \" ) : indent_style = settings . pop ( \" indent_style \" , \"\" ) . strip () indent_size = settings . pop ( \" indent_size \" , \"\" ) . strip () if indent_size == \" tab \" : indent_size = settings . pop ( \" tab_width \" , \"\" ) . strip () if indent_style == \" space \" : computed_settings [ \" indent \" ] = \" \" * ( indent_size and int ( indent_size ) or 4 ) elif indent_style == \" tab \" : computed_settings [ \" indent \" ] = \" \\t \" * ( indent_size and int ( indent_size ) or 1 ) max_line_length = settings . pop ( \" max_line_length \" , \"\" ) . strip () if max_line_length : computed_settings [ \" line_length \" ] = ( float ( \" inf \" ) if max_line_length == \" off \" else int ( max_line_length ) ) for key , value in settings . items () : access_key = key . replace ( \" not_ \" , \"\" ) . lower () existing_value_type = _get_str_to_type_converter ( access_key ) if existing_value_type in ( list , tuple ) : # sections has fixed order values ; no adding or substraction from any set if access_key == \" sections \" : computed_settings [ access_key ] = tuple ( _as_list ( value )) else : existing_data = set ( computed_settings . get ( access_key , default . get ( access_key )) ) if key . startswith ( \" not_ \" ) : computed_settings [ access_key ] = difference ( existing_data , _as_list ( value ) ) elif key . startswith ( \" known_ \" ) : computed_settings [ access_key ] = union ( existing_data , _abspaths ( cwd , _as_list ( value )) ) else : computed_settings [ access_key ] = union ( existing_data , _as_list ( value ) ) elif existing_value_type == bool : # Only some configuration formats support native boolean values . if not isinstance ( value , bool ) : value = bool ( strtobool ( value )) computed_settings [ access_key ] = value elif key . startswith ( \" known_ \" ) : computed_settings [ access_key ] = _abspaths ( cwd , _as_list ( value )) elif key == \" force_grid_wrap \" : try : result = existing_value_type ( value ) except ValueError : # backwards compat result = ( default . get ( access_key ) if value . lower () . strip () == \" false \" else 2 ) computed_settings [ access_key ] = result else : computed_settings [ access_key ] = getattr ( existing_value_type , str ( value ) , None ) or existing_value_type ( value ) def _as_list ( value : str ) -> List [ str ]: if isinstance ( value , list ) : return [ item . strip () for item in value ] filtered = [ item . strip () for item in value . replace ( \" \\n \" , \" , \" ) . split ( \" , \" ) if item . strip () ] return filtered def _abspaths ( cwd : str , values : Iterable [ str ] ) -> List [ str ]: paths = [ os . path . join ( cwd , value ) if not value . startswith ( os . path . sep ) and value . endswith ( os . path . sep ) else value for value in values ] return paths @ lru_cache () def _get_config_data ( file_path : str , sections : Iterable [ str ] ) -> Dict [ str , Any ]: settings = {} # type : Dict [ str , Any ] with open ( file_path ) as config_file : if file_path . endswith ( \" .toml \" ) : if toml : config = toml . load ( config_file ) for section in sections : config_section = config for key in section . split ( \" . \" ) : config_section = config_section . get ( key , {} ) settings . update ( config_section ) else : if \" [tool.isort] \" in config_file . read () : warnings . warn ( \" Found {} with [tool.isort] section, but toml package is not installed. \" \" To configure isort with {}, install with 'isort[pyproject]'. \" . format ( file_path , file_path ) ) else : if file_path . endswith ( \" .editorconfig \" ) : line = \" \\n \" last_position = config_file . tell () while line : line = config_file . readline () if \" [ \" in line : config_file . seek ( last_position ) break last_position = config_file . tell () config = configparser . ConfigParser ( strict = False ) config . read_file ( config_file ) for section in sections : if config . has_section ( section ) : settings . update ( config . items ( section )) return settings def file_should_be_skipped ( filename : str , config : Mapping [ str , Any ], path : str = \"\" ) -> bool : \"\"\" Returns True if the file and/or folder should be skipped based on the passed in settings. \"\"\" os_path = os . path . join ( path , filename ) normalized_path = os_path . replace ( \" \\\\ \" , \" / \" ) if normalized_path [ 1 : 2 ] == \" : \" : normalized_path = normalized_path [ 2 :] if path and config [ \" safety_excludes \" ]: check_exclude = \" / \" + filename . replace ( \" \\\\ \" , \" / \" ) + \" / \" if path and os . path . basename ( path ) in ( \" lib \" , ) : check_exclude = \" / \" + os . path . basename ( path ) + check_exclude if safety_exclude_re . search ( check_exclude ) : return True for skip_path in config [ \" skip \" ]: if posixpath . abspath ( normalized_path ) == posixpath . abspath ( skip_path . replace ( \" \\\\ \" , \" / \" ) ) : return True position = os . path . split ( filename ) while position [ 1 ]: if position [ 1 ] in config [ \" skip \" ]: return True position = os . path . split ( position [ 0 ] ) for glob in config [ \" skip_glob \" ]: if fnmatch . fnmatch ( filename , glob ) or fnmatch . fnmatch ( \" / \" + filename , glob ) : return True if not ( os . path . isfile ( os_path ) or os . path . isdir ( os_path ) or os . path . islink ( os_path ) ) : return True return False Variables DEFAULT_SECTIONS MAX_CONFIG_SEARCH_DEPTH default safety_exclude_re Functions file_should_be_skipped def file_should_be_skipped ( filename : str , config : Mapping [ str , Any ], path : str = '' ) -> bool Returns True if the file and/or folder should be skipped based on the passed in settings. View Source def file_should_be_skipped ( filename : str , config : Mapping [ str , Any ], path : str = \"\" ) -> bool : \"\"\" Returns True if the file and/or folder should be skipped based on the passed in settings. \"\"\" os_path = os . path . join ( path , filename ) normalized_path = os_path . replace ( \" \\\\ \" , \" / \" ) if normalized_path [ 1 : 2 ] == \" : \" : normalized_path = normalized_path [ 2 :] if path and config [ \" safety_excludes \" ]: check_exclude = \" / \" + filename . replace ( \" \\\\ \" , \" / \" ) + \" / \" if path and os . path . basename ( path ) in ( \" lib \" , ) : check_exclude = \" / \" + os . path . basename ( path ) + check_exclude if safety_exclude_re . search ( check_exclude ) : return True for skip_path in config [ \" skip \" ]: if posixpath . abspath ( normalized_path ) == posixpath . abspath ( skip_path . replace ( \" \\\\ \" , \" / \" ) ) : return True position = os . path . split ( filename ) while position [ 1 ]: if position [ 1 ] in config [ \" skip \" ]: return True position = os . path . split ( position [ 0 ] ) for glob in config [ \" skip_glob \" ]: if fnmatch . fnmatch ( filename , glob ) or fnmatch . fnmatch ( \" / \" + filename , glob ) : return True if not ( os . path . isfile ( os_path ) or os . path . isdir ( os_path ) or os . path . islink ( os_path ) ) : return True return False from_path def from_path ( path : Union [ str , pathlib . Path ], py_version : Union [ str , NoneType ] = None ) -> Dict [ str , Any ] View Source @ lru_cache () def from_path ( path : Union [ str , Path ], py_version : Optional [ str ] = None ) -> Dict [ str , Any ]: computed_settings = _get_default ( py_version ) isort_defaults = [ \" ~/.isort.cfg \" ] if appdirs : isort_defaults = [ appdirs . user_config_dir ( \" isort.cfg \" ) ] + isort_defaults if isinstance ( path , Path ) : path = str ( path ) _update_settings_with_config ( path , \" .editorconfig \" , [ \" ~/.editorconfig \" ], ( \" * \" , \" *.py \" , \" **.py \" ) , computed_settings , ) _update_settings_with_config ( path , \" pyproject.toml \" , [], ( \" tool.isort \" , ) , computed_settings ) _update_settings_with_config ( path , \" .isort.cfg \" , isort_defaults , ( \" settings \" , \" isort \" ) , computed_settings ) _update_settings_with_config ( path , \" setup.cfg \" , [], ( \" isort \" , \" tool:isort \" ) , computed_settings ) _update_settings_with_config ( path , \" tox.ini \" , [], ( \" isort \" , \" tool:isort \" ) , computed_settings ) return computed_settings prepare_config def prepare_config ( settings_path : pathlib . Path , ** setting_overrides : Any ) -> Dict [ str , Any ] View Source def prepare_config ( settings_path : Path , ** setting_overrides : Any ) -> Dict [ str , Any ]: py_version = setting_overrides . pop ( \" py_version \" , None ) config = from_path ( settings_path , py_version ) . copy () for key , value in setting_overrides . items () : access_key = key . replace ( \" not_ \" , \"\" ) . lower () # The sections config needs to retain order and can ' t be converted to a set. if access_key != \" sections \" and type ( config . get ( access_key )) in ( list , tuple ) : if key . startswith ( \" not_ \" ) : config [ access_key ] = list ( set ( config [ access_key ] ) . difference ( value )) else : config [ access_key ] = list ( set ( config [ access_key ] ) . union ( value )) else : config [ key ] = value if config [ \" force_alphabetical_sort \" ]: config . update ( { \" force_alphabetical_sort_within_sections \" : True , \" no_sections \" : True , \" lines_between_types \" : 1 , \" from_first \" : True , } ) indent = str ( config [ \" indent \" ] ) if indent . isdigit () : indent = \" \" * int ( indent ) else : indent = indent . strip ( \" ' \" ) . strip ( ' \" ' ) if indent . lower () == \" tab \" : indent = \" \\t \" config [ \" indent \" ] = indent config [ \" comment_prefix \" ] = config [ \" comment_prefix \" ]. strip ( \" ' \" ) . strip ( ' \" ' ) return config Classes WrapModes class WrapModes ( / , * args , ** kwargs ) An enumeration. View Source class WrapModes ( enum . Enum ) : GRID = 0 # 0 VERTICAL = 1 HANGING_INDENT = 2 VERTICAL_HANGING_INDENT = 3 VERTICAL_GRID = 4 VERTICAL_GRID_GROUPED = 5 VERTICAL_GRID_GROUPED_NO_COMMA = 6 NOQA = 7 @ staticmethod def from_string ( value : str ) -> \" WrapModes \" : return getattr ( WrapModes , str ( value ) , None ) or WrapModes ( int ( value )) Ancestors (in MRO) enum.Enum Class variables GRID HANGING_INDENT NOQA VERTICAL VERTICAL_GRID VERTICAL_GRID_GROUPED VERTICAL_GRID_GROUPED_NO_COMMA VERTICAL_HANGING_INDENT name value","title":"Settings"},{"location":"reference/isort/settings/#module-isortsettings","text":"isort/settings.py. Defines how the default settings for isort should be loaded (First from the default setting dictionary at the top of the file, then overridden by any settings in ~/.isort.cfg or $XDG_CONFIG_HOME/isort.cfg if there are any) Copyright (C) 2013 Timothy Edmund Crosley Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. View Source \"\"\" isort/settings.py. Defines how the default settings for isort should be loaded ( First from the default setting dictionary at the top of the file , then overridden by any settings in ~/ . isort . cfg or $ XDG_CONFIG_HOME / isort . cfg if there are any ) Copyright ( C ) 2013 Timothy Edmund Crosley Permission is hereby granted , free of charge , to any person obtaining a copy of this software and associated documentation files ( the \" Software \" ) , to deal in the Software without restriction , including without limitation the rights to use , copy , modify , merge , publish , distribute , sublicense , and / or sell copies of the Software , and to permit persons to whom the Software is furnished to do so , subject to the following conditions : The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software . THE SOFTWARE IS PROVIDED \" AS IS \" , WITHOUT WARRANTY OF ANY KIND , EXPRESS OR IMPLIED , INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY , FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT . IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM , DAMAGES OR OTHER LIABILITY , WHETHER IN AN ACTION OF CONTRACT , TORT OR OTHERWISE , ARISING FROM , OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE . \"\"\" import configparser import enum import fnmatch import os import posixpath import re import sys import warnings from distutils . util import strtobool from functools import lru_cache from pathlib import Path from typing import ( Any , Callable , Dict , Iterable , List , Mapping , MutableMapping , Optional , Union , ) from . stdlibs import py3 , py27 from . utils import difference , union try : import toml except ImportError : toml = None # type : ignore try : import appdirs if appdirs . system == \" darwin \" : appdirs . system = \" linux2 \" except ImportError : appdirs = None MAX_CONFIG_SEARCH_DEPTH = ( 25 ) # The number of parent directories isort will look for a config file within DEFAULT_SECTIONS = ( \" FUTURE \" , \" STDLIB \" , \" THIRDPARTY \" , \" FIRSTPARTY \" , \" LOCALFOLDER \" ) safety_exclude_re = re . compile ( r \" /(\\.eggs|\\.git|\\.hg|\\.mypy_cache|\\.nox|\\.tox|\\.venv|_build|buck-out|build|dist|\\.pants\\.d \" r \" |lib/python[0-9].[0-9]+|node_modules)/ \" ) class WrapModes ( enum . Enum ) : GRID = 0 # 0 VERTICAL = 1 HANGING_INDENT = 2 VERTICAL_HANGING_INDENT = 3 VERTICAL_GRID = 4 VERTICAL_GRID_GROUPED = 5 VERTICAL_GRID_GROUPED_NO_COMMA = 6 NOQA = 7 @ staticmethod def from_string ( value : str ) -> \" WrapModes \" : return getattr ( WrapModes , str ( value ) , None ) or WrapModes ( int ( value )) def _get_default ( py_version : Optional [ str ] ) -> Dict [ str , Any ]: \"\"\" Returns the correct standard library based on either the passed py_version flag or the python interpreter Additionaly users have the option to pass all as value instead of an version . As an result code will be checked against both standard libraries - python2 & python3 See Issue 889 and 778 for more information \"\"\" if py_version is None : major , minor = sys . version_info [ 0 : 2 ] elif py_version != \" all \" : minor = 0 # we have a minor if \" . \" in py_version : # we do not care about patches just major and minor splits = py_version . split ( \" . \" ) [ 0 : 2 ] major = int ( splits [ 0 ] ) minor = int ( splits [ 1 ] ) else : major = int ( py_version ) _default = default . copy () if py_version == \" all \" : standard_library = list ( set ( py3 . stdlib + py27 . stdlib )) elif major == 3 : standard_library = py3 . stdlib elif major == 2 and minor == 7 : standard_library = py27 . stdlib else : raise ValueError ( \" The python version %s is not supported. \" \" You can set a python version with the -py or --python-version flag \" % py_version ) _default [ \" known_standard_library \" ] = standard_library return _default # Note that none of these lists must be complete as they are simply fallbacks for when included auto - detection fails . default = { \" force_to_top \" : [], \" skip \" : [], \" skip_glob \" : [], \" line_length \" : 79 , \" wrap_length \" : 0 , \" line_ending \" : None , \" sections \" : DEFAULT_SECTIONS , \" no_sections \" : False , \" known_future_library \" : [ \" __future__ \" ], \" known_third_party \" : [ \" google.appengine.api \" ], \" known_first_party \" : [], \" multi_line_output \" : WrapModes . GRID , \" forced_separate \" : [], \" indent \" : \" \" * 4 , \" comment_prefix \" : \" # \" , \" length_sort \" : False , \" add_imports \" : [], \" remove_imports \" : [], \" reverse_relative \" : False , \" force_single_line \" : False , \" default_section \" : \" FIRSTPARTY \" , \" import_heading_future \" : \"\" , \" import_heading_stdlib \" : \"\" , \" import_heading_thirdparty \" : \"\" , \" import_heading_firstparty \" : \"\" , \" import_heading_localfolder \" : \"\" , \" balanced_wrapping \" : False , \" use_parentheses \" : False , \" order_by_type \" : True , \" atomic \" : False , \" lines_after_imports \" : - 1 , \" lines_between_sections \" : 1 , \" lines_between_types \" : 0 , \" combine_as_imports \" : False , \" combine_star \" : False , \" keep_direct_and_as_imports \" : False , \" include_trailing_comma \" : False , \" from_first \" : False , \" verbose \" : False , \" quiet \" : False , \" force_adds \" : False , \" force_alphabetical_sort_within_sections \" : False , \" force_alphabetical_sort \" : False , \" force_grid_wrap \" : 0 , \" force_sort_within_sections \" : False , \" show_diff \" : False , \" ignore_whitespace \" : False , \" no_lines_before \" : [], \" no_inline_sort \" : False , \" ignore_comments \" : False , \" safety_excludes \" : True , \" case_sensitive \" : False , } @ lru_cache () def from_path ( path : Union [ str , Path ], py_version : Optional [ str ] = None ) -> Dict [ str , Any ]: computed_settings = _get_default ( py_version ) isort_defaults = [ \" ~/.isort.cfg \" ] if appdirs : isort_defaults = [ appdirs . user_config_dir ( \" isort.cfg \" ) ] + isort_defaults if isinstance ( path , Path ) : path = str ( path ) _update_settings_with_config ( path , \" .editorconfig \" , [ \" ~/.editorconfig \" ], ( \" * \" , \" *.py \" , \" **.py \" ) , computed_settings , ) _update_settings_with_config ( path , \" pyproject.toml \" , [], ( \" tool.isort \" , ) , computed_settings ) _update_settings_with_config ( path , \" .isort.cfg \" , isort_defaults , ( \" settings \" , \" isort \" ) , computed_settings ) _update_settings_with_config ( path , \" setup.cfg \" , [], ( \" isort \" , \" tool:isort \" ) , computed_settings ) _update_settings_with_config ( path , \" tox.ini \" , [], ( \" isort \" , \" tool:isort \" ) , computed_settings ) return computed_settings def prepare_config ( settings_path : Path , ** setting_overrides : Any ) -> Dict [ str , Any ]: py_version = setting_overrides . pop ( \" py_version \" , None ) config = from_path ( settings_path , py_version ) . copy () for key , value in setting_overrides . items () : access_key = key . replace ( \" not_ \" , \"\" ) . lower () # The sections config needs to retain order and can ' t be converted to a set. if access_key != \" sections \" and type ( config . get ( access_key )) in ( list , tuple ) : if key . startswith ( \" not_ \" ) : config [ access_key ] = list ( set ( config [ access_key ] ) . difference ( value )) else : config [ access_key ] = list ( set ( config [ access_key ] ) . union ( value )) else : config [ key ] = value if config [ \" force_alphabetical_sort \" ]: config . update ( { \" force_alphabetical_sort_within_sections \" : True , \" no_sections \" : True , \" lines_between_types \" : 1 , \" from_first \" : True , } ) indent = str ( config [ \" indent \" ] ) if indent . isdigit () : indent = \" \" * int ( indent ) else : indent = indent . strip ( \" ' \" ) . strip ( ' \" ' ) if indent . lower () == \" tab \" : indent = \" \\t \" config [ \" indent \" ] = indent config [ \" comment_prefix \" ] = config [ \" comment_prefix \" ]. strip ( \" ' \" ) . strip ( ' \" ' ) return config def _update_settings_with_config ( path : str , name : str , default : Iterable [ str ], sections : Iterable [ str ], computed_settings : MutableMapping [ str , Any ], ) -> None : editor_config_file = None for potential_settings_path in default : expanded = os . path . expanduser ( potential_settings_path ) if os . path . exists ( expanded ) : editor_config_file = expanded break tries = 0 current_directory = path while current_directory and tries < MAX_CONFIG_SEARCH_DEPTH : potential_path = os . path . join ( current_directory , name ) if os . path . exists ( potential_path ) : editor_config_file = potential_path break new_directory = os . path . split ( current_directory ) [ 0 ] if current_directory == new_directory : break current_directory = new_directory tries += 1 if editor_config_file and os . path . exists ( editor_config_file ) : _update_with_config_file ( editor_config_file , sections , computed_settings ) def _get_str_to_type_converter ( setting_name : str ) -> Callable [[ str ], Any ]: type_converter = type ( default . get ( setting_name , \"\" )) # type : Callable [[ str ], Any ] if type_converter == WrapModes : type_converter = WrapModes . from_string return type_converter def _update_with_config_file ( file_path : str , sections : Iterable [ str ], computed_settings : MutableMapping [ str , Any ] ) -> None : cwd = os . path . dirname ( file_path ) settings = _get_config_data ( file_path , sections ) . copy () if not settings : return if file_path . endswith ( \" .editorconfig \" ) : indent_style = settings . pop ( \" indent_style \" , \"\" ) . strip () indent_size = settings . pop ( \" indent_size \" , \"\" ) . strip () if indent_size == \" tab \" : indent_size = settings . pop ( \" tab_width \" , \"\" ) . strip () if indent_style == \" space \" : computed_settings [ \" indent \" ] = \" \" * ( indent_size and int ( indent_size ) or 4 ) elif indent_style == \" tab \" : computed_settings [ \" indent \" ] = \" \\t \" * ( indent_size and int ( indent_size ) or 1 ) max_line_length = settings . pop ( \" max_line_length \" , \"\" ) . strip () if max_line_length : computed_settings [ \" line_length \" ] = ( float ( \" inf \" ) if max_line_length == \" off \" else int ( max_line_length ) ) for key , value in settings . items () : access_key = key . replace ( \" not_ \" , \"\" ) . lower () existing_value_type = _get_str_to_type_converter ( access_key ) if existing_value_type in ( list , tuple ) : # sections has fixed order values ; no adding or substraction from any set if access_key == \" sections \" : computed_settings [ access_key ] = tuple ( _as_list ( value )) else : existing_data = set ( computed_settings . get ( access_key , default . get ( access_key )) ) if key . startswith ( \" not_ \" ) : computed_settings [ access_key ] = difference ( existing_data , _as_list ( value ) ) elif key . startswith ( \" known_ \" ) : computed_settings [ access_key ] = union ( existing_data , _abspaths ( cwd , _as_list ( value )) ) else : computed_settings [ access_key ] = union ( existing_data , _as_list ( value ) ) elif existing_value_type == bool : # Only some configuration formats support native boolean values . if not isinstance ( value , bool ) : value = bool ( strtobool ( value )) computed_settings [ access_key ] = value elif key . startswith ( \" known_ \" ) : computed_settings [ access_key ] = _abspaths ( cwd , _as_list ( value )) elif key == \" force_grid_wrap \" : try : result = existing_value_type ( value ) except ValueError : # backwards compat result = ( default . get ( access_key ) if value . lower () . strip () == \" false \" else 2 ) computed_settings [ access_key ] = result else : computed_settings [ access_key ] = getattr ( existing_value_type , str ( value ) , None ) or existing_value_type ( value ) def _as_list ( value : str ) -> List [ str ]: if isinstance ( value , list ) : return [ item . strip () for item in value ] filtered = [ item . strip () for item in value . replace ( \" \\n \" , \" , \" ) . split ( \" , \" ) if item . strip () ] return filtered def _abspaths ( cwd : str , values : Iterable [ str ] ) -> List [ str ]: paths = [ os . path . join ( cwd , value ) if not value . startswith ( os . path . sep ) and value . endswith ( os . path . sep ) else value for value in values ] return paths @ lru_cache () def _get_config_data ( file_path : str , sections : Iterable [ str ] ) -> Dict [ str , Any ]: settings = {} # type : Dict [ str , Any ] with open ( file_path ) as config_file : if file_path . endswith ( \" .toml \" ) : if toml : config = toml . load ( config_file ) for section in sections : config_section = config for key in section . split ( \" . \" ) : config_section = config_section . get ( key , {} ) settings . update ( config_section ) else : if \" [tool.isort] \" in config_file . read () : warnings . warn ( \" Found {} with [tool.isort] section, but toml package is not installed. \" \" To configure isort with {}, install with 'isort[pyproject]'. \" . format ( file_path , file_path ) ) else : if file_path . endswith ( \" .editorconfig \" ) : line = \" \\n \" last_position = config_file . tell () while line : line = config_file . readline () if \" [ \" in line : config_file . seek ( last_position ) break last_position = config_file . tell () config = configparser . ConfigParser ( strict = False ) config . read_file ( config_file ) for section in sections : if config . has_section ( section ) : settings . update ( config . items ( section )) return settings def file_should_be_skipped ( filename : str , config : Mapping [ str , Any ], path : str = \"\" ) -> bool : \"\"\" Returns True if the file and/or folder should be skipped based on the passed in settings. \"\"\" os_path = os . path . join ( path , filename ) normalized_path = os_path . replace ( \" \\\\ \" , \" / \" ) if normalized_path [ 1 : 2 ] == \" : \" : normalized_path = normalized_path [ 2 :] if path and config [ \" safety_excludes \" ]: check_exclude = \" / \" + filename . replace ( \" \\\\ \" , \" / \" ) + \" / \" if path and os . path . basename ( path ) in ( \" lib \" , ) : check_exclude = \" / \" + os . path . basename ( path ) + check_exclude if safety_exclude_re . search ( check_exclude ) : return True for skip_path in config [ \" skip \" ]: if posixpath . abspath ( normalized_path ) == posixpath . abspath ( skip_path . replace ( \" \\\\ \" , \" / \" ) ) : return True position = os . path . split ( filename ) while position [ 1 ]: if position [ 1 ] in config [ \" skip \" ]: return True position = os . path . split ( position [ 0 ] ) for glob in config [ \" skip_glob \" ]: if fnmatch . fnmatch ( filename , glob ) or fnmatch . fnmatch ( \" / \" + filename , glob ) : return True if not ( os . path . isfile ( os_path ) or os . path . isdir ( os_path ) or os . path . islink ( os_path ) ) : return True return False","title":"Module isort.settings"},{"location":"reference/isort/settings/#variables","text":"DEFAULT_SECTIONS MAX_CONFIG_SEARCH_DEPTH default safety_exclude_re","title":"Variables"},{"location":"reference/isort/settings/#functions","text":"","title":"Functions"},{"location":"reference/isort/settings/#file_should_be_skipped","text":"def file_should_be_skipped ( filename : str , config : Mapping [ str , Any ], path : str = '' ) -> bool Returns True if the file and/or folder should be skipped based on the passed in settings. View Source def file_should_be_skipped ( filename : str , config : Mapping [ str , Any ], path : str = \"\" ) -> bool : \"\"\" Returns True if the file and/or folder should be skipped based on the passed in settings. \"\"\" os_path = os . path . join ( path , filename ) normalized_path = os_path . replace ( \" \\\\ \" , \" / \" ) if normalized_path [ 1 : 2 ] == \" : \" : normalized_path = normalized_path [ 2 :] if path and config [ \" safety_excludes \" ]: check_exclude = \" / \" + filename . replace ( \" \\\\ \" , \" / \" ) + \" / \" if path and os . path . basename ( path ) in ( \" lib \" , ) : check_exclude = \" / \" + os . path . basename ( path ) + check_exclude if safety_exclude_re . search ( check_exclude ) : return True for skip_path in config [ \" skip \" ]: if posixpath . abspath ( normalized_path ) == posixpath . abspath ( skip_path . replace ( \" \\\\ \" , \" / \" ) ) : return True position = os . path . split ( filename ) while position [ 1 ]: if position [ 1 ] in config [ \" skip \" ]: return True position = os . path . split ( position [ 0 ] ) for glob in config [ \" skip_glob \" ]: if fnmatch . fnmatch ( filename , glob ) or fnmatch . fnmatch ( \" / \" + filename , glob ) : return True if not ( os . path . isfile ( os_path ) or os . path . isdir ( os_path ) or os . path . islink ( os_path ) ) : return True return False","title":"file_should_be_skipped"},{"location":"reference/isort/settings/#from_path","text":"def from_path ( path : Union [ str , pathlib . Path ], py_version : Union [ str , NoneType ] = None ) -> Dict [ str , Any ] View Source @ lru_cache () def from_path ( path : Union [ str , Path ], py_version : Optional [ str ] = None ) -> Dict [ str , Any ]: computed_settings = _get_default ( py_version ) isort_defaults = [ \" ~/.isort.cfg \" ] if appdirs : isort_defaults = [ appdirs . user_config_dir ( \" isort.cfg \" ) ] + isort_defaults if isinstance ( path , Path ) : path = str ( path ) _update_settings_with_config ( path , \" .editorconfig \" , [ \" ~/.editorconfig \" ], ( \" * \" , \" *.py \" , \" **.py \" ) , computed_settings , ) _update_settings_with_config ( path , \" pyproject.toml \" , [], ( \" tool.isort \" , ) , computed_settings ) _update_settings_with_config ( path , \" .isort.cfg \" , isort_defaults , ( \" settings \" , \" isort \" ) , computed_settings ) _update_settings_with_config ( path , \" setup.cfg \" , [], ( \" isort \" , \" tool:isort \" ) , computed_settings ) _update_settings_with_config ( path , \" tox.ini \" , [], ( \" isort \" , \" tool:isort \" ) , computed_settings ) return computed_settings","title":"from_path"},{"location":"reference/isort/settings/#prepare_config","text":"def prepare_config ( settings_path : pathlib . Path , ** setting_overrides : Any ) -> Dict [ str , Any ] View Source def prepare_config ( settings_path : Path , ** setting_overrides : Any ) -> Dict [ str , Any ]: py_version = setting_overrides . pop ( \" py_version \" , None ) config = from_path ( settings_path , py_version ) . copy () for key , value in setting_overrides . items () : access_key = key . replace ( \" not_ \" , \"\" ) . lower () # The sections config needs to retain order and can ' t be converted to a set. if access_key != \" sections \" and type ( config . get ( access_key )) in ( list , tuple ) : if key . startswith ( \" not_ \" ) : config [ access_key ] = list ( set ( config [ access_key ] ) . difference ( value )) else : config [ access_key ] = list ( set ( config [ access_key ] ) . union ( value )) else : config [ key ] = value if config [ \" force_alphabetical_sort \" ]: config . update ( { \" force_alphabetical_sort_within_sections \" : True , \" no_sections \" : True , \" lines_between_types \" : 1 , \" from_first \" : True , } ) indent = str ( config [ \" indent \" ] ) if indent . isdigit () : indent = \" \" * int ( indent ) else : indent = indent . strip ( \" ' \" ) . strip ( ' \" ' ) if indent . lower () == \" tab \" : indent = \" \\t \" config [ \" indent \" ] = indent config [ \" comment_prefix \" ] = config [ \" comment_prefix \" ]. strip ( \" ' \" ) . strip ( ' \" ' ) return config","title":"prepare_config"},{"location":"reference/isort/settings/#classes","text":"","title":"Classes"},{"location":"reference/isort/settings/#wrapmodes","text":"class WrapModes ( / , * args , ** kwargs ) An enumeration. View Source class WrapModes ( enum . Enum ) : GRID = 0 # 0 VERTICAL = 1 HANGING_INDENT = 2 VERTICAL_HANGING_INDENT = 3 VERTICAL_GRID = 4 VERTICAL_GRID_GROUPED = 5 VERTICAL_GRID_GROUPED_NO_COMMA = 6 NOQA = 7 @ staticmethod def from_string ( value : str ) -> \" WrapModes \" : return getattr ( WrapModes , str ( value ) , None ) or WrapModes ( int ( value ))","title":"WrapModes"},{"location":"reference/isort/settings/#ancestors-in-mro","text":"enum.Enum","title":"Ancestors (in MRO)"},{"location":"reference/isort/settings/#class-variables","text":"GRID HANGING_INDENT NOQA VERTICAL VERTICAL_GRID VERTICAL_GRID_GROUPED VERTICAL_GRID_GROUPED_NO_COMMA VERTICAL_HANGING_INDENT name value","title":"Class variables"},{"location":"reference/isort/utils/","text":"Module isort.utils View Source import os import sys from contextlib import contextmanager from typing import Any , Container , Iterable , Iterator , List def exists_case_sensitive ( path : str ) -> bool : \"\"\" Returns if the given path exists and also matches the case on Windows. When finding files that can be imported, it is important for the cases to match because while file os.path.exists(\"module.py\") and os.path.exists(\"MODULE.py\") both return True on Windows, Python can only import using the case of the real file. \"\"\" result = os . path . exists ( path ) if ( sys . platform . startswith ( \"win\" ) or sys . platform == \"darwin\" ) and result : directory , basename = os . path . split ( path ) result = basename in os . listdir ( directory ) return result @contextmanager def chdir ( path : str ) -> Iterator [ None ]: \"\"\"Context manager for changing dir and restoring previous workdir after exit. \"\"\" curdir = os . getcwd () os . chdir ( path ) try : yield finally : os . chdir ( curdir ) def union ( a : Iterable [ Any ], b : Iterable [ Any ]) -> List [ Any ]: \"\"\" Return a list of items that are in `a` or `b` \"\"\" u = [] # type: List[Any] for item in a : if item not in u : u . append ( item ) for item in b : if item not in u : u . append ( item ) return u def difference ( a : Iterable [ Any ], b : Container [ Any ]) -> List [ Any ]: \"\"\" Return a list of items from `a` that are not in `b`. \"\"\" d = [] for item in a : if item not in b : d . append ( item ) return d def infer_line_separator ( file_contents : str ) -> str : if \" \\r\\n \" in file_contents : return \" \\r\\n \" elif \" \\r \" in file_contents : return \" \\r \" else : return \" \\n \" Functions chdir def chdir ( path : str ) -> Iterator [ NoneType ] Context manager for changing dir and restoring previous workdir after exit. View Source @ contextmanager def chdir ( path : str ) -> Iterator [ None ]: \"\"\" Context manager for changing dir and restoring previous workdir after exit. \"\"\" curdir = os . getcwd () os . chdir ( path ) try : yield finally : os . chdir ( curdir ) difference def difference ( a : Iterable [ Any ], b : Container [ Any ] ) -> List [ Any ] Return a list of items from a that are not in b . View Source def difference ( a : Iterable [ Any ], b : Container [ Any ] ) -> List [ Any ]: \"\"\" Return a list of items from `a` that are not in `b`. \"\"\" d = [] for item in a : if item not in b : d . append ( item ) return d exists_case_sensitive def exists_case_sensitive ( path : str ) -> bool Returns if the given path exists and also matches the case on Windows. When finding files that can be imported, it is important for the cases to match because while file os.path.exists(\"module.py\") and os.path.exists(\"MODULE.py\") both return True on Windows, Python can only import using the case of the real file. View Source def exists_case_sensitive ( path : str ) -> bool : \"\"\" Returns if the given path exists and also matches the case on Windows. When finding files that can be imported, it is important for the cases to match because while file os.path.exists(\"module.py\") and os.path.exists(\"MODULE.py\") both return True on Windows, Python can only import using the case of the real file. \"\"\" result = os . path . exists ( path ) if ( sys . platform . startswith ( \"win\" ) or sys . platform == \"darwin\" ) and result : directory , basename = os . path . split ( path ) result = basename in os . listdir ( directory ) return result infer_line_separator def infer_line_separator ( file_contents : str ) -> str View Source def infer_line_separator ( file_contents : str ) -> str : if \" \\r \\n \" in file_contents : return \" \\r \\n \" elif \" \\r \" in file_contents : return \" \\r \" else : return \" \\n \" union def union ( a : Iterable [ Any ], b : Iterable [ Any ] ) -> List [ Any ] Return a list of items that are in a or b View Source def union ( a : Iterable [ Any ], b : Iterable [ Any ] ) -> List [ Any ]: \"\"\" Return a list of items that are in `a` or `b` \"\"\" u = [] # type : List [ Any ] for item in a : if item not in u : u . append ( item ) for item in b : if item not in u : u . append ( item ) return u","title":"Utils"},{"location":"reference/isort/utils/#module-isortutils","text":"View Source import os import sys from contextlib import contextmanager from typing import Any , Container , Iterable , Iterator , List def exists_case_sensitive ( path : str ) -> bool : \"\"\" Returns if the given path exists and also matches the case on Windows. When finding files that can be imported, it is important for the cases to match because while file os.path.exists(\"module.py\") and os.path.exists(\"MODULE.py\") both return True on Windows, Python can only import using the case of the real file. \"\"\" result = os . path . exists ( path ) if ( sys . platform . startswith ( \"win\" ) or sys . platform == \"darwin\" ) and result : directory , basename = os . path . split ( path ) result = basename in os . listdir ( directory ) return result @contextmanager def chdir ( path : str ) -> Iterator [ None ]: \"\"\"Context manager for changing dir and restoring previous workdir after exit. \"\"\" curdir = os . getcwd () os . chdir ( path ) try : yield finally : os . chdir ( curdir ) def union ( a : Iterable [ Any ], b : Iterable [ Any ]) -> List [ Any ]: \"\"\" Return a list of items that are in `a` or `b` \"\"\" u = [] # type: List[Any] for item in a : if item not in u : u . append ( item ) for item in b : if item not in u : u . append ( item ) return u def difference ( a : Iterable [ Any ], b : Container [ Any ]) -> List [ Any ]: \"\"\" Return a list of items from `a` that are not in `b`. \"\"\" d = [] for item in a : if item not in b : d . append ( item ) return d def infer_line_separator ( file_contents : str ) -> str : if \" \\r\\n \" in file_contents : return \" \\r\\n \" elif \" \\r \" in file_contents : return \" \\r \" else : return \" \\n \"","title":"Module isort.utils"},{"location":"reference/isort/utils/#functions","text":"","title":"Functions"},{"location":"reference/isort/utils/#chdir","text":"def chdir ( path : str ) -> Iterator [ NoneType ] Context manager for changing dir and restoring previous workdir after exit. View Source @ contextmanager def chdir ( path : str ) -> Iterator [ None ]: \"\"\" Context manager for changing dir and restoring previous workdir after exit. \"\"\" curdir = os . getcwd () os . chdir ( path ) try : yield finally : os . chdir ( curdir )","title":"chdir"},{"location":"reference/isort/utils/#difference","text":"def difference ( a : Iterable [ Any ], b : Container [ Any ] ) -> List [ Any ] Return a list of items from a that are not in b . View Source def difference ( a : Iterable [ Any ], b : Container [ Any ] ) -> List [ Any ]: \"\"\" Return a list of items from `a` that are not in `b`. \"\"\" d = [] for item in a : if item not in b : d . append ( item ) return d","title":"difference"},{"location":"reference/isort/utils/#exists_case_sensitive","text":"def exists_case_sensitive ( path : str ) -> bool Returns if the given path exists and also matches the case on Windows. When finding files that can be imported, it is important for the cases to match because while file os.path.exists(\"module.py\") and os.path.exists(\"MODULE.py\") both return True on Windows, Python can only import using the case of the real file. View Source def exists_case_sensitive ( path : str ) -> bool : \"\"\" Returns if the given path exists and also matches the case on Windows. When finding files that can be imported, it is important for the cases to match because while file os.path.exists(\"module.py\") and os.path.exists(\"MODULE.py\") both return True on Windows, Python can only import using the case of the real file. \"\"\" result = os . path . exists ( path ) if ( sys . platform . startswith ( \"win\" ) or sys . platform == \"darwin\" ) and result : directory , basename = os . path . split ( path ) result = basename in os . listdir ( directory ) return result","title":"exists_case_sensitive"},{"location":"reference/isort/utils/#infer_line_separator","text":"def infer_line_separator ( file_contents : str ) -> str View Source def infer_line_separator ( file_contents : str ) -> str : if \" \\r \\n \" in file_contents : return \" \\r \\n \" elif \" \\r \" in file_contents : return \" \\r \" else : return \" \\n \"","title":"infer_line_separator"},{"location":"reference/isort/utils/#union","text":"def union ( a : Iterable [ Any ], b : Iterable [ Any ] ) -> List [ Any ] Return a list of items that are in a or b View Source def union ( a : Iterable [ Any ], b : Iterable [ Any ] ) -> List [ Any ]: \"\"\" Return a list of items that are in `a` or `b` \"\"\" u = [] # type : List [ Any ] for item in a : if item not in u : u . append ( item ) for item in b : if item not in u : u . append ( item ) return u","title":"union"},{"location":"reference/isort/stdlibs/","text":"Module isort.stdlibs Sub-modules isort.stdlibs.py27 isort.stdlibs.py3","title":"Index"},{"location":"reference/isort/stdlibs/#module-isortstdlibs","text":"","title":"Module isort.stdlibs"},{"location":"reference/isort/stdlibs/#sub-modules","text":"isort.stdlibs.py27 isort.stdlibs.py3","title":"Sub-modules"},{"location":"reference/isort/stdlibs/py27/","text":"Module isort.stdlibs.py27 File contains the standard library of Python 2.7. DO NOT EDIT. If the standard library changes, a new list should be created using the mkstdlibs.py script. View Source \"\"\" File contains the standard library of Python 2 . 7 . DO NOT EDIT . If the standard library changes , a new list should be created using the mkstdlibs . py script . \"\"\" stdlib = [ \" AL \" , \" BaseHTTPServer \" , \" Bastion \" , \" CGIHTTPServer \" , \" Carbon \" , \" ColorPicker \" , \" ConfigParser \" , \" Cookie \" , \" DEVICE \" , \" DocXMLRPCServer \" , \" EasyDialogs \" , \" FL \" , \" FrameWork \" , \" GL \" , \" HTMLParser \" , \" MacOS \" , \" MimeWriter \" , \" MiniAEFrame \" , \" Nav \" , \" PixMapWrapper \" , \" Queue \" , \" SUNAUDIODEV \" , \" ScrolledText \" , \" SimpleHTTPServer \" , \" SimpleXMLRPCServer \" , \" SocketServer \" , \" StringIO \" , \" Tix \" , \" Tkinter \" , \" UserDict \" , \" UserList \" , \" UserString \" , \" W \" , \" __builtin__ \" , \" _winreg \" , \" abc \" , \" aepack \" , \" aetools \" , \" aetypes \" , \" aifc \" , \" al \" , \" anydbm \" , \" applesingle \" , \" argparse \" , \" array \" , \" ast \" , \" asynchat \" , \" asyncore \" , \" atexit \" , \" audioop \" , \" autoGIL \" , \" base64 \" , \" bdb \" , \" binascii \" , \" binhex \" , \" bisect \" , \" bsddb \" , \" buildtools \" , \" bz2 \" , \" cPickle \" , \" cProfile \" , \" cStringIO \" , \" calendar \" , \" cd \" , \" cfmfile \" , \" cgi \" , \" cgitb \" , \" chunk \" , \" cmath \" , \" cmd \" , \" code \" , \" codecs \" , \" codeop \" , \" collections \" , \" colorsys \" , \" commands \" , \" compileall \" , \" compiler \" , \" contextlib \" , \" cookielib \" , \" copy \" , \" copy_reg \" , \" crypt \" , \" csv \" , \" ctypes \" , \" curses \" , \" datetime \" , \" dbhash \" , \" dbm \" , \" decimal \" , \" difflib \" , \" dircache \" , \" dis \" , \" distutils \" , \" dl \" , \" doctest \" , \" dumbdbm \" , \" dummy_thread \" , \" dummy_threading \" , \" email \" , \" encodings \" , \" ensurepip \" , \" errno \" , \" exceptions \" , \" fcntl \" , \" filecmp \" , \" fileinput \" , \" findertools \" , \" fl \" , \" flp \" , \" fm \" , \" fnmatch \" , \" formatter \" , \" fpectl \" , \" fpformat \" , \" fractions \" , \" ftplib \" , \" functools \" , \" future_builtins \" , \" gc \" , \" gdbm \" , \" gensuitemodule \" , \" getopt \" , \" getpass \" , \" gettext \" , \" gl \" , \" glob \" , \" grp \" , \" gzip \" , \" hashlib \" , \" heapq \" , \" hmac \" , \" hotshot \" , \" htmlentitydefs \" , \" htmllib \" , \" httplib \" , \" ic \" , \" icopen \" , \" imageop \" , \" imaplib \" , \" imgfile \" , \" imghdr \" , \" imp \" , \" importlib \" , \" imputil \" , \" inspect \" , \" io \" , \" itertools \" , \" jpeg \" , \" json \" , \" keyword \" , \" lib2to3 \" , \" linecache \" , \" locale \" , \" logging \" , \" macerrors \" , \" macostools \" , \" macpath \" , \" macresource \" , \" mailbox \" , \" mailcap \" , \" marshal \" , \" math \" , \" md5 \" , \" mhlib \" , \" mimetools \" , \" mimetypes \" , \" mimify \" , \" mmap \" , \" modulefinder \" , \" msilib \" , \" msvcrt \" , \" multifile \" , \" multiprocessing \" , \" mutex \" , \" netrc \" , \" new \" , \" nis \" , \" nntplib \" , \" numbers \" , \" operator \" , \" optparse \" , \" os \" , \" ossaudiodev \" , \" parser \" , \" pdb \" , \" pickle \" , \" pickletools \" , \" pipes \" , \" pkgutil \" , \" platform \" , \" plistlib \" , \" popen2 \" , \" poplib \" , \" posix \" , \" posixfile \" , \" pprint \" , \" profile \" , \" pstats \" , \" pty \" , \" pwd \" , \" py_compile \" , \" pyclbr \" , \" pydoc \" , \" quopri \" , \" random \" , \" re \" , \" readline \" , \" resource \" , \" rexec \" , \" rfc822 \" , \" rlcompleter \" , \" robotparser \" , \" runpy \" , \" sched \" , \" select \" , \" sets \" , \" sgmllib \" , \" sha \" , \" shelve \" , \" shlex \" , \" shutil \" , \" signal \" , \" site \" , \" smtpd \" , \" smtplib \" , \" sndhdr \" , \" socket \" , \" spwd \" , \" sqlite3 \" , \" ssl \" , \" stat \" , \" statvfs \" , \" string \" , \" stringprep \" , \" struct \" , \" subprocess \" , \" sunau \" , \" sunaudiodev \" , \" symbol \" , \" symtable \" , \" sys \" , \" sysconfig \" , \" syslog \" , \" tabnanny \" , \" tarfile \" , \" telnetlib \" , \" tempfile \" , \" termios \" , \" test \" , \" textwrap \" , \" thread \" , \" threading \" , \" time \" , \" timeit \" , \" token \" , \" tokenize \" , \" trace \" , \" traceback \" , \" ttk \" , \" tty \" , \" turtle \" , \" types \" , \" unicodedata \" , \" unittest \" , \" urllib \" , \" urllib2 \" , \" urlparse \" , \" user \" , \" uu \" , \" uuid \" , \" videoreader \" , \" warnings \" , \" wave \" , \" weakref \" , \" webbrowser \" , \" whichdb \" , \" winsound \" , \" wsgiref \" , \" xdrlib \" , \" xml \" , \" xmlrpclib \" , \" zipfile \" , \" zipimport \" , \" zlib \" , ] Variables stdlib","title":"Py27"},{"location":"reference/isort/stdlibs/py27/#module-isortstdlibspy27","text":"File contains the standard library of Python 2.7. DO NOT EDIT. If the standard library changes, a new list should be created using the mkstdlibs.py script. View Source \"\"\" File contains the standard library of Python 2 . 7 . DO NOT EDIT . If the standard library changes , a new list should be created using the mkstdlibs . py script . \"\"\" stdlib = [ \" AL \" , \" BaseHTTPServer \" , \" Bastion \" , \" CGIHTTPServer \" , \" Carbon \" , \" ColorPicker \" , \" ConfigParser \" , \" Cookie \" , \" DEVICE \" , \" DocXMLRPCServer \" , \" EasyDialogs \" , \" FL \" , \" FrameWork \" , \" GL \" , \" HTMLParser \" , \" MacOS \" , \" MimeWriter \" , \" MiniAEFrame \" , \" Nav \" , \" PixMapWrapper \" , \" Queue \" , \" SUNAUDIODEV \" , \" ScrolledText \" , \" SimpleHTTPServer \" , \" SimpleXMLRPCServer \" , \" SocketServer \" , \" StringIO \" , \" Tix \" , \" Tkinter \" , \" UserDict \" , \" UserList \" , \" UserString \" , \" W \" , \" __builtin__ \" , \" _winreg \" , \" abc \" , \" aepack \" , \" aetools \" , \" aetypes \" , \" aifc \" , \" al \" , \" anydbm \" , \" applesingle \" , \" argparse \" , \" array \" , \" ast \" , \" asynchat \" , \" asyncore \" , \" atexit \" , \" audioop \" , \" autoGIL \" , \" base64 \" , \" bdb \" , \" binascii \" , \" binhex \" , \" bisect \" , \" bsddb \" , \" buildtools \" , \" bz2 \" , \" cPickle \" , \" cProfile \" , \" cStringIO \" , \" calendar \" , \" cd \" , \" cfmfile \" , \" cgi \" , \" cgitb \" , \" chunk \" , \" cmath \" , \" cmd \" , \" code \" , \" codecs \" , \" codeop \" , \" collections \" , \" colorsys \" , \" commands \" , \" compileall \" , \" compiler \" , \" contextlib \" , \" cookielib \" , \" copy \" , \" copy_reg \" , \" crypt \" , \" csv \" , \" ctypes \" , \" curses \" , \" datetime \" , \" dbhash \" , \" dbm \" , \" decimal \" , \" difflib \" , \" dircache \" , \" dis \" , \" distutils \" , \" dl \" , \" doctest \" , \" dumbdbm \" , \" dummy_thread \" , \" dummy_threading \" , \" email \" , \" encodings \" , \" ensurepip \" , \" errno \" , \" exceptions \" , \" fcntl \" , \" filecmp \" , \" fileinput \" , \" findertools \" , \" fl \" , \" flp \" , \" fm \" , \" fnmatch \" , \" formatter \" , \" fpectl \" , \" fpformat \" , \" fractions \" , \" ftplib \" , \" functools \" , \" future_builtins \" , \" gc \" , \" gdbm \" , \" gensuitemodule \" , \" getopt \" , \" getpass \" , \" gettext \" , \" gl \" , \" glob \" , \" grp \" , \" gzip \" , \" hashlib \" , \" heapq \" , \" hmac \" , \" hotshot \" , \" htmlentitydefs \" , \" htmllib \" , \" httplib \" , \" ic \" , \" icopen \" , \" imageop \" , \" imaplib \" , \" imgfile \" , \" imghdr \" , \" imp \" , \" importlib \" , \" imputil \" , \" inspect \" , \" io \" , \" itertools \" , \" jpeg \" , \" json \" , \" keyword \" , \" lib2to3 \" , \" linecache \" , \" locale \" , \" logging \" , \" macerrors \" , \" macostools \" , \" macpath \" , \" macresource \" , \" mailbox \" , \" mailcap \" , \" marshal \" , \" math \" , \" md5 \" , \" mhlib \" , \" mimetools \" , \" mimetypes \" , \" mimify \" , \" mmap \" , \" modulefinder \" , \" msilib \" , \" msvcrt \" , \" multifile \" , \" multiprocessing \" , \" mutex \" , \" netrc \" , \" new \" , \" nis \" , \" nntplib \" , \" numbers \" , \" operator \" , \" optparse \" , \" os \" , \" ossaudiodev \" , \" parser \" , \" pdb \" , \" pickle \" , \" pickletools \" , \" pipes \" , \" pkgutil \" , \" platform \" , \" plistlib \" , \" popen2 \" , \" poplib \" , \" posix \" , \" posixfile \" , \" pprint \" , \" profile \" , \" pstats \" , \" pty \" , \" pwd \" , \" py_compile \" , \" pyclbr \" , \" pydoc \" , \" quopri \" , \" random \" , \" re \" , \" readline \" , \" resource \" , \" rexec \" , \" rfc822 \" , \" rlcompleter \" , \" robotparser \" , \" runpy \" , \" sched \" , \" select \" , \" sets \" , \" sgmllib \" , \" sha \" , \" shelve \" , \" shlex \" , \" shutil \" , \" signal \" , \" site \" , \" smtpd \" , \" smtplib \" , \" sndhdr \" , \" socket \" , \" spwd \" , \" sqlite3 \" , \" ssl \" , \" stat \" , \" statvfs \" , \" string \" , \" stringprep \" , \" struct \" , \" subprocess \" , \" sunau \" , \" sunaudiodev \" , \" symbol \" , \" symtable \" , \" sys \" , \" sysconfig \" , \" syslog \" , \" tabnanny \" , \" tarfile \" , \" telnetlib \" , \" tempfile \" , \" termios \" , \" test \" , \" textwrap \" , \" thread \" , \" threading \" , \" time \" , \" timeit \" , \" token \" , \" tokenize \" , \" trace \" , \" traceback \" , \" ttk \" , \" tty \" , \" turtle \" , \" types \" , \" unicodedata \" , \" unittest \" , \" urllib \" , \" urllib2 \" , \" urlparse \" , \" user \" , \" uu \" , \" uuid \" , \" videoreader \" , \" warnings \" , \" wave \" , \" weakref \" , \" webbrowser \" , \" whichdb \" , \" winsound \" , \" wsgiref \" , \" xdrlib \" , \" xml \" , \" xmlrpclib \" , \" zipfile \" , \" zipimport \" , \" zlib \" , ]","title":"Module isort.stdlibs.py27"},{"location":"reference/isort/stdlibs/py27/#variables","text":"stdlib","title":"Variables"},{"location":"reference/isort/stdlibs/py3/","text":"Module isort.stdlibs.py3 File contains the standard library of Python 3. DO NOT EDIT. If the standard library changes, a new list should be created using the mkstdlibs.py script. View Source \"\"\" File contains the standard library of Python 3 . DO NOT EDIT . If the standard library changes , a new list should be created using the mkstdlibs . py script . \"\"\" stdlib = [ \" _dummy_thread \" , \" _thread \" , \" abc \" , \" aifc \" , \" argparse \" , \" array \" , \" ast \" , \" asynchat \" , \" asyncio \" , \" asyncore \" , \" atexit \" , \" audioop \" , \" base64 \" , \" bdb \" , \" binascii \" , \" binhex \" , \" bisect \" , \" builtins \" , \" bz2 \" , \" cProfile \" , \" calendar \" , \" cgi \" , \" cgitb \" , \" chunk \" , \" cmath \" , \" cmd \" , \" code \" , \" codecs \" , \" codeop \" , \" collections \" , \" colorsys \" , \" compileall \" , \" concurrent \" , \" configparser \" , \" contextlib \" , \" contextvars \" , \" copy \" , \" copyreg \" , \" crypt \" , \" csv \" , \" ctypes \" , \" curses \" , \" dataclasses \" , \" datetime \" , \" dbm \" , \" decimal \" , \" difflib \" , \" dis \" , \" distutils \" , \" doctest \" , \" dummy_threading \" , \" email \" , \" encodings \" , \" ensurepip \" , \" enum \" , \" errno \" , \" faulthandler \" , \" fcntl \" , \" filecmp \" , \" fileinput \" , \" fnmatch \" , \" formatter \" , \" fractions \" , \" ftplib \" , \" functools \" , \" gc \" , \" getopt \" , \" getpass \" , \" gettext \" , \" glob \" , \" grp \" , \" gzip \" , \" hashlib \" , \" heapq \" , \" hmac \" , \" html \" , \" http \" , \" imaplib \" , \" imghdr \" , \" imp \" , \" importlib \" , \" inspect \" , \" io \" , \" ipaddress \" , \" itertools \" , \" json \" , \" keyword \" , \" lib2to3 \" , \" linecache \" , \" locale \" , \" logging \" , \" lzma \" , \" macpath \" , \" mailbox \" , \" mailcap \" , \" marshal \" , \" math \" , \" mimetypes \" , \" mmap \" , \" modulefinder \" , \" msilib \" , \" msvcrt \" , \" multiprocessing \" , \" netrc \" , \" nis \" , \" nntplib \" , \" numbers \" , \" operator \" , \" optparse \" , \" os \" , \" ossaudiodev \" , \" parser \" , \" pathlib \" , \" pdb \" , \" pickle \" , \" pickletools \" , \" pipes \" , \" pkgutil \" , \" platform \" , \" plistlib \" , \" poplib \" , \" posix \" , \" pprint \" , \" profile \" , \" pstats \" , \" pty \" , \" pwd \" , \" py_compile \" , \" pyclbr \" , \" pydoc \" , \" queue \" , \" quopri \" , \" random \" , \" re \" , \" readline \" , \" reprlib \" , \" resource \" , \" rlcompleter \" , \" runpy \" , \" sched \" , \" secrets \" , \" select \" , \" selectors \" , \" shelve \" , \" shlex \" , \" shutil \" , \" signal \" , \" site \" , \" smtpd \" , \" smtplib \" , \" sndhdr \" , \" socket \" , \" socketserver \" , \" spwd \" , \" sqlite3 \" , \" ssl \" , \" stat \" , \" statistics \" , \" string \" , \" stringprep \" , \" struct \" , \" subprocess \" , \" sunau \" , \" symbol \" , \" symtable \" , \" sys \" , \" sysconfig \" , \" syslog \" , \" tabnanny \" , \" tarfile \" , \" telnetlib \" , \" tempfile \" , \" termios \" , \" test \" , \" textwrap \" , \" threading \" , \" time \" , \" timeit \" , \" tkinter \" , \" token \" , \" tokenize \" , \" trace \" , \" traceback \" , \" tracemalloc \" , \" tty \" , \" turtle \" , \" turtledemo \" , \" types \" , \" typing \" , \" unicodedata \" , \" unittest \" , \" urllib \" , \" uu \" , \" uuid \" , \" venv \" , \" warnings \" , \" wave \" , \" weakref \" , \" webbrowser \" , \" winreg \" , \" winsound \" , \" wsgiref \" , \" xdrlib \" , \" xml \" , \" xmlrpc \" , \" zipapp \" , \" zipfile \" , \" zipimport \" , \" zlib \" , ] Variables stdlib","title":"Py3"},{"location":"reference/isort/stdlibs/py3/#module-isortstdlibspy3","text":"File contains the standard library of Python 3. DO NOT EDIT. If the standard library changes, a new list should be created using the mkstdlibs.py script. View Source \"\"\" File contains the standard library of Python 3 . DO NOT EDIT . If the standard library changes , a new list should be created using the mkstdlibs . py script . \"\"\" stdlib = [ \" _dummy_thread \" , \" _thread \" , \" abc \" , \" aifc \" , \" argparse \" , \" array \" , \" ast \" , \" asynchat \" , \" asyncio \" , \" asyncore \" , \" atexit \" , \" audioop \" , \" base64 \" , \" bdb \" , \" binascii \" , \" binhex \" , \" bisect \" , \" builtins \" , \" bz2 \" , \" cProfile \" , \" calendar \" , \" cgi \" , \" cgitb \" , \" chunk \" , \" cmath \" , \" cmd \" , \" code \" , \" codecs \" , \" codeop \" , \" collections \" , \" colorsys \" , \" compileall \" , \" concurrent \" , \" configparser \" , \" contextlib \" , \" contextvars \" , \" copy \" , \" copyreg \" , \" crypt \" , \" csv \" , \" ctypes \" , \" curses \" , \" dataclasses \" , \" datetime \" , \" dbm \" , \" decimal \" , \" difflib \" , \" dis \" , \" distutils \" , \" doctest \" , \" dummy_threading \" , \" email \" , \" encodings \" , \" ensurepip \" , \" enum \" , \" errno \" , \" faulthandler \" , \" fcntl \" , \" filecmp \" , \" fileinput \" , \" fnmatch \" , \" formatter \" , \" fractions \" , \" ftplib \" , \" functools \" , \" gc \" , \" getopt \" , \" getpass \" , \" gettext \" , \" glob \" , \" grp \" , \" gzip \" , \" hashlib \" , \" heapq \" , \" hmac \" , \" html \" , \" http \" , \" imaplib \" , \" imghdr \" , \" imp \" , \" importlib \" , \" inspect \" , \" io \" , \" ipaddress \" , \" itertools \" , \" json \" , \" keyword \" , \" lib2to3 \" , \" linecache \" , \" locale \" , \" logging \" , \" lzma \" , \" macpath \" , \" mailbox \" , \" mailcap \" , \" marshal \" , \" math \" , \" mimetypes \" , \" mmap \" , \" modulefinder \" , \" msilib \" , \" msvcrt \" , \" multiprocessing \" , \" netrc \" , \" nis \" , \" nntplib \" , \" numbers \" , \" operator \" , \" optparse \" , \" os \" , \" ossaudiodev \" , \" parser \" , \" pathlib \" , \" pdb \" , \" pickle \" , \" pickletools \" , \" pipes \" , \" pkgutil \" , \" platform \" , \" plistlib \" , \" poplib \" , \" posix \" , \" pprint \" , \" profile \" , \" pstats \" , \" pty \" , \" pwd \" , \" py_compile \" , \" pyclbr \" , \" pydoc \" , \" queue \" , \" quopri \" , \" random \" , \" re \" , \" readline \" , \" reprlib \" , \" resource \" , \" rlcompleter \" , \" runpy \" , \" sched \" , \" secrets \" , \" select \" , \" selectors \" , \" shelve \" , \" shlex \" , \" shutil \" , \" signal \" , \" site \" , \" smtpd \" , \" smtplib \" , \" sndhdr \" , \" socket \" , \" socketserver \" , \" spwd \" , \" sqlite3 \" , \" ssl \" , \" stat \" , \" statistics \" , \" string \" , \" stringprep \" , \" struct \" , \" subprocess \" , \" sunau \" , \" symbol \" , \" symtable \" , \" sys \" , \" sysconfig \" , \" syslog \" , \" tabnanny \" , \" tarfile \" , \" telnetlib \" , \" tempfile \" , \" termios \" , \" test \" , \" textwrap \" , \" threading \" , \" time \" , \" timeit \" , \" tkinter \" , \" token \" , \" tokenize \" , \" trace \" , \" traceback \" , \" tracemalloc \" , \" tty \" , \" turtle \" , \" turtledemo \" , \" types \" , \" typing \" , \" unicodedata \" , \" unittest \" , \" urllib \" , \" uu \" , \" uuid \" , \" venv \" , \" warnings \" , \" wave \" , \" weakref \" , \" webbrowser \" , \" winreg \" , \" winsound \" , \" wsgiref \" , \" xdrlib \" , \" xml \" , \" xmlrpc \" , \" zipapp \" , \" zipfile \" , \" zipimport \" , \" zlib \" , ]","title":"Module isort.stdlibs.py3"},{"location":"reference/isort/stdlibs/py3/#variables","text":"stdlib","title":"Variables"}]}